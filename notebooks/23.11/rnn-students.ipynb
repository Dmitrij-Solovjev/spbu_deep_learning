{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4eda323-3063-435f-bc1a-b1446b014c1c",
   "metadata": {},
   "source": [
    "# Простейшая рекуррентная сеть\n",
    "В этом ноутбуке мы пройдемся по основам работы с RNN. Сегодня займемся задачей генерации текста. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d8b089-5f9c-4dcb-8b14-3f565c24e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Iterable, Tuple\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.distributions.categorical import Categorical\n",
    "import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198424b3-07c0-4b46-83f0-8bbb53acacd4",
   "metadata": {},
   "source": [
    "В качестве обучающего датасета возьмем набор из 120 тысяч анекдотов на русском языке. \n",
    "[Ссылка на данные](https://archive.org/download/120_tysyach_anekdotov) и [пост на хабре про тематическое моделирование](https://habr.com/ru/companies/otus/articles/723306/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5fda8b3-2e4b-4385-aad5-b10ad73a5d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|startoftext|>Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже!\\n\\n<|startoftext|>- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...\\n\\n<|startoftext|>- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От со'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./anek_djvu.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "text[118:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f21a5-c7e3-445f-b902-24e18242bd7b",
   "metadata": {},
   "source": [
    "Мы не хотим моделировать все подряд, поэтому разобьем датасет на отдельные анекдоты.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fddd3f65-a156-4bbd-8c56-078652d38ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_data(text):\n",
    "    return text.replace(\"\\n\\n\", \"\").split(\"<|startoftext|>\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae42013-ef71-485c-805e-8cc4c61fe6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_text = cut_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67e8e214-e40c-4705-beb4-f51a6a284137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже!',\n",
       " '- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...',\n",
       " '- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От собственного храпа по крайней мере еще ни разу не просыпался.- Ну, так у жены спроси.- А жена и подавно не знает. У нее странная привычка после замужества возникла: как спать ложится - беруши вставляет.',\n",
       " 'Поссорилась с мужем. Пока он спал, я мысленно развелась с ним, поделила имущество, переехала, поняла, что жить без него не могу, дала последний шанс, вернулась. В итоге, ложусь спать уже счастливой женщиной.',\n",
       " 'Если тебя посещают мысли о смерти - это еще полбеды. Беда - это когда смерть посещают мысли о тебе...']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_text[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f6226-74c6-4488-a7bc-9360437e1b1f",
   "metadata": {},
   "source": [
    "Сделаем для начала самую простую модель с токенами на уровне символов. Это значит, что каждому символу в тексте ставится в соответствие некоторое число. Некоторые способы токенизации используют части слов или, наоборот, части бинарного представления текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e923efb-a3d5-4e22-b8e0-8bf6260d1e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = tuple(set(text))\n",
    "int2char = dict(enumerate(unique_chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99fa447-208d-4285-bb76-0870e985ce58",
   "metadata": {},
   "source": [
    "Напишем функции для энкодинга и декодинга нашего текста. Они будут преобразовывать список символов в список чисел и обратно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97704441-98c6-4c16-b0c2-10b88f941c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sentence, vocab):\n",
    "    return [vocab[sys] for sys in sentence] # List of ints \n",
    "\n",
    "def decode(tokens, vocab):\n",
    "    return [vocab[toc] for toc in tokens]# list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d0b4340-44bb-45ab-8cfe-972c9cfd410e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[145,\n",
       " 113,\n",
       " 110,\n",
       " 37,\n",
       " 94,\n",
       " 113,\n",
       " 118,\n",
       " 59,\n",
       " 176,\n",
       " 134,\n",
       " 28,\n",
       " 141,\n",
       " 117,\n",
       " 110,\n",
       " 120,\n",
       " 118,\n",
       " 18,\n",
       " 141,\n",
       " 113,\n",
       " 118,\n",
       " 86,\n",
       " 110,\n",
       " 113,\n",
       " 150,\n",
       " 113,\n",
       " 118,\n",
       " 173,\n",
       " 206,\n",
       " 92,\n",
       " 139,\n",
       " 103,\n",
       " 113,\n",
       " 173,\n",
       " 118,\n",
       " 103,\n",
       " 176,\n",
       " 172,\n",
       " 117,\n",
       " 139,\n",
       " 176,\n",
       " 28,\n",
       " 141,\n",
       " 86,\n",
       " 80,\n",
       " 118,\n",
       " 86,\n",
       " 176,\n",
       " 134,\n",
       " 117,\n",
       " 134,\n",
       " 117,\n",
       " 118,\n",
       " 3,\n",
       " 28,\n",
       " 103,\n",
       " 141,\n",
       " 139,\n",
       " 176,\n",
       " 110,\n",
       " 37,\n",
       " 103,\n",
       " 96,\n",
       " 134,\n",
       " 117,\n",
       " 118,\n",
       " 94,\n",
       " 110,\n",
       " 176,\n",
       " 150,\n",
       " 117,\n",
       " 180,\n",
       " 176,\n",
       " 134,\n",
       " 117,\n",
       " 38,\n",
       " 118,\n",
       " 57,\n",
       " 176,\n",
       " 94,\n",
       " 118,\n",
       " 150,\n",
       " 86,\n",
       " 28,\n",
       " 118,\n",
       " 206,\n",
       " 139,\n",
       " 113,\n",
       " 170,\n",
       " 196,\n",
       " 134,\n",
       " 176,\n",
       " 103,\n",
       " 113,\n",
       " 120,\n",
       " 118,\n",
       " 172,\n",
       " 110,\n",
       " 117,\n",
       " 103,\n",
       " 199]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверьте, что энеодинг и декодинг работают\n",
    "encoded = encode(cut_text[0], char2int)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a40a7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Только заметил, что слово \"п@рно\" набирается самими центральными клавишами. Как все продумано, блин!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = decode(encoded, int2char)\n",
    "\"\".join(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017baeba-1197-4d21-8cc8-28ccf43262c5",
   "metadata": {},
   "source": [
    "Просто представления символов в виде числа не подходят для обучения моделей. На выходе должны быть вероятности всех возможных токенов из словаря. Поэтому модели удобно учить с помощью энтропии. К тому же, токены часто преобразуют из исходного представления в эмбеддинги, которые также позволяют получить более удобное представление в высокоразмерном пространстве. \n",
    "\n",
    "В итоге векторы в модели выглядят следующим образом:\n",
    "![alt_text](../../additional_materials/images/char_rnn.jfif)\n",
    "\n",
    "Задание: реализуйте метод, который преобразует батч в бинарное представление."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e692112f-edea-4e18-b48b-5aec75f935d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(int_words: torch.Tensor, vocab_size: int) -> torch.Tensor:\n",
    "    \"\"\"Encodes batch of sentences into binary values\"\"\"\n",
    "    words_one_hot = torch.zeros(\n",
    "\n",
    "        (int_words.numel(), vocab_size), dtype=int_words.dtype, device=int_words.device\n",
    "        # init one hot tensor. \n",
    "    )\n",
    "    words_one_hot[torch.arange(words_one_hot.shape[0]), int_words.flatten()] = 1\n",
    "    words_one_hot = words_one_hot.reshape((*int_words.shape, vocab_size))\n",
    "    # your code: make from int one hot vector for each element of input tensor. Size bxseq_len -> b x seq_len x vocab_size\n",
    "    return words_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88488683-6df3-430e-b942-9c10548a1802",
   "metadata": {},
   "source": [
    "Проверьте ваш код."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af941c64-cc6d-41b4-92e3-a8f37b861545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 1, 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "test_seq = torch.tensor([[2, 6, 4, 1], [0,3, 2, 4]])\n",
    "test_one_hot = one_hot_encode(test_seq, 8)\n",
    "\n",
    "print(test_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da82134-e59d-4806-be2c-839c2f850ee6",
   "metadata": {},
   "source": [
    "Однако, наши последовательности на самом деле разной длины. Как же объединить их в батч?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0fe1e-40a5-4a58-b1bd-b4a4101d986a",
   "metadata": {},
   "source": [
    "Реализуем два необходимых класса: \n",
    "- токенайзер, который будет брать текст, кодировать и декодировать символы. Еще одно, что будет реализовано там - добавлено несколько специальных символов (паддинг, конец последовательности, начало последовательности).\n",
    "- Датасет, который будет брать набор шуток, используя токенайзер, строить векторное представление слов (Word embedding) и дополнять последовательность до максимальной длины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69d266c8-b4d0-42fd-9c6c-02b7f3b9a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, cut_text, max_len: int = 512):\n",
    "        self.text = text\n",
    "        self.max_len = max_len\n",
    "        self.specials = ['<pad>', '<bos>', '<eos>']\n",
    "        unique_chars = tuple(set(text))\n",
    "        self.int2char = dict(enumerate(tuple(set(text))))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        self._add_special(\"<pad>\")\n",
    "        self._add_special('<bos>')\n",
    "        self._add_special('<eos>')\n",
    "    \n",
    "    def _add_special(self, symbol) -> None:\n",
    "        # add special characters to yuor dicts\n",
    "        sym_num = len(self.char2int)\n",
    "        self.char2int[symbol] = sym_num\n",
    "        self.int2char[sym_num] = symbol\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.int2char) # your code\n",
    "        \n",
    "    def decode_symbol(self, el):\n",
    "        return self.int2char[el]\n",
    "        \n",
    "    def encode_symbol(self, el):\n",
    "        return self.char2int[el]\n",
    "        \n",
    "    def str_to_idx(self, chars):\n",
    "        return [self.char2int[sym] for sym in chars] # str -> list[int]\n",
    "\n",
    "    def idx_to_str(self, idx):\n",
    "        return [self.int2char[toc] for toc in idx] # list[int] -> list[str]\n",
    "\n",
    "    def encode(self, chars, eos=True):\n",
    "        if eos:\n",
    "            chars = ['<bos>'] + list(chars) + ['<eos>']\n",
    "        else:\n",
    "            chars = ['<bos>'] + list(chars)\n",
    "        return self.str_to_idx(chars)\n",
    "\n",
    "    def decode(self, idx):\n",
    "        chars = self.idx_to_str(idx)\n",
    "        return \"\".join(chars) # make string from list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8a76399-0ae4-4d4f-9d95-56d695eb7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokesDataset(Dataset):\n",
    "    def __init__(self, tokenizer, cut_text, max_len: int = 256):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cut_text = cut_text\n",
    "        self.pad_index = self.tokenizer.encode_symbol(\"<pad>\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cut_text)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        #  в идеале запонлять паддингами лучше в другом месте\n",
    "        encoded = self.tokenizer.encode(self.cut_text[item])[:self.max_len]\n",
    "        padded = torch.full((self.max_len, ), self.pad_index, dtype=torch.long)\n",
    "        padded[:len(encoded)] = torch.tensor(encoded)\n",
    "        # pad your sequence and make a final sample. You can skip padding and pad sequences with torch special method.\n",
    "        return padded, len(encoded)\n",
    "\n",
    "# Optionally add new methods to your dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af9e66a2-d196-459f-a88a-94bc119873e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(text)\n",
    "dataset = JokesDataset(tokenizer, cut_text, 256)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c72173d-d38b-4d4c-a98e-878267c0fd87",
   "metadata": {},
   "source": [
    "Вопрос: А как бы мы должны были разделять данные на последовательности и батчи в случае, если бы использовался сплошной текст?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "182387e9-9768-42b2-b428-16d73b24b07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[215, 162, 110,  ..., 214, 214, 214],\n",
       "         [215,  57, 118,  ..., 214, 214, 214],\n",
       "         [215, 159, 141,  ..., 214, 214, 214],\n",
       "         ...,\n",
       "         [215, 184, 103,  ..., 214, 214, 214],\n",
       "         [215,  88, 176,  ..., 214, 214, 214],\n",
       "         [215, 145, 176,  ..., 214, 214, 214]]),\n",
       " tensor([ 93, 162,  78, 180,  88, 147, 120,  83, 137,  46, 150, 173, 105,  54,\n",
       "          86, 246,  82,  84, 172, 147,  65,  84, 157,  97, 171,  69,  73,  43,\n",
       "         118, 113, 136, 137])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Задание: проверьте свой датасет\n",
    "for batch in dataloader:\n",
    "    break\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf1f16-53d0-45a6-abd5-1a4c5b17285f",
   "metadata": {},
   "source": [
    "Теперь реализуем нашу модель. \n",
    "Необходимо следующее:\n",
    " - Используя токенайзер, задать размер словаря\n",
    " - Задать слой RNN с помощью torch.RNN. Доп.задание: создайте модель, используя слой LSTM.\n",
    " - Задать полносвязный слой с набором параметров: размерность ввода — n_hidden; размерность выхода — размер словаря. Этот слой преобразует состояние модели в логиты токенов.\n",
    " - Определить шаг forward, который будет использоваться при обучении\n",
    " - Определить метод init_hidden, который будет задавать начальное внутреннее состояние. Инициализировать будем нулями.\n",
    " - Определить метод inference, в котором будет происходить генерация последовательности из префикса. Здесь мы уже не используем явные логиты, а семплируем токены на их основе.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cc03daf-9a78-4d34-a8da-c1aed594b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        hidden_dim: int = 256,\n",
    "        num_layers: int = 2,\n",
    "        drop_prob: float = 0.5,\n",
    "        max_len: int = 512,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        self.max_len = max_len\n",
    "        # create mappings\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        ## define the LSTM, dropout and fully connected layers\n",
    "        self.encoder = nn.Embedding(self.tokenizer.vocab_size, self.hidden_dim)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=self.drop_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=self.drop_prob)\n",
    "        self.decoder = nn.Linear(\n",
    "            in_features=self.hidden_dim,\n",
    "            out_features=self.tokenizer.vocab_size,\n",
    "        )\n",
    "\n",
    "    # Forward - это проход вперёд по слою\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, lengths: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # one-hot encode your sequence\n",
    "        packed_embeds = self.encoder(x) # pack your sequence. This helps with the efficiency. Use torch function pack_padded_sequence\n",
    "        outputs, hidden = self.rnn(packed_embeds) # run you model\n",
    "        \n",
    "        # TODO: Понять нафига\n",
    "        #  out, lengths = # pad sequence back\n",
    "        \n",
    "        # Pass through a dropout layer and fully connected layer\n",
    "        out = self.dropout(outputs)\n",
    "        ## Get the output for classification.\n",
    "        out = self.decoder(out)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    \n",
    "    # инференс - режим не обучения (По сути штатная работа)\n",
    "    def inference(self, prefix='<bos> ', device=\"cpu\"):\n",
    "        tokens = torch.tensor([self.tokenizer.encode(prefix, eos=False)], device=device) # encode prefix\n",
    "        \n",
    "        # 2 stopping conditions: reaching max len or getting <eos> token\n",
    "        # Generate sequence iteratively\n",
    "        for _ in range(self.max_len - len(tokens[0])):\n",
    "            # YOUR CODE: generate sequence one by one\n",
    "            # Pass tokens through the embedding layer\n",
    "            logits, hidden = self.forward(tokens, torch.tensor([tokens.size(1)]))\n",
    "            \n",
    "            # Get the last token's logits and sample a token\n",
    "            next_token_logits = logits[:, -1, :]\n",
    "            new_token = torch.multinomial(\n",
    "                torch.nn.functional.softmax(next_token_logits, dim=-1), num_samples=1\n",
    "            )\n",
    "\n",
    "            # Append the new token\n",
    "            tokens = torch.cat([tokens, new_token], dim=1)\n",
    "\n",
    "            # Stop if the <eos> token is generated\n",
    "            if new_token.item() == self.tokenizer.encode_symbol(\"<eos>\"):\n",
    "                break\n",
    "        # Decode the token IDs back into a string\n",
    "        return self.tokenizer.decode(tokens.squeeze().tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1202bfda-3653-4644-8fcc-eda9e92e434f",
   "metadata": {},
   "source": [
    "Зададим параметры для обучения. Можете варьировать их, чтобы вам хватило ресурсов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "173284d2-1d28-4235-a3ac-e25494039e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "seq_length = 512\n",
    "n_hidden = 64 #256\n",
    "n_layers = 4 #4\n",
    "drop_prob = 0.1\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329823d-abd8-4044-8206-470f07b6da62",
   "metadata": {},
   "source": [
    "Напишите функцию для одного тренировочного шага. В этом ноутбуке сам процесс обучения модели достаточно тривиален, поэтому мы не будем использовать сложные функции для обучающего цикла. Вы же, однако, можете дописать их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "737cb10c-1da8-43fc-b332-1b53f4fb6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(\n",
    "    model: CharRNN,\n",
    "    train_batch: Tuple[torch.Tensor, torch.Tensor],\n",
    "    vocab_size: int,\n",
    "    criterion: nn.Module,\n",
    "    optimizer,\n",
    "    device=\"cpu\"\n",
    ") -> torch.Tensor:\n",
    "    inputs, lengths = train_batch\n",
    "    inputs = inputs.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "\n",
    "    # Сброс градиентов\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Прямой проход\n",
    "    outputs, _ = model(inputs[:, :-1], lengths)\n",
    "\n",
    "    # Переформатирование выходов и целевых меток для расчета функции потерь\n",
    "    outputs = outputs.view(-1, vocab_size)\n",
    "    targets = inputs[:, 1:].reshape(-1)\n",
    "\n",
    "    # Вычисление функции потерь\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Обратный проход\n",
    "    loss.backward()\n",
    "\n",
    "    # Шаг оптимизации\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1055e6e-6374-4af3-b1ab-8ad8b4125664",
   "metadata": {},
   "source": [
    "Инициализируйте модель, функцию потерь и оптимизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f85fc024-7cec-4833-ac15-cafe05724003",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharRNN(tokenizer, hidden_dim=n_hidden, num_layers=n_layers, drop_prob=drop_prob)\n",
    "hidden = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a140de0c-e648-4d9f-babf-659486dbae92",
   "metadata": {},
   "source": [
    "Проверьте необученную модель: она должна выдавать бессмысленные последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37263cdf-5a6c-4612-8cf9-57105c169943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    clear_output()\n",
    "    plt.plot(range(1, len(losses) + 1), losses)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f70324-c88a-4d98-bae6-e6c5356f2025",
   "metadata": {},
   "source": [
    "Проведите обучение на протяжении нескольких эпох и выведите график лоссов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "406bfdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "174d7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57059744-44ac-4aad-86f6-f67dc2ea7600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    with tqdm.tqdm(total=len(dataloader)) as prbar:\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            loss = training_step(model, batch, tokenizer.vocab_size, criterion, optimizer, device)\n",
    "            epoch_loss += loss\n",
    "        \n",
    "            if i % 100 == 0:\n",
    "                #print(f'Done {i/len(dataloader) * 100:.2f}%, Loss: {loss:.4f}')\n",
    "                metrics_str = f\"Loss: {round(loss, 4)} \"\n",
    "                #for k, v in metrics_dict.items():\n",
    "                #    metrics_str += f\"{k}: {round(float(v), 4)} \"\n",
    "                prbar.set_description(metrics_str)\n",
    "                prbar.update(100)\n",
    "    \n",
    "    epoch_loss /= len(dataloader)\n",
    "    losses.append(epoch_loss)\n",
    "    \n",
    "    plot_losses(losses)\n",
    "    #torch.save(model.state_dict(), \"rnn.pt\")\n",
    "    torch.save(model, \"rnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "399e1521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNN(\n",
       "  (encoder): Embedding(217, 64)\n",
       "  (rnn): LSTM(64, 64, num_layers=4, batch_first=True, dropout=0.1)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (decoder): Linear(in_features=64, out_features=217, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load(\"rnn.pt\", weights_only=True))\n",
    "model = torch.load(\"rnn.pt\", weights_only=False)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8694a-132f-4a44-a5d3-a0f39219e55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>Пилите, Шура, пилите. Они надеть рьхы, а умен читних Ножный молинжо.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они только оттелит!<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они вам это же почему нешья в \"Приченицо., .семит. Самой судиру еще инпаями.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они любили деязтем на нему у стали.?<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<bos>Пилите, Шура, пилите. Они извеслинственные и вам к!ала одного матюльлый и колон их мужчин похишал! Мальчик.., тоистока не Парякся.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они какая вахась дазеши сдет, и чем содерсным оспонутские кнует для ты! Оатастом будеер - престоливый?- Какая подводным о отногомный?- А а в ваши, я вы еще нет?<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они спосул дереваву кода лет - дня спасистимая паметовый позо истам я коеков - муж всегда братиционр.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они умочтке, как в россиметов и дурак плеваться на своим рахде из Упит...- Сеня  З<pad>rвас \"В такая?- Ну на утриху, день, я умеет \"Очнуй, что фофисра?<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они срутает ивушок порожне удерка друга, туом девичтерь тебя прижалитее. И таки\" настало от коеценкова.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они блантки получать в нем России на дожека на в думой обоменно, и еще приляла разбонане, а у вас теперь конматиру.<eos>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.inference(\"Пилите, Шура, пилите. Они \", device=device) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef889dd2-fde2-429c-9c61-f5a93517bd3f",
   "metadata": {},
   "source": [
    "Теперь попробуем написать свой собственный RNN. Это будет довольно простая модель с одним слоем.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1fe4954-e2b5-43c5-9bb6-0b2a5cc2cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: custom model nn.Module, changed CharRNN, etc\n",
    "\n",
    "class CustomCharRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        hidden_dim: int = 256,\n",
    "        num_layers: int = 1,\n",
    "        drop_prob: float = 0.5,\n",
    "        max_len: int = 512,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        self.max_len = max_len\n",
    "        # create mappings\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        ## define the LSTM, dropout and fully connected layers\n",
    "        self.encoder = nn.Embedding(self.tokenizer.vocab_size, self.hidden_dim)\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=self.drop_prob)\n",
    "        self.decoder = nn.Linear(\n",
    "            in_features=self.hidden_dim,\n",
    "            out_features=self.tokenizer.vocab_size,\n",
    "        )\n",
    "\n",
    "    # Forward - это проход вперёд по слою\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, lengths: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # one-hot encode your sequence\n",
    "        packed_embeds = self.encoder(x) # pack your sequence. This helps with the efficiency. Use torch function pack_padded_sequence\n",
    "        outputs, hidden = self.rnn(packed_embeds) # run you model\n",
    "        \n",
    "        # TODO: Понять нафига\n",
    "        #  out, lengths = # pad sequence back\n",
    "        \n",
    "        # Pass through a dropout layer and fully connected layer\n",
    "        out = self.dropout(outputs)\n",
    "        ## Get the output for classification.\n",
    "        out = self.decoder(out)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    \n",
    "    # инференс - режим не обучения (По сути штатная работа)\n",
    "    def inference(self, prefix='<bos> ', device=\"cpu\"):\n",
    "        tokens = torch.tensor([self.tokenizer.encode(prefix, eos=False)], device=device) # encode prefix\n",
    "        \n",
    "        # 2 stopping conditions: reaching max len or getting <eos> token\n",
    "        # Generate sequence iteratively\n",
    "        for _ in range(self.max_len - len(tokens[0])):\n",
    "            # YOUR CODE: generate sequence one by one\n",
    "            # Pass tokens through the embedding layer\n",
    "            logits, hidden = self.forward(tokens, torch.tensor([tokens.size(1)]))\n",
    "            \n",
    "            # Get the last token's logits and sample a token\n",
    "            next_token_logits = logits[:, -1, :]\n",
    "            new_token = torch.multinomial(\n",
    "                torch.nn.functional.softmax(next_token_logits, dim=-1), num_samples=1\n",
    "            )\n",
    "\n",
    "            # Append the new token\n",
    "            tokens = torch.cat([tokens, new_token], dim=1)\n",
    "\n",
    "            # Stop if the <eos> token is generated\n",
    "            if new_token.item() == self.tokenizer.encode_symbol(\"<eos>\"):\n",
    "                break\n",
    "        # Decode the token IDs back into a string\n",
    "        return self.tokenizer.decode(tokens.squeeze().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbce99f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_rnn = CustomCharRNN(tokenizer, hidden_dim=n_hidden, num_layers=1, drop_prob=drop_prob).to(device)\n",
    "hidden = None\n",
    "optimizer2 = torch.optim.Adam(real_rnn.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bcec5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0299 :  72%|███████▏  | 900/1242 [00:49<00:18, 18.05it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)) \u001b[38;5;28;01mas\u001b[39;00m prbar:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m----> 8\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[18], line 27\u001b[0m, in \u001b[0;36mtraining_step\u001b[0;34m(model, train_batch, vocab_size, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Обратный проход\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Шаг оптимизации\u001b[39;00m\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Документы/Першин_Никольская_Нейронные_сети/.myvenv/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Документы/Першин_Никольская_Нейронные_сети/.myvenv/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Документы/Першин_Никольская_Нейронные_сети/.myvenv/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "num_epochs = 8\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    with tqdm.tqdm(total=len(dataloader)) as prbar:\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            loss = training_step(real_rnn, batch, tokenizer.vocab_size, criterion, optimizer2, device)\n",
    "            epoch_loss += loss\n",
    "        \n",
    "            if i % 100 == 0:\n",
    "                metrics_str = f\"Loss: {round(loss, 4)} \"\n",
    "                prbar.set_description(metrics_str)\n",
    "                prbar.update(100)\n",
    "    \n",
    "    epoch_loss /= len(dataloader)\n",
    "    losses.append(epoch_loss)\n",
    "    \n",
    "    plot_losses(losses)\n",
    "    torch.save(real_rnn.state_dict(), \"real_rnn2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36120513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>Пилите, Шура, пилите. Они вас два теперь тестошек и клефаума!<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они призеть, в какая<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они не ни тут й*гу тогда и томленны.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они есть бенсеровали. Содевоков.Со них остатости аразма и.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они недеть чечекой нопусшивал крагамазы.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они подскорь и зао ссущия bАНглрараху... Кулик?- Что-то дамся мужяне. Кер, когда выокзистать читал.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они как думаешь созразать у вас.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они шира. Он на подспвочный?- Скажят, а чите!!<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они дора дуя, того детьшим о огиттешемосс - до санко прошло.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они есть не кондать. У тункизнебся докета женило!<eos>']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.inference(\"Пилите, Шура, пилите. Они \", device=device) for _ in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2beef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
