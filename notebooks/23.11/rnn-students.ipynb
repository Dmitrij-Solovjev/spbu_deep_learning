{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4eda323-3063-435f-bc1a-b1446b014c1c",
   "metadata": {},
   "source": [
    "# Простейшая рекуррентная сеть\n",
    "В этом ноутбуке мы пройдемся по основам работы с RNN. Сегодня займемся задачей генерации текста. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d8b089-5f9c-4dcb-8b14-3f565c24e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Iterable, Tuple\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.distributions.categorical import Categorical\n",
    "import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198424b3-07c0-4b46-83f0-8bbb53acacd4",
   "metadata": {},
   "source": [
    "В качестве обучающего датасета возьмем набор из 120 тысяч анекдотов на русском языке. \n",
    "[Ссылка на данные](https://archive.org/download/120_tysyach_anekdotov) и [пост на хабре про тематическое моделирование](https://habr.com/ru/companies/otus/articles/723306/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5fda8b3-2e4b-4385-aad5-b10ad73a5d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|startoftext|>Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже!\\n\\n<|startoftext|>- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...\\n\\n<|startoftext|>- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От со'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./anek_djvu.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "text[118:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f21a5-c7e3-445f-b902-24e18242bd7b",
   "metadata": {},
   "source": [
    "Мы не хотим моделировать все подряд, поэтому разобьем датасет на отдельные анекдоты.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fddd3f65-a156-4bbd-8c56-078652d38ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_data(text):\n",
    "    return text.replace(\"\\n\\n\", \"\").split(\"<|startoftext|>\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae42013-ef71-485c-805e-8cc4c61fe6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_text = cut_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67e8e214-e40c-4705-beb4-f51a6a284137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже!',\n",
       " '- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...',\n",
       " '- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От собственного храпа по крайней мере еще ни разу не просыпался.- Ну, так у жены спроси.- А жена и подавно не знает. У нее странная привычка после замужества возникла: как спать ложится - беруши вставляет.',\n",
       " 'Поссорилась с мужем. Пока он спал, я мысленно развелась с ним, поделила имущество, переехала, поняла, что жить без него не могу, дала последний шанс, вернулась. В итоге, ложусь спать уже счастливой женщиной.',\n",
       " 'Если тебя посещают мысли о смерти - это еще полбеды. Беда - это когда смерть посещают мысли о тебе...']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_text[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f6226-74c6-4488-a7bc-9360437e1b1f",
   "metadata": {},
   "source": [
    "Сделаем для начала самую простую модель с токенами на уровне символов. Это значит, что каждому символу в тексте ставится в соответствие некоторое число. Некоторые способы токенизации используют части слов или, наоборот, части бинарного представления текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e923efb-a3d5-4e22-b8e0-8bf6260d1e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = tuple(set(text))\n",
    "int2char = dict(enumerate(unique_chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99fa447-208d-4285-bb76-0870e985ce58",
   "metadata": {},
   "source": [
    "Напишем функции для энкодинга и декодинга нашего текста. Они будут преобразовывать список символов в список чисел и обратно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97704441-98c6-4c16-b0c2-10b88f941c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sentence, vocab):\n",
    "    return [vocab[sys] for sys in sentence] # List of ints \n",
    "\n",
    "def decode(tokens, vocab):\n",
    "    return [vocab[toc] for toc in tokens]# list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d0b4340-44bb-45ab-8cfe-972c9cfd410e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[112,\n",
       " 171,\n",
       " 110,\n",
       " 59,\n",
       " 10,\n",
       " 171,\n",
       " 34,\n",
       " 173,\n",
       " 187,\n",
       " 68,\n",
       " 179,\n",
       " 70,\n",
       " 43,\n",
       " 110,\n",
       " 94,\n",
       " 34,\n",
       " 132,\n",
       " 70,\n",
       " 171,\n",
       " 34,\n",
       " 72,\n",
       " 110,\n",
       " 171,\n",
       " 180,\n",
       " 171,\n",
       " 34,\n",
       " 35,\n",
       " 55,\n",
       " 113,\n",
       " 209,\n",
       " 169,\n",
       " 171,\n",
       " 35,\n",
       " 34,\n",
       " 169,\n",
       " 187,\n",
       " 142,\n",
       " 43,\n",
       " 209,\n",
       " 187,\n",
       " 179,\n",
       " 70,\n",
       " 72,\n",
       " 192,\n",
       " 34,\n",
       " 72,\n",
       " 187,\n",
       " 68,\n",
       " 43,\n",
       " 68,\n",
       " 43,\n",
       " 34,\n",
       " 124,\n",
       " 179,\n",
       " 169,\n",
       " 70,\n",
       " 209,\n",
       " 187,\n",
       " 110,\n",
       " 59,\n",
       " 169,\n",
       " 186,\n",
       " 68,\n",
       " 43,\n",
       " 34,\n",
       " 10,\n",
       " 110,\n",
       " 187,\n",
       " 180,\n",
       " 43,\n",
       " 121,\n",
       " 187,\n",
       " 68,\n",
       " 43,\n",
       " 109,\n",
       " 34,\n",
       " 21,\n",
       " 187,\n",
       " 10,\n",
       " 34,\n",
       " 180,\n",
       " 72,\n",
       " 179,\n",
       " 34,\n",
       " 55,\n",
       " 209,\n",
       " 171,\n",
       " 197,\n",
       " 8,\n",
       " 68,\n",
       " 187,\n",
       " 169,\n",
       " 171,\n",
       " 94,\n",
       " 34,\n",
       " 142,\n",
       " 110,\n",
       " 43,\n",
       " 169,\n",
       " 174]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверьте, что энеодинг и декодинг работают\n",
    "encoded = encode(cut_text[0], char2int)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a40a7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Только заметил, что слово \"п@рно\" набирается самими центральными клавишами. Как все продумано, блин!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = decode(encoded, int2char)\n",
    "\"\".join(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017baeba-1197-4d21-8cc8-28ccf43262c5",
   "metadata": {},
   "source": [
    "Просто представления символов в виде числа не подходят для обучения моделей. На выходе должны быть вероятности всех возможных токенов из словаря. Поэтому модели удобно учить с помощью энтропии. К тому же, токены часто преобразуют из исходного представления в эмбеддинги, которые также позволяют получить более удобное представление в высокоразмерном пространстве. \n",
    "\n",
    "В итоге векторы в модели выглядят следующим образом:\n",
    "![alt_text](../../additional_materials/images/char_rnn.jfif)\n",
    "\n",
    "Задание: реализуйте метод, который преобразует батч в бинарное представление."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e692112f-edea-4e18-b48b-5aec75f935d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(int_words: torch.Tensor, vocab_size: int) -> torch.Tensor:\n",
    "    \"\"\"Encodes batch of sentences into binary values\"\"\"\n",
    "    words_one_hot = torch.zeros(\n",
    "\n",
    "        (int_words.numel(), vocab_size), dtype=int_words.dtype, device=int_words.device\n",
    "        # init one hot tensor. \n",
    "    )\n",
    "    words_one_hot[torch.arange(words_one_hot.shape[0]), int_words.flatten()] = 1\n",
    "    words_one_hot = words_one_hot.reshape((*int_words.shape, vocab_size))\n",
    "    # your code: make from int one hot vector for each element of input tensor. Size bxseq_len -> b x seq_len x vocab_size\n",
    "    return words_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88488683-6df3-430e-b942-9c10548a1802",
   "metadata": {},
   "source": [
    "Проверьте ваш код."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af941c64-cc6d-41b4-92e3-a8f37b861545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 1, 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "test_seq = torch.tensor([[2, 6, 4, 1], [0,3, 2, 4]])\n",
    "test_one_hot = one_hot_encode(test_seq, 8)\n",
    "\n",
    "print(test_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da82134-e59d-4806-be2c-839c2f850ee6",
   "metadata": {},
   "source": [
    "Однако, наши последовательности на самом деле разной длины. Как же объединить их в батч?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0fe1e-40a5-4a58-b1bd-b4a4101d986a",
   "metadata": {},
   "source": [
    "Реализуем два необходимых класса: \n",
    "- токенайзер, который будет брать текст, кодировать и декодировать символы. Еще одно, что будет реализовано там - добавлено несколько специальных символов (паддинг, конец последовательности, начало последовательности).\n",
    "- Датасет, который будет брать набор шуток, используя токенайзер, строить векторное представление слов (Word embedding) и дополнять последовательность до максимальной длины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69d266c8-b4d0-42fd-9c6c-02b7f3b9a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, cut_text, max_len: int = 512):\n",
    "        self.text = text\n",
    "        self.max_len = max_len\n",
    "        self.specials = ['<pad>', '<bos>', '<eos>']\n",
    "        unique_chars = tuple(set(text))\n",
    "        self.int2char = dict(enumerate(tuple(set(text))))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        self._add_special(\"<pad>\")\n",
    "        self._add_special('<bos>')\n",
    "        self._add_special('<eos>')\n",
    "    \n",
    "    def _add_special(self, symbol) -> None:\n",
    "        # add special characters to yuor dicts\n",
    "        sym_num = len(self.char2int)\n",
    "        self.char2int[symbol] = sym_num\n",
    "        self.int2char[sym_num] = symbol\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.int2char) # your code\n",
    "        \n",
    "    def decode_symbol(self, el):\n",
    "        return self.int2char[el]\n",
    "        \n",
    "    def encode_symbol(self, el):\n",
    "        return self.char2int[el]\n",
    "        \n",
    "    def str_to_idx(self, chars):\n",
    "        return [self.char2int[sym] for sym in chars] # str -> list[int]\n",
    "\n",
    "    def idx_to_str(self, idx):\n",
    "        return [self.int2char[toc] for toc in idx] # list[int] -> list[str]\n",
    "\n",
    "    def encode(self, chars, eos=True):\n",
    "        if eos:\n",
    "            chars = ['<bos>'] + list(chars) + ['<eos>']\n",
    "        else:\n",
    "            chars = ['<bos>'] + list(chars)\n",
    "        return self.str_to_idx(chars)\n",
    "\n",
    "    def decode(self, idx):\n",
    "        chars = self.idx_to_str(idx)\n",
    "        return \"\".join(chars) # make string from list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8a76399-0ae4-4d4f-9d95-56d695eb7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokesDataset(Dataset):\n",
    "    def __init__(self, tokenizer, cut_text, max_len: int = 256):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cut_text = cut_text\n",
    "        self.pad_index = self.tokenizer.encode_symbol(\"<pad>\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cut_text)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        #  в идеале запонлять паддингами лучше в другом месте\n",
    "        encoded = self.tokenizer.encode(self.cut_text[item])[:self.max_len]\n",
    "        padded = torch.full((self.max_len, ), self.pad_index, dtype=torch.long)\n",
    "        padded[:len(encoded)] = torch.tensor(encoded)\n",
    "        # pad your sequence and make a final sample. You can skip padding and pad sequences with torch special method.\n",
    "        return padded, len(encoded)\n",
    "\n",
    "# Optionally add new methods to your dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af9e66a2-d196-459f-a88a-94bc119873e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(text)\n",
    "dataset = JokesDataset(tokenizer, cut_text, 256)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c72173d-d38b-4d4c-a98e-878267c0fd87",
   "metadata": {},
   "source": [
    "Вопрос: А как бы мы должны были разделять данные на последовательности и батчи в случае, если бы использовался сплошной текст?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "182387e9-9768-42b2-b428-16d73b24b07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[215,  22,  34,  ..., 214, 214, 214],\n",
       "         [215,  22,  34,  ..., 214, 214, 214],\n",
       "         [215,  22,  34,  ..., 214, 214, 214],\n",
       "         ...,\n",
       "         [215,  86,  72,  ..., 214, 214, 214],\n",
       "         [215,  22,  34,  ..., 214, 214, 214],\n",
       "         [215, 112, 187,  ..., 214, 214, 214]]),\n",
       " tensor([ 90,  94, 162, 144, 102,  76,  36,  78, 114,  94, 195, 173,  58, 101,\n",
       "         111, 107,  88, 190, 118, 214, 182, 204, 115, 131, 175,  63, 111,  46,\n",
       "         117,  92, 116, 181])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Задание: проверьте свой датасет\n",
    "for batch in dataloader:\n",
    "    break\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf1f16-53d0-45a6-abd5-1a4c5b17285f",
   "metadata": {},
   "source": [
    "Теперь реализуем нашу модель. \n",
    "Необходимо следующее:\n",
    " - Используя токенайзер, задать размер словаря\n",
    " - Задать слой RNN с помощью torch.RNN. Доп.задание: создайте модель, используя слой LSTM.\n",
    " - Задать полносвязный слой с набором параметров: размерность ввода — n_hidden; размерность выхода — размер словаря. Этот слой преобразует состояние модели в логиты токенов.\n",
    " - Определить шаг forward, который будет использоваться при обучении\n",
    " - Определить метод init_hidden, который будет задавать начальное внутреннее состояние. Инициализировать будем нулями.\n",
    " - Определить метод inference, в котором будет происходить генерация последовательности из префикса. Здесь мы уже не используем явные логиты, а семплируем токены на их основе.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cc03daf-9a78-4d34-a8da-c1aed594b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        hidden_dim: int = 256,\n",
    "        num_layers: int = 2,\n",
    "        drop_prob: float = 0.5,\n",
    "        max_len: int = 512,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        self.max_len = max_len\n",
    "        # create mappings\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        ## define the LSTM, dropout and fully connected layers\n",
    "        self.encoder = nn.Embedding(self.tokenizer.vocab_size, self.hidden_dim)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=self.drop_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=self.drop_prob)\n",
    "        self.decoder = nn.Linear(\n",
    "            in_features=self.hidden_dim,\n",
    "            out_features=self.tokenizer.vocab_size,\n",
    "        )\n",
    "\n",
    "    # Forward - это проход вперёд по слою\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, lengths: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # one-hot encode your sequence\n",
    "        packed_embeds = self.encoder(x) # pack your sequence. This helps with the efficiency. Use torch function pack_padded_sequence\n",
    "        outputs, hidden = self.rnn(packed_embeds) # run you model\n",
    "        \n",
    "        # TODO: Понять нафига\n",
    "        #  out, lengths = # pad sequence back\n",
    "        \n",
    "        # Pass through a dropout layer and fully connected layer\n",
    "        out = self.dropout(outputs)\n",
    "        ## Get the output for classification.\n",
    "        out = self.decoder(out)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    \n",
    "    # инференс - режим не обучения (По сути штатная работа)\n",
    "    def inference(self, prefix='<bos> ', device=\"cpu\"):\n",
    "        tokens = torch.tensor([self.tokenizer.encode(prefix, eos=False)], device=device) # encode prefix\n",
    "        \n",
    "        # 2 stopping conditions: reaching max len or getting <eos> token\n",
    "        # Generate sequence iteratively\n",
    "        for _ in range(self.max_len - len(tokens[0])):\n",
    "            # YOUR CODE: generate sequence one by one\n",
    "            # Pass tokens through the embedding layer\n",
    "            logits, hidden = self.forward(tokens, torch.tensor([tokens.size(1)]))\n",
    "            \n",
    "            # Get the last token's logits and sample a token\n",
    "            next_token_logits = logits[:, -1, :]\n",
    "            new_token = torch.multinomial(\n",
    "                torch.nn.functional.softmax(next_token_logits, dim=-1), num_samples=1\n",
    "            )\n",
    "\n",
    "            # Append the new token\n",
    "            tokens = torch.cat([tokens, new_token], dim=1)\n",
    "\n",
    "            # Stop if the <eos> token is generated\n",
    "            if new_token.item() == self.tokenizer.encode_symbol(\"<eos>\"):\n",
    "                break\n",
    "        # Decode the token IDs back into a string\n",
    "        return self.tokenizer.decode(tokens.squeeze().tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1202bfda-3653-4644-8fcc-eda9e92e434f",
   "metadata": {},
   "source": [
    "Зададим параметры для обучения. Можете варьировать их, чтобы вам хватило ресурсов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173284d2-1d28-4235-a3ac-e25494039e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "seq_length = 512\n",
    "n_hidden = 64 #256\n",
    "n_layers = 4 #4\n",
    "drop_prob = 0.1\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329823d-abd8-4044-8206-470f07b6da62",
   "metadata": {},
   "source": [
    "Напишите функцию для одного тренировочного шага. В этом ноутбуке сам процесс обучения модели достаточно тривиален, поэтому мы не будем использовать сложные функции для обучающего цикла. Вы же, однако, можете дописать их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "737cb10c-1da8-43fc-b332-1b53f4fb6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(\n",
    "    model: CharRNN,\n",
    "    train_batch: Tuple[torch.Tensor, torch.Tensor],\n",
    "    vocab_size: int,\n",
    "    criterion: nn.Module,\n",
    "    optimizer,\n",
    "    device=\"cpu\"\n",
    ") -> torch.Tensor:\n",
    "    inputs, lengths = train_batch\n",
    "    inputs = inputs.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "\n",
    "    # Сброс градиентов\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Прямой проход\n",
    "    outputs, _ = model(inputs[:, :-1], lengths)\n",
    "\n",
    "    # Переформатирование выходов и целевых меток для расчета функции потерь\n",
    "    outputs = outputs.view(-1, vocab_size)\n",
    "    targets = inputs[:, 1:].reshape(-1)\n",
    "\n",
    "    # Вычисление функции потерь\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Обратный проход\n",
    "    loss.backward()\n",
    "\n",
    "    # Шаг оптимизации\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1055e6e-6374-4af3-b1ab-8ad8b4125664",
   "metadata": {},
   "source": [
    "Инициализируйте модель, функцию потерь и оптимизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f85fc024-7cec-4833-ac15-cafe05724003",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharRNN(tokenizer, hidden_dim=n_hidden, num_layers=n_layers, drop_prob=drop_prob)\n",
    "hidden = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a140de0c-e648-4d9f-babf-659486dbae92",
   "metadata": {},
   "source": [
    "Проверьте необученную модель: она должна выдавать бессмысленные последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37263cdf-5a6c-4612-8cf9-57105c169943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    clear_output()\n",
    "    plt.plot(range(1, len(losses) + 1), losses)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f70324-c88a-4d98-bae6-e6c5356f2025",
   "metadata": {},
   "source": [
    "Проведите обучение на протяжении нескольких эпох и выведите график лоссов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "406bfdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "174d7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57059744-44ac-4aad-86f6-f67dc2ea7600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0247 :  32%|███▏      | 400/1242 [00:40<01:25,  9.85it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)) \u001b[38;5;28;01mas\u001b[39;00m prbar:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m----> 8\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;66;03m#print(f'Done {i/len(dataloader) * 100:.2f}%, Loss: {loss:.4f}')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 17\u001b[0m, in \u001b[0;36mtraining_step\u001b[0;34m(model, train_batch, vocab_size, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Прямой проход\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m outputs, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Переформатирование выходов и целевых меток для расчета функции потерь\u001b[39;00m\n\u001b[1;32m     20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, vocab_size)\n",
      "File \u001b[0;32m~/Документы/Першин_Никольская_Нейронные_сети/.myvenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Документы/Першин_Никольская_Нейронные_сети/.myvenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 40\u001b[0m, in \u001b[0;36mCharRNN.forward\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, lengths: torch\u001b[38;5;241m.\u001b[39mTensor\n\u001b[1;32m     37\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# one-hot encode your sequence\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     packed_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x) \u001b[38;5;66;03m# pack your sequence. This helps with the efficiency. Use torch function pack_padded_sequence\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     outputs, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked_embeds\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# run you model\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# TODO: Понять нафига\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m#  out, lengths = # pad sequence back\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Pass through a dropout layer and fully connected layer\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(outputs)\n",
      "File \u001b[0;32m~/Документы/Першин_Никольская_Нейронные_сети/.myvenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Документы/Першин_Никольская_Нейронные_сети/.myvenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Документы/Першин_Никольская_Нейронные_сети/.myvenv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:917\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    914\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    920\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    921\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    with tqdm.tqdm(total=len(dataloader)) as prbar:\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            loss = training_step(model, batch, tokenizer.vocab_size, criterion, optimizer, device)\n",
    "            epoch_loss += loss\n",
    "        \n",
    "            if i % 100 == 0:\n",
    "                #print(f'Done {i/len(dataloader) * 100:.2f}%, Loss: {loss:.4f}')\n",
    "                metrics_str = f\"Loss: {round(loss, 4)} \"\n",
    "                #for k, v in metrics_dict.items():\n",
    "                #    metrics_str += f\"{k}: {round(float(v), 4)} \"\n",
    "                prbar.set_description(metrics_str)\n",
    "                prbar.update(100)\n",
    "    \n",
    "    epoch_loss /= len(dataloader)\n",
    "    losses.append(epoch_loss)\n",
    "    \n",
    "    plot_losses(losses)\n",
    "    #torch.save(model.state_dict(), \"rnn.pt\")\n",
    "    torch.save(model, \"rnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e1521",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CharRNN:\n\tsize mismatch for encoder.weight: copying a param with shape torch.Size([217, 64]) from checkpoint, the shape in current model is torch.Size([217, 256]).\n\tsize mismatch for rnn.weight_ih_l0: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.weight_hh_l0: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.bias_ih_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.bias_hh_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.weight_ih_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.weight_hh_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.bias_ih_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.bias_hh_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.weight_ih_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.weight_hh_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.bias_ih_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.bias_hh_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.weight_ih_l3: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.weight_hh_l3: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.bias_ih_l3: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.bias_hh_l3: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.weight: copying a param with shape torch.Size([217, 64]) from checkpoint, the shape in current model is torch.Size([217, 256]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#model = TheModelClass(*args, **kwargs)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrnn_backup.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Документы/Першин_Никольская_Нейронные_сети/.myvenv/lib/python3.12/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CharRNN:\n\tsize mismatch for encoder.weight: copying a param with shape torch.Size([217, 64]) from checkpoint, the shape in current model is torch.Size([217, 256]).\n\tsize mismatch for rnn.weight_ih_l0: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.weight_hh_l0: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.bias_ih_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.bias_hh_l0: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.weight_ih_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.weight_hh_l1: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.bias_ih_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.bias_hh_l1: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.weight_ih_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.weight_hh_l2: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.bias_ih_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.bias_hh_l2: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.weight_ih_l3: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.weight_hh_l3: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for rnn.bias_ih_l3: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for rnn.bias_hh_l3: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.weight: copying a param with shape torch.Size([217, 64]) from checkpoint, the shape in current model is torch.Size([217, 256])."
     ]
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load(\"rnn.pt\", weights_only=True))\n",
    "model = torch.load(\"rnn.pt\", weights_only=False)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c314e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8694a-132f-4a44-a5d3-a0f39219e55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>Пилите, Шура, пилите. Они 。¿4Мs手s¿sдaUaдaМЦ$¿Х¿ЕдХдa€s̈¿″。Us№sns。¿4nsKМ。̈。̈¿Us̈4a″ЕЕ¿s№4。цa。№|<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они 。¿Х¿果№s¿м。Мsц。Ua¿Х¿Ц4ЕU|<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они Е¿K。д¿№a″Аa手¿с¿ЦsЦ。€a¿。т。¿ц¿nсU。¿̈ЕММЕs″。ns¿4sМ。д″。。¿4s№s̈с给¿м№s¿ns“€a。№¿Ц№na″a应<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они Е¿4nЕ€a。№¿дsМs№s。¿″。€sЦ№a№sU¿s¿Мсм 。̈¿Ц№sns″。|<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они Е¿Е″д。nЕ№.h<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они Е¿МxKsц″ЕUsц¿4sЦс€с№¿U¿№。М。Уs″|||<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они 。Ц№。nЕм。ЦUs̈Е¿%sxëс¿Ыnl̈s¿s№¿Мx€。Ё给¿ЦsЦ。€Е¿€s¿̈sna¿″sм.x¿€nсë¿n。 ЕМ¿̈。″$¿UсnЕ№.¿Е¿ЦцЕ″¿″a¿Uс4Еx¿ц¿ UsМ.″s̈|<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они 。М。h<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они Е¿1并¿举¿̈Е″с№¿KlМ¿€。″.ëЕ给¿。ës¿sKns4a№.¿″。¿Usn̈。″.UЕЁ|<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они 。МЕ¿″。¿4s̈sëa№.¿цЦ№a№.应<eos>']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.inference(\"Пилите, Шура, пилите. Они \", device=device) for _ in range(10)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef889dd2-fde2-429c-9c61-f5a93517bd3f",
   "metadata": {},
   "source": [
    "Теперь попробуем написать свой собственный RNN. Это будет довольно простая модель с одним слоем.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe4954-e2b5-43c5-9bb6-0b2a5cc2cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: custom model nn.Module, changed CharRNN, etc\n",
    "\n",
    "class CustomCharRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        hidden_dim: int = 256,\n",
    "        num_layers: int = 1,\n",
    "        drop_prob: float = 0.5,\n",
    "        max_len: int = 512,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        self.max_len = max_len\n",
    "        # create mappings\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        ## define the LSTM, dropout and fully connected layers\n",
    "        self.encoder = nn.Embedding(self.tokenizer.vocab_size, self.hidden_dim)\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=self.drop_prob)\n",
    "        self.decoder = nn.Linear(\n",
    "            in_features=self.hidden_dim,\n",
    "            out_features=self.tokenizer.vocab_size,\n",
    "        )\n",
    "\n",
    "    # Forward - это проход вперёд по слою\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, lengths: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # one-hot encode your sequence\n",
    "        packed_embeds = self.encoder(x) # pack your sequence. This helps with the efficiency. Use torch function pack_padded_sequence\n",
    "        outputs, hidden = self.rnn(packed_embeds) # run you model\n",
    "        \n",
    "        # TODO: Понять нафига\n",
    "        #  out, lengths = # pad sequence back\n",
    "        \n",
    "        # Pass through a dropout layer and fully connected layer\n",
    "        out = self.dropout(outputs)\n",
    "        ## Get the output for classification.\n",
    "        out = self.decoder(out)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    \n",
    "    # инференс - режим не обучения (По сути штатная работа)\n",
    "    def inference(self, prefix='<bos> ', device=\"cpu\"):\n",
    "        tokens = torch.tensor([self.tokenizer.encode(prefix, eos=False)], device=device) # encode prefix\n",
    "        \n",
    "        # 2 stopping conditions: reaching max len or getting <eos> token\n",
    "        # Generate sequence iteratively\n",
    "        for _ in range(self.max_len - len(tokens[0])):\n",
    "            # YOUR CODE: generate sequence one by one\n",
    "            # Pass tokens through the embedding layer\n",
    "            logits, hidden = self.forward(tokens, torch.tensor([tokens.size(1)]))\n",
    "            \n",
    "            # Get the last token's logits and sample a token\n",
    "            next_token_logits = logits[:, -1, :]\n",
    "            new_token = torch.multinomial(\n",
    "                torch.nn.functional.softmax(next_token_logits, dim=-1), num_samples=1\n",
    "            )\n",
    "\n",
    "            # Append the new token\n",
    "            tokens = torch.cat([tokens, new_token], dim=1)\n",
    "\n",
    "            # Stop if the <eos> token is generated\n",
    "            if new_token.item() == self.tokenizer.encode_symbol(\"<eos>\"):\n",
    "                break\n",
    "        # Decode the token IDs back into a string\n",
    "        return self.tokenizer.decode(tokens.squeeze().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbce99f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_rnn = CustomCharRNN(tokenizer, hidden_dim=n_hidden, num_layers=1, drop_prob=drop_prob).to(device)\n",
    "hidden = None\n",
    "optimizer2 = torch.optim.Adam(real_rnn.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcec5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "num_epochs = 8\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    with tqdm.tqdm(total=len(dataloader)) as prbar:\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            loss = training_step(real_rnn, batch, tokenizer.vocab_size, criterion, optimizer2, device)\n",
    "            epoch_loss += loss\n",
    "        \n",
    "            if i % 100 == 0:\n",
    "                metrics_str = f\"Loss: {round(loss, 4)} \"\n",
    "                prbar.set_description(metrics_str)\n",
    "                prbar.update(100)\n",
    "    \n",
    "    epoch_loss /= len(dataloader)\n",
    "    losses.append(epoch_loss)\n",
    "    \n",
    "    plot_losses(losses)\n",
    "    torch.save(real_rnn.state_dict(), \"real_rnn2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36120513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>Пилите, Шура, пилите. Они вас два теперь тестошек и клефаума!<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они призеть, в какая<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они не ни тут й*гу тогда и томленны.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они есть бенсеровали. Содевоков.Со них остатости аразма и.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они недеть чечекой нопусшивал крагамазы.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они подскорь и зао ссущия bАНглрараху... Кулик?- Что-то дамся мужяне. Кер, когда выокзистать читал.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они как думаешь созразать у вас.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они шира. Он на подспвочный?- Скажят, а чите!!<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они дора дуя, того детьшим о огиттешемосс - до санко прошло.<eos>',\n",
       " '<bos>Пилите, Шура, пилите. Они есть не кондать. У тункизнебся докета женило!<eos>']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.inference(\"Пилите, Шура, пилите. Они \", device=device) for _ in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2beef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
