{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Iterable, Tuple\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.distributions.categorical import Categorical\n",
    "import tqdm\n",
    "import re\n",
    "from functools import cmp_to_key\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "with open(\"../../datasets/anek_djvu.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|startoftext|>Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже!\\n\\n<|startoftext|>- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...\\n\\n<|startoftext|>- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От со'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[118:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбитие на анектоды\n",
    "def cut_data(text):\n",
    "    return text.replace(\"\\n\\n\", \"\").split(\"<|startoftext|>\")[1:]\n",
    "cut_text = cut_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Одна мамаша жалуется другой:- Васенька у нас поздний ребенок: раньше двенадцати ночи домой не приходит.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "cut_text[random.randint(0, 31000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_symbols = {'\\n', ':', ';', '=', '>', '?', '@', ' ', '!', '\"', '#', '$', '%', '&', '\\'', '*', '+', ',', '\\-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ё', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ъ', 'Ы', 'Ь', 'Э', 'Ю', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё'}\n",
    "\n",
    "allowed_symbols2 = {'\\n', ':', ';', '=', '>', '?', '@', ' ', '!', '\"', '#', '$', '%', '&', '\\'', '*', '+', ',', '\\-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ё', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ъ', 'Ы', 'Ь', 'Э', 'Ю', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё'}\n",
    "\n",
    "allowed_symbols2_rus = {':', ';', '?', '@', ' ', '!', '\"', '#', '$', '%', '*', '+', ',', '\\-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9','Ё', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ъ', 'Ы', 'Ь', 'Э', 'Ю', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_MAX_TOKEN_LEN = 2\n",
    "GLOBAL_MAX_TOKEN_COUNT = 61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4. RNN\n",
    "## Задача 1. 3 балла\n",
    "Обучите RNN/LSTM на данных из классной работы, используя другой токенайзер. Опишите его и свой выбор. Покажите разницу в генерации моделей, обученных с разными токенайзерами.\n",
    "## {*} Задача 1.1 2 балла\n",
    "Напишите свой токенайзер вручную, с использованием только библиотек numpy, torch, sklearn, stats, опционально других пакетов, не предоставляющих готовые инструменты токенизации и т.п., за исключением предобработки текста (лемматизация, стеминг и т.д.) . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Tokenizer:\n",
    "    def __init__(self, cut_text, max_count_token: int = 512, max_token_len = 2, allowed_s = allowed_symbols2_rus):\n",
    "        self.allowed_s = allowed_s\n",
    "        self.max_token_len = max_token_len\n",
    "        self.text = cut_text\n",
    "        self.max_count_token = max_count_token\n",
    "        self.specials = {'<pad>':999999, '<bos>':999999, '<eos>':999999}\n",
    "        \n",
    "        self.create_vocab(\"\".join(self.text))\n",
    "        \n",
    "    def token_compare(self, item1:dict, item2:dict):\n",
    "        if ((\" \" in item1[0] or \" \" in item2[0]) and not(item1[0] == \" \" or item2[0] == \" \")):\n",
    "            #print(item1[0], item2[0])\n",
    "            if (\" \" in item1[0] and \" \" in item2[0]):\n",
    "                return 0\n",
    "            elif (\" \" in item1[0]):\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        else:\n",
    "            #if (len(item2[0]) > len(item1[0]) and item2[0])\n",
    "            return item2[1] - item1[1]\n",
    "    \n",
    "    def create_vocab(self, text: str):\n",
    "        regex = r'[^' + \"\".join(self.allowed_s).lower() + ']'\n",
    "        reg = re.compile(regex)\n",
    "        text = reg.sub('', text.replace('ё', 'е'))\n",
    "    \n",
    "        my_dict = {}\n",
    "        i = 1\n",
    "        text_len = len(text)\n",
    "        for index in range(0, text_len - i + 1):\n",
    "            token = text[index:index+i]\n",
    "            if not token in my_dict:\n",
    "                my_dict[token]=9999999\n",
    "    \n",
    "        text = re.sub(r'[^а-я ]', '', text)\n",
    "\n",
    "    \n",
    "        for i in range (2, self.max_token_len+1):\n",
    "            text_len = len(text)\n",
    "            for index in range(0, text_len - i + 1):\n",
    "                token = text[index:index+i]\n",
    "                if token in my_dict:\n",
    "                    my_dict[token]+=1\n",
    "                else:\n",
    "                    my_dict[token]=1\n",
    "                # Assign unique IDs to tokens\n",
    "        \n",
    "        # отсортировали по принципу с пробелом в конец, 1 символ в начало,\n",
    "        #   остальное по частоте, чтобы лего сделать crop\n",
    "        sorted_tokens = dict(sorted(my_dict.items(), key=cmp_to_key(self.token_compare))[:self.max_count_token])\n",
    "        # Сортируем по длине токена, а после по частоте\n",
    "        sorted_tokens.update(self.specials)\n",
    "\n",
    "        sorted_tokens = sorted(sorted_tokens.items(), key=lambda x: (-len(x[0]), -x[1]))\n",
    "\n",
    "        self.token_to_id = {token: idx for idx, (token, _) in enumerate(sorted_tokens)}\n",
    "        self.id_to_token = {idx: token for token, idx in self.token_to_id.items()}\n",
    "    \n",
    "    def _add_special(self, symbol) -> None:\n",
    "        # add special characters to yuor dicts\n",
    "        sym_num = len(self.token_to_id)\n",
    "        self.token_to_id[symbol] = sym_num\n",
    "        self.id_to_token[sym_num] = symbol\n",
    "    \n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.token_to_id) # your code\n",
    "    \n",
    "    def decode_symbol(self, el):\n",
    "        return self.id_to_token[el]\n",
    "        \n",
    "    def encode_symbol(self, el):\n",
    "        return self.token_to_id[el]\n",
    "\n",
    "    #@property\n",
    "    def tokenize(self, text: str):\n",
    "        \"\"\"\n",
    "        Tokenizes the input text into numbers using the built dictionary.\n",
    "        :param text: Input text to tokenize.\n",
    "        :return: A list of token IDs representing the text.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.token_to_id:\n",
    "            raise ValueError(\"Tokenizer dictionary is empty. Call 'build_dict' first.\")\n",
    "        \n",
    "        tokens = []\n",
    "        i = 0\n",
    "        while i < len(text):\n",
    "            match = None\n",
    "            # Try to find the longest matching token\n",
    "            for size in range(max(self.max_token_len, 5), 0, -1):\n",
    "                if i + size <= len(text):\n",
    "                    substring = text[i:i + size]\n",
    "                    if substring in self.token_to_id:\n",
    "                        match = substring\n",
    "                        break\n",
    "            \n",
    "            if match:\n",
    "                tokens.append(self.token_to_id[match])\n",
    "                i += len(match)  # Move past the matched token\n",
    "            else:\n",
    "                # If no match, handle single characters (fallback)\n",
    "                tokens.append(self.token_to_id[text[i]])\n",
    "                i += 1\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def detokenize(self, token_ids):\n",
    "        \"\"\"\n",
    "        Converts token IDs back into the original text using the dictionary.\n",
    "        :param token_ids: A list of token IDs.\n",
    "        :return: The reconstructed text.\n",
    "        \"\"\"\n",
    "        return ''.join(self.id_to_token[token_id] for token_id in token_ids)\n",
    "    \n",
    "    def encode(self, chars, eos=True):\n",
    "        regex = r'[^' + \"\".join(self.allowed_s) + ']'\n",
    "        reg = re.compile(regex)\n",
    "        chars = reg.sub('', chars.lower().replace('ё', 'е'))\n",
    "\n",
    "        if eos:\n",
    "            chars = '<bos>' + chars + '<eos>'\n",
    "        else:\n",
    "            chars = '<bos>' + chars\n",
    "        return self.tokenize(chars)\n",
    "\n",
    "    def decode(self, idx):\n",
    "        return self.detokenize(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokesDataset(Dataset):\n",
    "    def __init__(self, tokenizer, cut_text, max_len: int = 512):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cut_text = cut_text\n",
    "        self.pad_index = self.tokenizer.encode_symbol(\"<pad>\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cut_text)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        #  в идеале запонлять паддингами лучше в другом месте\n",
    "        encoded = self.tokenizer.encode(self.cut_text[item])[:self.max_len]\n",
    "        padded = torch.full((self.max_len, ), self.pad_index, dtype=torch.long)\n",
    "        padded[:len(encoded)] = torch.tensor(encoded)\n",
    "        # pad your sequence and make a final sample. You can skip padding and pad sequences with torch special method.\n",
    "        return padded, len(encoded)\n",
    "\n",
    "# Optionally add new methods to your dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2. 3 балла\n",
    "Реализуйте с помощью только torch/numpy слой RNN, обучите его на данных из классной работы и, опционально, своих данных. Покажите, что модель обучается\n",
    "## {*} Задача 2.1 +1 балл\n",
    "За реализацию слоев GRU/LSTM/bidirectional RNN, многослойной модели по +1 баллу к базовым (даже если ванильная RNN не реализована)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "```python\n",
    "self.rnn = nn.RNN(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вопроc: зачем num_layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRNN(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_size:int,\n",
    "            seq_len:int):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_size = hidden_size        \n",
    "        \n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        \n",
    "\n",
    "        # Кратко поясню: сходимости не было, был либо разброс,\n",
    "        #   либо затухание, поэтому nn\n",
    "\n",
    "        self.Lh = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Lx = nn.Linear(hidden_size, hidden_size)\n",
    "        #self.Wh = torch.rand(hidden_size, hidden_size, dtype=torch.float32, requires_grad=True)\n",
    "        #self.Wx = torch.rand(hidden_size, hidden_size, dtype=torch.float32, requires_grad=True)\n",
    "        self.Lh = torch.nn.utils.spectral_norm(self.Lh)\n",
    "        self.Lx = torch.nn.utils.spectral_norm(self.Lx)\n",
    "\n",
    "        self.bh = torch.rand((1, hidden_size), dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros((1, self.hidden_size), dtype=torch.float32)\n",
    "        \n",
    "        h_t_minus_1 = h_0\n",
    "        h_t = h_0\n",
    "        output = []\n",
    "        for t in range(len(x[0])):\n",
    "            #h_t = torch.tanh(\n",
    "            #    x[t] @ self.Wx.T\n",
    "            #    + h_t_minus_1 @ self.Wh.T\n",
    "            #    + self.bh\n",
    "            #)\n",
    "            h_t = self.Lh(h_t_minus_1) + self.Lx(x[0][t]) + self.bh\n",
    "            output.append(h_t)\n",
    "            h_t_minus_1 = h_t\n",
    "        \n",
    "        output = torch.stack(output)\n",
    "        output = output.transpose(0, 1)\n",
    "        return output, None #h_t.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        hidden_dim: int = 256,\n",
    "        num_layers: int = 2,\n",
    "        drop_prob: float = 0.5,\n",
    "        max_text_len: int = 512, # Максимальная длина сообщения в символах\n",
    "    ) -> None:\n",
    "        '''    hidden_dim: Длинна словаря (количество ожидаемых признаков во входных данных x)\n",
    "               max_len: Максимальная длина сообщения в символах\n",
    "        '''\n",
    "        \n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        self.max_text_len = max_text_len\n",
    "        # create mappings\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        ## define the LSTM, dropout and fully connected layers\n",
    "        self.encoder = nn.Embedding(self.tokenizer.vocab_size, self.hidden_dim)\n",
    "        self.rnn = CustomRNN(\n",
    "            hidden_size=self.hidden_dim,\n",
    "            seq_len=4\n",
    "        )\n",
    "        #self.rnn = nn.LSTM(\n",
    "        #    input_size=self.hidden_dim,\n",
    "        #    hidden_size=self.hidden_dim,\n",
    "        #    num_layers=1,\n",
    "        #    batch_first=True,\n",
    "        #    dropout=self.drop_prob\n",
    "        #)\n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(p=self.drop_prob)\n",
    "        self.decoder = nn.Linear(\n",
    "            in_features=self.hidden_dim,\n",
    "            out_features=self.tokenizer.vocab_size,\n",
    "        )\n",
    "\n",
    "    # Forward - это проход вперёд по слою\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, lengths: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # one-hot encode your sequence\n",
    "        packed_embeds = self.encoder(x) # pack your sequence. This helps with the efficiency. Use torch function pack_padded_sequence\n",
    "        outputs, hidden = self.rnn(packed_embeds) # run you model\n",
    "        #print(outputs)\n",
    "        # TODO: Понять нафига\n",
    "        #  out, lengths = # pad sequence back\n",
    "        \n",
    "        # Pass through a dropout layer and fully connected layer\n",
    "        out = self.dropout(outputs)\n",
    "        ## Get the output for classification.\n",
    "        out = self.decoder(out)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    \n",
    "    # инференс - режим не обучения (По сути штатная работа)\n",
    "    def inference(self, prefix='<bos> ', device=\"cpu\"):\n",
    "        tokens = torch.tensor([self.tokenizer.encode(prefix, eos=False)], device=device) # encode prefix\n",
    "        \n",
    "        # 2 stopping conditions: reaching max len or getting <eos> token\n",
    "        # Generate sequence iteratively\n",
    "        for _ in range(self.max_text_len - len(tokens[0])):\n",
    "            # YOUR CODE: generate sequence one by one\n",
    "            # Pass tokens through the embedding layer\n",
    "            logits, hidden = self.forward(tokens, torch.tensor([tokens.size(1)]))\n",
    "            \n",
    "            # Get the last token's logits and sample a token\n",
    "            next_token_logits = logits[:, -1, :]\n",
    "            new_token = torch.multinomial(\n",
    "                torch.nn.functional.softmax(next_token_logits, dim=-1), num_samples=1\n",
    "            )\n",
    "\n",
    "            # Append the new token\n",
    "            tokens = torch.cat([tokens, new_token], dim=1)\n",
    "\n",
    "            # Stop if the <eos> token is generated\n",
    "            if new_token.item() == self.tokenizer.encode_symbol(\"<eos>\"):\n",
    "                break\n",
    "        # Decode the token IDs back into a string\n",
    "        return self.tokenizer.decode(tokens.squeeze().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(\n",
    "    model: CharRNN,\n",
    "    train_batch: Tuple[torch.Tensor, torch.Tensor],\n",
    "    vocab_size: int,\n",
    "    criterion: nn.Module,\n",
    "    optimizer,\n",
    "    device=\"cpu\"\n",
    ") -> torch.Tensor:\n",
    "    inputs, lengths = train_batch\n",
    "    inputs = inputs.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "\n",
    "    # Сброс градиентов\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Прямой проход\n",
    "    outputs, _ = model(inputs[:, :-1], lengths)\n",
    "\n",
    "    # Переформатирование выходов и целевых меток для расчета функции потерь\n",
    "    outputs = outputs.view(-1, vocab_size)\n",
    "    targets = inputs[:, 1:].reshape(-1)\n",
    "\n",
    "    # Вычисление функции потерь\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Обратный проход\n",
    "    loss.backward()\n",
    "\n",
    "    # Шаг оптимизации\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    clear_output()\n",
    "    plt.plot(range(1, len(losses) + 1), losses)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "n_hidden = 512 # 10+3 #64 #256\n",
    "n_layers = 1 #4\n",
    "drop_prob = 0.1\n",
    "lr = 0.001\n",
    "\n",
    "num_epochs = 1\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Custom_Tokenizer(cut_text,\n",
    "                             max_count_token=GLOBAL_MAX_TOKEN_COUNT,\n",
    "                             max_token_len = GLOBAL_MAX_TOKEN_LEN,\n",
    "                             allowed_s = allowed_symbols2_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharRNN(tokenizer, hidden_dim=n_hidden, num_layers=n_layers, drop_prob=drop_prob)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = JokesDataset(tokenizer, cut_text, 256)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1, 33, 37, 12, 38, 16, 20, 12, 15,  8, 10, 11, 12, 10, 44,  9, 24, 12,\n",
       "          25,  6, 13, 10, 19, 13, 12, 24, 15, 45,  6,  4, 10, 22, 24,  6,  5,  6,\n",
       "          43, 10,  7, 16, 11, 25, 33,  7, 10, 16, 10, 22, 24,  6, 15, 14, 24, 10,\n",
       "          24, 33,  9, 12, 20,  6, 13, 31,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0]]),\n",
       " tensor([63])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 3.8306 :   0%|          | 100/124155 [00:00<05:46, 358.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4594, -0.0243,  0.8459,  ...,  0.1624,  0.3805,  1.4520],\n",
      "         [ 0.2756,  0.3621,  0.1218,  ...,  0.5622,  0.6335, -0.7251],\n",
      "         [ 1.7405,  1.3530,  0.8900,  ...,  0.8764, -0.4259,  0.3965],\n",
      "         ...,\n",
      "         [ 0.7019,  1.2146,  0.4924,  ...,  0.2532,  0.6365, -0.0549],\n",
      "         [ 0.7019,  1.2146,  0.4924,  ...,  0.2532,  0.6365, -0.0549],\n",
      "         [ 0.7019,  1.2146,  0.4924,  ...,  0.2532,  0.6365, -0.0549]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4143,  0.1880,  0.7689,  ...,  0.2029,  0.4842,  1.2518],\n",
      "         [ 0.8471,  1.5932, -0.2649,  ..., -0.3340, -0.6254,  0.7413],\n",
      "         [ 0.5439,  1.0712,  1.0177,  ...,  1.5379,  0.8573,  0.0617],\n",
      "         ...,\n",
      "         [ 1.4487,  0.9102,  1.4192,  ..., -0.1279, -0.6524,  1.2155],\n",
      "         [ 1.4487,  0.9102,  1.4192,  ..., -0.1279, -0.6524,  1.2155],\n",
      "         [ 1.4487,  0.9102,  1.4192,  ..., -0.1279, -0.6524,  1.2155]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4068,  0.1791,  0.7782,  ...,  0.2141,  0.4905,  1.2460],\n",
      "         [ 0.2742,  1.4283,  1.0497,  ...,  0.5396,  0.9061,  0.9893],\n",
      "         [ 0.1992,  1.2273,  0.9874,  ..., -0.5220, -0.8316,  0.2354],\n",
      "         ...,\n",
      "         [ 1.4868,  0.7113,  1.5557,  ..., -0.3809, -1.0161,  1.6845],\n",
      "         [ 1.4868,  0.7113,  1.5557,  ..., -0.3809, -1.0161,  1.6845],\n",
      "         [ 1.4868,  0.7113,  1.5557,  ..., -0.3809, -1.0161,  1.6845]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3910,  0.2401,  0.7477,  ...,  0.1940,  0.5244,  1.1823],\n",
      "         [ 0.2880,  0.7559,  0.4593,  ...,  0.4418, -0.0238, -0.1799],\n",
      "         [ 0.8638,  0.9960,  0.0580,  ..., -0.2944, -0.3182,  0.5787],\n",
      "         ...,\n",
      "         [ 1.3084,  0.6237,  1.4691,  ..., -0.4645, -1.0466,  1.8187],\n",
      "         [ 1.3084,  0.6237,  1.4691,  ..., -0.4645, -1.0466,  1.8187],\n",
      "         [ 1.3084,  0.6237,  1.4691,  ..., -0.4645, -1.0466,  1.8187]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3765,  0.2663,  0.7226,  ...,  0.1915,  0.5423,  1.1461],\n",
      "         [-0.0921,  0.9760, -0.2498,  ...,  0.5444,  0.4245,  0.4757],\n",
      "         [ 0.8500,  0.3664,  0.9725,  ...,  0.3800,  0.9059,  0.2700],\n",
      "         ...,\n",
      "         [ 1.0974,  0.5650,  1.3240,  ..., -0.4775, -1.0007,  1.8429],\n",
      "         [ 1.0974,  0.5650,  1.3240,  ..., -0.4775, -1.0007,  1.8429],\n",
      "         [ 1.0974,  0.5650,  1.3240,  ..., -0.4775, -1.0007,  1.8429]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 3.6483e-01,  2.8339e-01,  7.0717e-01,  ...,  1.9768e-01,\n",
      "           5.5425e-01,  1.1193e+00],\n",
      "         [ 4.3975e-01,  6.0700e-01,  1.5633e-01,  ...,  4.3780e-01,\n",
      "           4.8300e-01,  2.9134e-01],\n",
      "         [ 5.0011e-01,  7.1868e-01, -6.2168e-05,  ...,  9.2849e-01,\n",
      "           4.6543e-02,  1.0605e+00],\n",
      "         ...,\n",
      "         [ 9.3610e-01,  5.0550e-01,  1.1879e+00,  ..., -4.4793e-01,\n",
      "          -9.4363e-01,  1.8476e+00],\n",
      "         [ 9.3610e-01,  5.0550e-01,  1.1879e+00,  ..., -4.4793e-01,\n",
      "          -9.4363e-01,  1.8476e+00],\n",
      "         [ 9.3610e-01,  5.0550e-01,  1.1879e+00,  ..., -4.4793e-01,\n",
      "          -9.4363e-01,  1.8476e+00]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3565,  0.2922,  0.6948,  ...,  0.2063,  0.5665,  1.1010],\n",
      "         [-0.0688,  1.7998,  0.2378,  ..., -0.2646,  0.2695,  0.6201],\n",
      "         [-0.0037,  0.9750,  0.7529,  ..., -0.5258, -0.0589,  0.2031],\n",
      "         ...,\n",
      "         [ 0.7987,  0.4402,  1.0564,  ..., -0.4645, -0.9015,  1.8441],\n",
      "         [ 0.7987,  0.4402,  1.0564,  ..., -0.4645, -0.9015,  1.8441],\n",
      "         [ 0.7987,  0.4402,  1.0564,  ..., -0.4645, -0.9015,  1.8441]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3517,  0.2984,  0.6821,  ...,  0.2089,  0.5766,  1.0875],\n",
      "         [ 0.3183,  0.4851,  0.0997,  ...,  0.4686,  0.4765,  0.3487],\n",
      "         [ 0.6218, -0.5168, -0.6122,  ...,  0.3829,  0.0162,  0.1522],\n",
      "         ...,\n",
      "         [ 0.7038,  0.3911,  0.9522,  ..., -0.4937, -0.8636,  1.8351],\n",
      "         [ 0.7038,  0.3911,  0.9522,  ..., -0.4937, -0.8636,  1.8351],\n",
      "         [ 0.7038,  0.3911,  0.9522,  ..., -0.4937, -0.8636,  1.8351]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3478,  0.3027,  0.6729,  ...,  0.2134,  0.5856,  1.0772],\n",
      "         [ 0.1948,  0.2182,  0.1905,  ...,  0.2219,  0.4919,  0.1545],\n",
      "         [ 0.3962, -0.0136,  0.2361,  ...,  0.8084,  0.1689,  1.0913],\n",
      "         ...,\n",
      "         [ 0.6478,  0.3423,  0.8703,  ..., -0.5359, -0.8317,  1.8331],\n",
      "         [ 0.6478,  0.3423,  0.8703,  ..., -0.5359, -0.8317,  1.8331],\n",
      "         [ 0.6478,  0.3423,  0.8703,  ..., -0.5359, -0.8317,  1.8331]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3465,  0.3037,  0.6685,  ...,  0.2213,  0.5929,  1.0703],\n",
      "         [-0.1765,  0.6408, -0.2857,  ...,  0.4692,  0.4061,  0.5791],\n",
      "         [-0.2002,  0.5340,  0.4417,  ..., -0.3625, -0.1763,  0.2998],\n",
      "         ...,\n",
      "         [ 0.6219,  0.3070,  0.8128,  ..., -0.5858, -0.8059,  1.8273],\n",
      "         [ 0.6219,  0.3070,  0.8128,  ..., -0.5858, -0.8059,  1.8273],\n",
      "         [ 0.6219,  0.3070,  0.8128,  ..., -0.5858, -0.8059,  1.8273]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3472,  0.3016,  0.6682,  ...,  0.2307,  0.5982,  1.0663],\n",
      "         [ 0.4874,  0.3145,  0.4652,  ..., -0.0275,  0.6749,  0.4078],\n",
      "         [-0.3169, -0.1534,  0.0877,  ..., -0.0076,  0.4820,  0.2305],\n",
      "         ...,\n",
      "         [ 0.6159,  0.2836,  0.7638,  ..., -0.6423, -0.7859,  1.8222],\n",
      "         [ 0.6159,  0.2836,  0.7638,  ..., -0.6423, -0.7859,  1.8222],\n",
      "         [ 0.6159,  0.2836,  0.7638,  ..., -0.6423, -0.7859,  1.8222]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3476,  0.2982,  0.6680,  ...,  0.2418,  0.6028,  1.0636],\n",
      "         [ 0.0632,  0.7508, -0.0447,  ...,  0.8207,  0.4263,  0.1728],\n",
      "         [ 0.1380, -0.1149, -0.2407,  ...,  0.3350, -0.2297,  0.5213],\n",
      "         ...,\n",
      "         [ 0.6173,  0.2768,  0.7362,  ..., -0.6893, -0.7715,  1.8213],\n",
      "         [ 0.6173,  0.2768,  0.7362,  ..., -0.6893, -0.7715,  1.8213],\n",
      "         [ 0.6173,  0.2768,  0.7362,  ..., -0.6893, -0.7715,  1.8213]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3471,  0.2933,  0.6674,  ...,  0.2492,  0.6071,  1.0623],\n",
      "         [ 0.0121,  0.9585,  0.4556,  ..., -0.4669, -0.2823,  0.3421],\n",
      "         [ 0.2796, -0.0479,  0.1465,  ...,  0.7234,  0.4535,  1.3349],\n",
      "         ...,\n",
      "         [ 0.6197,  0.2742,  0.7119,  ..., -0.7056, -0.7611,  1.8223],\n",
      "         [ 0.6197,  0.2742,  0.7119,  ..., -0.7056, -0.7611,  1.8223],\n",
      "         [ 0.6197,  0.2742,  0.7119,  ..., -0.7056, -0.7611,  1.8223]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3462,  0.2904,  0.6677,  ...,  0.2548,  0.6112,  1.0616],\n",
      "         [ 0.1437,  0.1811,  0.0662,  ...,  0.0942,  0.4784,  0.2133],\n",
      "         [ 0.2850, -0.2340,  0.0299,  ...,  0.6532,  0.3280,  1.1424],\n",
      "         ...,\n",
      "         [ 0.6269,  0.2759,  0.6979,  ..., -0.7380, -0.7548,  1.8310],\n",
      "         [ 0.6269,  0.2759,  0.6979,  ..., -0.7380, -0.7548,  1.8310],\n",
      "         [ 0.6269,  0.2759,  0.6979,  ..., -0.7380, -0.7548,  1.8310]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3463,  0.2872,  0.6698,  ...,  0.2651,  0.6148,  1.0611],\n",
      "         [ 0.1329,  0.1791,  0.0409,  ...,  0.0788,  0.4697,  0.2159],\n",
      "         [ 0.2687, -0.2555,  0.0043,  ...,  0.6395,  0.3429,  1.1548],\n",
      "         ...,\n",
      "         [ 0.6292,  0.2732,  0.6895,  ..., -0.7757, -0.7529,  1.8414],\n",
      "         [ 0.6292,  0.2732,  0.6895,  ..., -0.7757, -0.7529,  1.8414],\n",
      "         [ 0.6292,  0.2732,  0.6895,  ..., -0.7757, -0.7529,  1.8414]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3472,  0.2818,  0.6744,  ...,  0.2754,  0.6182,  1.0605],\n",
      "         [ 0.1218,  0.1816,  0.0255,  ...,  0.0836,  0.4600,  0.2169],\n",
      "         [ 0.2531, -0.2741, -0.0086,  ...,  0.6549,  0.3478,  1.1585],\n",
      "         ...,\n",
      "         [ 0.6342,  0.2789,  0.6951,  ..., -0.7924, -0.7585,  1.8520],\n",
      "         [ 0.6342,  0.2789,  0.6951,  ..., -0.7924, -0.7585,  1.8520],\n",
      "         [ 0.6342,  0.2789,  0.6951,  ..., -0.7924, -0.7585,  1.8520]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3489,  0.2748,  0.6816,  ...,  0.2860,  0.6212,  1.0602],\n",
      "         [ 0.1092,  0.1827,  0.0178,  ...,  0.0762,  0.4508,  0.2138],\n",
      "         [ 0.2354, -0.2950, -0.0077,  ...,  0.6450,  0.3489,  1.1516],\n",
      "         ...,\n",
      "         [ 0.6383,  0.2894,  0.7115,  ..., -0.8247, -0.7687,  1.8595],\n",
      "         [ 0.6383,  0.2894,  0.7115,  ..., -0.8247, -0.7687,  1.8595],\n",
      "         [ 0.6383,  0.2894,  0.7115,  ..., -0.8247, -0.7687,  1.8595]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3499,  0.2679,  0.6899,  ...,  0.3000,  0.6236,  1.0608],\n",
      "         [ 0.5715, -0.2517, -0.2813,  ..., -0.1216, -0.0628,  0.3068],\n",
      "         [-0.5655,  0.3853, -0.3011,  ..., -0.6039,  0.5944,  0.8221],\n",
      "         ...,\n",
      "         [ 0.6418,  0.3028,  0.7328,  ..., -0.8570, -0.7802,  1.8690],\n",
      "         [ 0.6418,  0.3028,  0.7328,  ..., -0.8570, -0.7802,  1.8690],\n",
      "         [ 0.6418,  0.3028,  0.7328,  ..., -0.8570, -0.7802,  1.8690]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3507,  0.2633,  0.6981,  ...,  0.3133,  0.6260,  1.0614],\n",
      "         [-0.3908,  0.7193, -0.1370,  ..., -0.4186,  0.3218,  0.9399],\n",
      "         [-0.4318,  0.0971, -0.5763,  ...,  0.4906,  0.6714,  0.6325],\n",
      "         ...,\n",
      "         [ 0.6530,  0.3195,  0.7585,  ..., -0.9004, -0.7905,  1.8783],\n",
      "         [ 0.6530,  0.3195,  0.7585,  ..., -0.9004, -0.7905,  1.8783],\n",
      "         [ 0.6530,  0.3195,  0.7585,  ..., -0.9004, -0.7905,  1.8783]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3529,  0.2575,  0.7052,  ...,  0.3271,  0.6281,  1.0618],\n",
      "         [-0.1298,  1.0828,  0.0596,  ..., -0.7180,  0.2876,  0.5921],\n",
      "         [-0.1942,  0.5911,  0.2216,  ..., -0.6133, -0.0156,  0.2652],\n",
      "         ...,\n",
      "         [ 0.3128, -0.0970, -0.2183,  ..., -0.5186, -0.2930,  0.8505],\n",
      "         [-0.4737,  0.2530, -0.3054,  ...,  0.0082,  0.7245,  0.6884],\n",
      "         [-0.4857,  0.3388, -0.6693,  ...,  0.5834,  0.5726,  0.5417]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3561,  0.2513,  0.7109,  ...,  0.3371,  0.6300,  1.0636],\n",
      "         [ 0.4345,  0.1226,  0.4349,  ..., -0.3154,  0.5474,  0.4177],\n",
      "         [-0.7081, -0.1053, -0.2974,  ..., -0.0780,  0.8677,  0.7319],\n",
      "         ...,\n",
      "         [ 0.6828,  0.3566,  0.8178,  ..., -0.9594, -0.8037,  1.9007],\n",
      "         [ 0.6828,  0.3566,  0.8178,  ..., -0.9594, -0.8037,  1.9007],\n",
      "         [ 0.6828,  0.3566,  0.8178,  ..., -0.9594, -0.8037,  1.9007]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3577,  0.2460,  0.7159,  ...,  0.3487,  0.6317,  1.0654],\n",
      "         [ 0.1852,  0.3487,  0.4563,  ...,  0.0805, -0.3708,  0.8023],\n",
      "         [ 0.0976,  0.0356,  0.0604,  ..., -0.0523,  0.3358,  0.7720],\n",
      "         ...,\n",
      "         [ 0.6979,  0.3725,  0.8424,  ..., -0.9850, -0.8096,  1.9136],\n",
      "         [ 0.6979,  0.3725,  0.8424,  ..., -0.9850, -0.8096,  1.9136],\n",
      "         [ 0.6979,  0.3725,  0.8424,  ..., -0.9850, -0.8096,  1.9136]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3597,  0.2417,  0.7215,  ...,  0.3562,  0.6336,  1.0659],\n",
      "         [ 0.0719,  0.1956, -0.0088,  ...,  0.0517,  0.4307,  0.1792],\n",
      "         [ 0.1987, -0.3712,  0.0856,  ...,  0.6669,  0.3925,  1.1463],\n",
      "         ...,\n",
      "         [ 0.7149,  0.3899,  0.8675,  ..., -1.0205, -0.8148,  1.9270],\n",
      "         [ 0.7149,  0.3899,  0.8675,  ..., -1.0205, -0.8148,  1.9270],\n",
      "         [ 0.7149,  0.3899,  0.8675,  ..., -1.0205, -0.8148,  1.9270]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3622,  0.2361,  0.7291,  ...,  0.3645,  0.6352,  1.0667],\n",
      "         [ 0.0680,  0.2028, -0.0117,  ...,  0.0420,  0.4315,  0.1739],\n",
      "         [ 0.2042, -0.3715,  0.1150,  ...,  0.6507,  0.4052,  1.1477],\n",
      "         ...,\n",
      "         [ 0.7337,  0.4108,  0.8961,  ..., -1.0596, -0.8188,  1.9415],\n",
      "         [ 0.7337,  0.4108,  0.8961,  ..., -1.0596, -0.8188,  1.9415],\n",
      "         [ 0.7337,  0.4108,  0.8961,  ..., -1.0596, -0.8188,  1.9415]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3651,  0.2300,  0.7383,  ...,  0.3729,  0.6361,  1.0674],\n",
      "         [ 0.0641,  0.2134, -0.0150,  ...,  0.0301,  0.4300,  0.1686],\n",
      "         [ 0.2114, -0.3620,  0.1411,  ...,  0.6148,  0.4140,  1.1462],\n",
      "         ...,\n",
      "         [ 0.7529,  0.4334,  0.9224,  ..., -1.0997, -0.8242,  1.9551],\n",
      "         [ 0.7529,  0.4334,  0.9224,  ..., -1.0997, -0.8242,  1.9551],\n",
      "         [ 0.7529,  0.4334,  0.9224,  ..., -1.0997, -0.8242,  1.9551]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3681,  0.2227,  0.7492,  ...,  0.3836,  0.6368,  1.0687],\n",
      "         [ 0.0606,  0.2290, -0.0190,  ...,  0.0244,  0.4259,  0.1627],\n",
      "         [ 0.2188, -0.3450,  0.1666,  ...,  0.5972,  0.4158,  1.1458],\n",
      "         ...,\n",
      "         [ 0.7713,  0.4567,  0.9472,  ..., -1.1325, -0.8321,  1.9689],\n",
      "         [ 0.7713,  0.4567,  0.9472,  ..., -1.1325, -0.8321,  1.9689],\n",
      "         [ 0.7713,  0.4567,  0.9472,  ..., -1.1325, -0.8321,  1.9689]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3721,  0.2135,  0.7611,  ...,  0.3934,  0.6377,  1.0703],\n",
      "         [ 0.2139,  0.1083,  0.1754,  ...,  0.2569,  0.5852,  0.5888],\n",
      "         [ 0.1074, -0.3000, -0.1410,  ...,  0.6787,  0.4237,  1.2672],\n",
      "         ...,\n",
      "         [ 0.7894,  0.4776,  0.9715,  ..., -1.1613, -0.8402,  1.9832],\n",
      "         [ 0.7894,  0.4776,  0.9715,  ..., -1.1613, -0.8402,  1.9832],\n",
      "         [ 0.7894,  0.4776,  0.9715,  ..., -1.1613, -0.8402,  1.9832]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3751,  0.2047,  0.7725,  ...,  0.4045,  0.6388,  1.0724],\n",
      "         [ 0.1905,  0.3654,  0.1530,  ...,  0.6627,  0.2521,  0.9004],\n",
      "         [-0.6864,  0.1755, -0.1824,  ..., -0.1670,  0.4180,  0.6516],\n",
      "         ...,\n",
      "         [ 0.8049,  0.4982,  0.9980,  ..., -1.1888, -0.8465,  1.9969],\n",
      "         [ 0.8049,  0.4982,  0.9980,  ..., -1.1888, -0.8465,  1.9969],\n",
      "         [ 0.8049,  0.4982,  0.9980,  ..., -1.1888, -0.8465,  1.9969]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3774,  0.1980,  0.7822,  ...,  0.4188,  0.6397,  1.0748],\n",
      "         [-0.2075,  0.5744, -0.3193,  ...,  0.3101,  0.4124,  0.6230],\n",
      "         [-0.2556, -0.2403,  0.2388,  ..., -0.1053,  0.7940,  0.6961],\n",
      "         ...,\n",
      "         [ 0.8192,  0.5167,  1.0211,  ..., -1.2135, -0.8527,  2.0085],\n",
      "         [ 0.8192,  0.5167,  1.0211,  ..., -1.2135, -0.8527,  2.0085],\n",
      "         [ 0.8192,  0.5167,  1.0211,  ..., -1.2135, -0.8527,  2.0085]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 3.7960e-01,  1.9224e-01,  7.9117e-01,  ...,  4.3571e-01,\n",
      "           6.3997e-01,  1.0774e+00],\n",
      "         [ 4.0576e-02,  2.7731e-01, -2.2526e-02,  ..., -4.7137e-04,\n",
      "           4.1344e-01,  1.4414e-01],\n",
      "         [ 2.2943e-01, -2.8481e-01,  2.7269e-01,  ...,  5.4454e-01,\n",
      "           4.2151e-01,  1.1550e+00],\n",
      "         ...,\n",
      "         [ 8.3159e-01,  5.3503e-01,  1.0424e+00,  ..., -1.2396e+00,\n",
      "          -8.5852e-01,  2.0186e+00],\n",
      "         [ 8.3159e-01,  5.3503e-01,  1.0424e+00,  ..., -1.2396e+00,\n",
      "          -8.5852e-01,  2.0186e+00],\n",
      "         [ 8.3159e-01,  5.3503e-01,  1.0424e+00,  ..., -1.2396e+00,\n",
      "          -8.5852e-01,  2.0186e+00]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3826,  0.1853,  0.8006,  ...,  0.4540,  0.6401,  1.0804],\n",
      "         [ 0.1930,  0.3579,  0.1854,  ...,  0.6023,  0.2428,  0.9045],\n",
      "         [-0.6940,  0.5516, -0.2975,  ..., -0.6268,  0.5562,  0.7736],\n",
      "         ...,\n",
      "         [ 0.8434,  0.5513,  1.0627,  ..., -1.2627, -0.8657,  2.0283],\n",
      "         [ 0.8434,  0.5513,  1.0627,  ..., -1.2627, -0.8657,  2.0283],\n",
      "         [ 0.8434,  0.5513,  1.0627,  ..., -1.2627, -0.8657,  2.0283]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3849,  0.1801,  0.8084,  ...,  0.4749,  0.6402,  1.0841],\n",
      "         [-0.3571,  0.3916, -0.1896,  ..., -0.3049,  0.5666,  0.7900],\n",
      "         [ 0.2218, -0.1322,  0.4045,  ..., -0.9596,  0.1026,  0.9869],\n",
      "         ...,\n",
      "         [ 0.8526,  0.5652,  1.0805,  ..., -1.2807, -0.8738,  2.0385],\n",
      "         [ 0.8526,  0.5652,  1.0805,  ..., -1.2807, -0.8738,  2.0385],\n",
      "         [ 0.8526,  0.5652,  1.0805,  ..., -1.2807, -0.8738,  2.0385]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3879,  0.1756,  0.8164,  ...,  0.4915,  0.6397,  1.0872],\n",
      "         [-0.1843,  0.2720,  0.1749,  ..., -0.3429,  0.1839,  1.2948],\n",
      "         [-0.5167,  0.1741, -0.1370,  ..., -0.3237,  0.7577,  0.8167],\n",
      "         ...,\n",
      "         [ 0.8647,  0.5758,  1.0984,  ..., -1.3031, -0.8804,  2.0485],\n",
      "         [ 0.8647,  0.5758,  1.0984,  ..., -1.3031, -0.8804,  2.0485],\n",
      "         [ 0.8647,  0.5758,  1.0984,  ..., -1.3031, -0.8804,  2.0485]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3914,  0.1715,  0.8218,  ...,  0.5046,  0.6391,  1.0911],\n",
      "         [ 0.0229,  0.3067, -0.0241,  ..., -0.0298,  0.3941,  0.1246],\n",
      "         [ 0.2382, -0.2488,  0.3504,  ...,  0.4958,  0.3974,  1.1790],\n",
      "         ...,\n",
      "         [ 0.8762,  0.5830,  1.1124,  ..., -1.3240, -0.8869,  2.0580],\n",
      "         [ 0.8762,  0.5830,  1.1124,  ..., -1.3240, -0.8869,  2.0580],\n",
      "         [ 0.8762,  0.5830,  1.1124,  ..., -1.3240, -0.8869,  2.0580]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.3954,  0.1643,  0.8276,  ...,  0.5201,  0.6394,  1.0955],\n",
      "         [-0.3603,  0.3792, -0.1904,  ..., -0.4072,  0.5721,  0.8106],\n",
      "         [ 0.5137,  0.4340,  0.2792,  ..., -0.4182,  0.2497,  0.5328],\n",
      "         ...,\n",
      "         [ 0.8862,  0.5870,  1.1202,  ..., -1.3363, -0.8936,  2.0674],\n",
      "         [ 0.8862,  0.5870,  1.1202,  ..., -1.3363, -0.8936,  2.0674],\n",
      "         [ 0.8862,  0.5870,  1.1202,  ..., -1.3363, -0.8936,  2.0674]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4004,  0.1569,  0.8341,  ...,  0.5325,  0.6388,  1.0997],\n",
      "         [-0.4277,  0.8372, -0.1407,  ..., -0.6506,  0.3067,  0.9140],\n",
      "         [-0.3806,  0.3409, -0.4307,  ...,  0.3926,  0.6655,  0.6092],\n",
      "         ...,\n",
      "         [ 0.8933,  0.5918,  1.1261,  ..., -1.3396, -0.9003,  2.0773],\n",
      "         [ 0.8933,  0.5918,  1.1261,  ..., -1.3396, -0.9003,  2.0773],\n",
      "         [ 0.8933,  0.5918,  1.1261,  ..., -1.3396, -0.9003,  2.0773]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4072,  0.1484,  0.8378,  ...,  0.5424,  0.6374,  1.1023],\n",
      "         [ 0.1851,  0.1469,  0.1847,  ..., -0.6502, -0.2473,  0.3976],\n",
      "         [ 0.1753, -0.0516,  0.3055,  ...,  0.6252,  0.4654,  1.2886],\n",
      "         ...,\n",
      "         [ 0.9012,  0.5943,  1.1310,  ..., -1.3358, -0.9070,  2.0868],\n",
      "         [ 0.9012,  0.5943,  1.1310,  ..., -1.3358, -0.9070,  2.0868],\n",
      "         [ 0.9012,  0.5943,  1.1310,  ..., -1.3358, -0.9070,  2.0868]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4133,  0.1388,  0.8420,  ...,  0.5517,  0.6366,  1.1054],\n",
      "         [ 0.0267,  0.3138, -0.0518,  ..., -0.0170,  0.3859,  0.1099],\n",
      "         [ 0.2806, -0.2762,  0.3058,  ...,  0.5220,  0.3962,  1.2110],\n",
      "         ...,\n",
      "         [ 0.9087,  0.5981,  1.1361,  ..., -1.3385, -0.9108,  2.0952],\n",
      "         [ 0.9087,  0.5981,  1.1361,  ..., -1.3385, -0.9108,  2.0952],\n",
      "         [ 0.9087,  0.5981,  1.1361,  ..., -1.3385, -0.9108,  2.0952]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4198,  0.1275,  0.8481,  ...,  0.5614,  0.6366,  1.1087],\n",
      "         [ 0.0263,  0.3156, -0.0568,  ..., -0.0147,  0.3864,  0.1059],\n",
      "         [ 0.2885, -0.2811,  0.2903,  ...,  0.5180,  0.3995,  1.2146],\n",
      "         ...,\n",
      "         [ 0.9134,  0.6007,  1.1402,  ..., -1.3376, -0.9141,  2.1020],\n",
      "         [ 0.9134,  0.6007,  1.1402,  ..., -1.3376, -0.9141,  2.1020],\n",
      "         [ 0.9134,  0.6007,  1.1402,  ..., -1.3376, -0.9141,  2.1020]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4256,  0.1152,  0.8554,  ...,  0.5736,  0.6374,  1.1119],\n",
      "         [ 0.4017,  0.4353,  0.2655,  ..., -0.8438, -0.4481,  0.9157],\n",
      "         [ 0.3946, -0.1441, -0.0411,  ..., -1.0737,  0.4193,  0.4487],\n",
      "         ...,\n",
      "         [ 0.9160,  0.6033,  1.1415,  ..., -1.3305, -0.9176,  2.1095],\n",
      "         [ 0.9160,  0.6033,  1.1415,  ..., -1.3305, -0.9176,  2.1095],\n",
      "         [ 0.9160,  0.6033,  1.1415,  ..., -1.3305, -0.9176,  2.1095]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4317,  0.1050,  0.8600,  ...,  0.5839,  0.6383,  1.1161],\n",
      "         [ 0.2084,  0.1065,  0.1972,  ..., -0.6910, -0.2645,  0.4071],\n",
      "         [-0.3205,  0.4085, -0.3826,  ...,  0.3197,  0.6621,  0.5322],\n",
      "         ...,\n",
      "         [ 0.9144,  0.6031,  1.1409,  ..., -1.3202, -0.9197,  2.1171],\n",
      "         [ 0.9144,  0.6031,  1.1409,  ..., -1.3202, -0.9197,  2.1171],\n",
      "         [ 0.9144,  0.6031,  1.1409,  ..., -1.3202, -0.9197,  2.1171]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4359,  0.0935,  0.8648,  ...,  0.5935,  0.6388,  1.1205],\n",
      "         [ 0.0098,  0.3205, -0.0788,  ...,  0.0075,  0.3921,  0.0962],\n",
      "         [ 0.3070, -0.3230,  0.2285,  ...,  0.5163,  0.3977,  1.2314],\n",
      "         ...,\n",
      "         [ 0.9114,  0.6018,  1.1400,  ..., -1.3081, -0.9216,  2.1236],\n",
      "         [ 0.9113,  0.6018,  1.1400,  ..., -1.3081, -0.9216,  2.1236],\n",
      "         [ 0.9114,  0.6018,  1.1400,  ..., -1.3081, -0.9216,  2.1236]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4404,  0.0803,  0.8719,  ...,  0.6025,  0.6395,  1.1259],\n",
      "         [ 0.5809, -0.4003, -0.2767,  ..., -0.5933, -0.1490,  0.2634],\n",
      "         [-0.3064,  0.0962,  0.4163,  ..., -0.8269,  0.3969,  0.2584],\n",
      "         ...,\n",
      "         [ 0.9072,  0.6027,  1.1383,  ..., -1.3000, -0.9224,  2.1316],\n",
      "         [ 0.9072,  0.6027,  1.1383,  ..., -1.3000, -0.9224,  2.1316],\n",
      "         [ 0.9072,  0.6027,  1.1383,  ..., -1.3000, -0.9224,  2.1316]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4434,  0.0687,  0.8789,  ...,  0.6121,  0.6399,  1.1311],\n",
      "         [ 0.4334, -0.3294,  0.2212,  ..., -0.1298, -0.4045,  0.4910],\n",
      "         [-0.0598, -0.0943,  0.0191,  ...,  0.0480,  0.6987,  0.4699],\n",
      "         ...,\n",
      "         [ 0.9012,  0.6024,  1.1367,  ..., -1.2930, -0.9234,  2.1398],\n",
      "         [ 0.9012,  0.6024,  1.1367,  ..., -1.2930, -0.9234,  2.1398],\n",
      "         [ 0.9012,  0.6024,  1.1367,  ..., -1.2930, -0.9234,  2.1398]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 4.4617e-01,  5.7793e-02,  8.8759e-01,  ...,  6.1856e-01,\n",
      "           6.4079e-01,  1.1355e+00],\n",
      "         [-2.3160e-02,  3.1524e-01, -1.0116e-01,  ...,  1.2201e-03,\n",
      "           4.0013e-01,  9.5997e-02],\n",
      "         [ 2.9237e-01, -3.9520e-01,  1.5693e-01,  ...,  4.7135e-01,\n",
      "           3.8996e-01,  1.2626e+00],\n",
      "         ...,\n",
      "         [ 8.9598e-01,  6.0089e-01,  1.1324e+00,  ..., -1.2835e+00,\n",
      "          -9.2491e-01,  2.1472e+00],\n",
      "         [ 8.9598e-01,  6.0089e-01,  1.1324e+00,  ..., -1.2835e+00,\n",
      "          -9.2491e-01,  2.1472e+00],\n",
      "         [ 8.9598e-01,  6.0089e-01,  1.1324e+00,  ..., -1.2835e+00,\n",
      "          -9.2491e-01,  2.1472e+00]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4494,  0.0471,  0.8963,  ...,  0.6295,  0.6412,  1.1391],\n",
      "         [ 0.4026, -0.3643,  0.2172,  ..., -0.1348, -0.3980,  0.5135],\n",
      "         [-0.7463,  0.5981, -0.3918,  ..., -0.7738,  0.4930,  0.8003],\n",
      "         ...,\n",
      "         [ 0.8929,  0.5978,  1.1293,  ..., -1.2792, -0.9273,  2.1533],\n",
      "         [ 0.8929,  0.5978,  1.1293,  ..., -1.2792, -0.9273,  2.1533],\n",
      "         [ 0.8929,  0.5978,  1.1293,  ..., -1.2792, -0.9273,  2.1533]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4519,  0.0367,  0.9064,  ...,  0.6371,  0.6422,  1.1419],\n",
      "         [-0.0384,  0.2969, -0.1008,  ..., -0.0208,  0.4105,  0.0957],\n",
      "         [ 0.2754, -0.4505,  0.1094,  ...,  0.4609,  0.3813,  1.2750],\n",
      "         ...,\n",
      "         [ 0.8867,  0.5950,  1.1253,  ..., -1.2758, -0.9284,  2.1589],\n",
      "         [ 0.8867,  0.5950,  1.1253,  ..., -1.2758, -0.9284,  2.1589],\n",
      "         [ 0.8867,  0.5950,  1.1253,  ..., -1.2758, -0.9284,  2.1589]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4559,  0.0249,  0.9182,  ...,  0.6466,  0.6430,  1.1450],\n",
      "         [ 0.5490, -0.4951, -0.2875,  ..., -0.6617, -0.1523,  0.2730],\n",
      "         [-0.6865,  0.8823, -0.5422,  ..., -0.0757,  0.2489,  0.5765],\n",
      "         ...,\n",
      "         [ 0.8810,  0.5923,  1.1206,  ..., -1.2676, -0.9306,  2.1630],\n",
      "         [ 0.8810,  0.5923,  1.1206,  ..., -1.2676, -0.9306,  2.1630],\n",
      "         [ 0.8810,  0.5923,  1.1206,  ..., -1.2676, -0.9306,  2.1630]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4578,  0.0161,  0.9288,  ...,  0.6579,  0.6445,  1.1479],\n",
      "         [-0.0530,  0.2907, -0.1102,  ..., -0.0102,  0.4171,  0.0844],\n",
      "         [ 0.2569, -0.4970,  0.0706,  ...,  0.4972,  0.3721,  1.2795],\n",
      "         ...,\n",
      "         [ 0.8758,  0.5910,  1.1154,  ..., -1.2527, -0.9338,  2.1667],\n",
      "         [ 0.8758,  0.5910,  1.1154,  ..., -1.2527, -0.9338,  2.1667],\n",
      "         [ 0.8758,  0.5910,  1.1154,  ..., -1.2527, -0.9338,  2.1667]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4598,  0.0065,  0.9416,  ...,  0.6714,  0.6461,  1.1518],\n",
      "         [-0.5409,  0.3482, -0.4301,  ..., -0.4685,  0.6087,  0.8744],\n",
      "         [-0.0207,  0.0707,  0.0161,  ...,  0.7295,  0.4869,  0.8949],\n",
      "         ...,\n",
      "         [ 0.8697,  0.5891,  1.1072,  ..., -1.2397, -0.9371,  2.1708],\n",
      "         [ 0.8697,  0.5891,  1.1072,  ..., -1.2397, -0.9371,  2.1708],\n",
      "         [ 0.8697,  0.5891,  1.1072,  ..., -1.2397, -0.9371,  2.1708]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 4.6236e-01, -9.3180e-04,  9.5365e-01,  ...,  6.7827e-01,\n",
      "           6.4639e-01,  1.1544e+00],\n",
      "         [ 9.0623e-02,  8.1760e-02,  1.5495e-01,  ...,  1.0265e-01,\n",
      "           5.9796e-01,  6.8033e-01],\n",
      "         [ 4.0548e-01, -8.2466e-01, -7.1445e-01,  ..., -4.6562e-01,\n",
      "           9.1407e-02,  2.4294e-01],\n",
      "         ...,\n",
      "         [ 8.6591e-01,  5.8739e-01,  1.1003e+00,  ..., -1.2249e+00,\n",
      "          -9.4050e-01,  2.1750e+00],\n",
      "         [ 8.6591e-01,  5.8739e-01,  1.1003e+00,  ..., -1.2249e+00,\n",
      "          -9.4050e-01,  2.1750e+00],\n",
      "         [ 8.6591e-01,  5.8739e-01,  1.1003e+00,  ..., -1.2249e+00,\n",
      "          -9.4050e-01,  2.1750e+00]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 4.6507e-01, -8.0566e-03,  9.6103e-01,  ...,  6.8120e-01,\n",
      "           6.4710e-01,  1.1568e+00],\n",
      "         [ 1.7505e-01,  1.7205e-03,  1.6455e-01,  ..., -7.2323e-01,\n",
      "          -3.0849e-01,  4.2298e-01],\n",
      "         [ 3.0970e-01, -2.4150e-01, -1.9158e-01,  ..., -1.0298e+00,\n",
      "           5.5775e-01,  2.9789e-01],\n",
      "         ...,\n",
      "         [ 8.6424e-01,  5.8689e-01,  1.0959e+00,  ..., -1.2142e+00,\n",
      "          -9.4333e-01,  2.1765e+00],\n",
      "         [ 8.6424e-01,  5.8689e-01,  1.0959e+00,  ..., -1.2142e+00,\n",
      "          -9.4333e-01,  2.1765e+00],\n",
      "         [ 8.6424e-01,  5.8689e-01,  1.0959e+00,  ..., -1.2142e+00,\n",
      "          -9.4333e-01,  2.1765e+00]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4671, -0.0156,  0.9666,  ...,  0.6853,  0.6477,  1.1591],\n",
      "         [ 0.0780,  0.0958,  0.1439,  ...,  0.0861,  0.6015,  0.6818],\n",
      "         [ 0.2051, -0.7256, -0.1727,  ...,  0.0422, -0.1588,  0.4943],\n",
      "         ...,\n",
      "         [ 0.8642,  0.5856,  1.0897,  ..., -1.2072, -0.9461,  2.1782],\n",
      "         [ 0.8642,  0.5856,  1.0897,  ..., -1.2072, -0.9461,  2.1782],\n",
      "         [ 0.8642,  0.5856,  1.0897,  ..., -1.2072, -0.9461,  2.1782]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4686, -0.0214,  0.9694,  ...,  0.6897,  0.6479,  1.1607],\n",
      "         [ 0.4349, -0.0787,  0.6928,  ..., -1.1922, -0.0651,  1.0572],\n",
      "         [-0.6895,  0.4010, -0.2128,  ..., -0.4219,  0.4347,  0.8272],\n",
      "         ...,\n",
      "         [ 0.8665,  0.5845,  1.0846,  ..., -1.2030, -0.9481,  2.1791],\n",
      "         [ 0.8665,  0.5845,  1.0846,  ..., -1.2030, -0.9481,  2.1791],\n",
      "         [ 0.8665,  0.5845,  1.0846,  ..., -1.2030, -0.9481,  2.1791]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4684, -0.0256,  0.9710,  ...,  0.6919,  0.6485,  1.1624],\n",
      "         [-0.6216,  0.3594, -0.5648,  ..., -0.3879,  0.5948,  0.8605],\n",
      "         [ 0.3209, -0.2148,  0.4850,  ..., -0.9823,  0.1729,  0.9221],\n",
      "         ...,\n",
      "         [ 0.8663,  0.5837,  1.0792,  ..., -1.2035, -0.9493,  2.1793],\n",
      "         [ 0.8663,  0.5837,  1.0792,  ..., -1.2035, -0.9493,  2.1793],\n",
      "         [ 0.8663,  0.5837,  1.0792,  ..., -1.2035, -0.9493,  2.1793]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 4.6833e-01, -2.7893e-02,  9.7230e-01,  ...,  6.9020e-01,\n",
      "           6.4738e-01,  1.1627e+00],\n",
      "         [ 2.2853e-01, -9.7448e-04,  1.1093e-01,  ..., -7.2375e-01,\n",
      "          -3.2001e-01,  4.1718e-01],\n",
      "         [-7.2953e-01,  2.0833e-01, -6.4022e-01,  ..., -4.2775e-01,\n",
      "           9.0785e-01,  7.5991e-01],\n",
      "         ...,\n",
      "         [ 8.6615e-01,  5.7902e-01,  1.0773e+00,  ..., -1.2090e+00,\n",
      "          -9.4872e-01,  2.1800e+00],\n",
      "         [ 8.6615e-01,  5.7902e-01,  1.0773e+00,  ..., -1.2090e+00,\n",
      "          -9.4872e-01,  2.1800e+00],\n",
      "         [ 8.6615e-01,  5.7902e-01,  1.0773e+00,  ..., -1.2090e+00,\n",
      "          -9.4872e-01,  2.1800e+00]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4668, -0.0307,  0.9724,  ...,  0.6897,  0.6463,  1.1635],\n",
      "         [ 0.2472, -0.0025,  0.1050,  ..., -0.7307, -0.3191,  0.4148],\n",
      "         [ 0.1633, -0.4002, -0.0666,  ...,  0.4994,  0.4650,  1.3839],\n",
      "         ...,\n",
      "         [ 0.8692,  0.5751,  1.0767,  ..., -1.2124, -0.9480,  2.1802],\n",
      "         [ 0.8692,  0.5751,  1.0767,  ..., -1.2124, -0.9480,  2.1802],\n",
      "         [ 0.8692,  0.5751,  1.0767,  ..., -1.2124, -0.9480,  2.1802]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4658, -0.0340,  0.9739,  ...,  0.6891,  0.6454,  1.1654],\n",
      "         [ 0.4015, -0.4920,  0.2006,  ..., -0.2538, -0.4179,  0.5095],\n",
      "         [-0.8570,  0.5236, -0.6059,  ..., -0.7102,  0.4983,  0.7726],\n",
      "         ...,\n",
      "         [ 0.8737,  0.5725,  1.0742,  ..., -1.2171, -0.9480,  2.1803],\n",
      "         [ 0.8737,  0.5725,  1.0742,  ..., -1.2171, -0.9480,  2.1803],\n",
      "         [ 0.8737,  0.5725,  1.0742,  ..., -1.2171, -0.9480,  2.1803]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4639, -0.0354,  0.9766,  ...,  0.6853,  0.6459,  1.1659],\n",
      "         [ 0.1123,  0.0755, -0.6671,  ..., -1.0247, -0.2522,  0.6140],\n",
      "         [-0.6699,  0.4973, -0.2003,  ..., -0.5691,  0.8362,  0.9653],\n",
      "         ...,\n",
      "         [ 0.8781,  0.5724,  1.0708,  ..., -1.2223, -0.9460,  2.1795],\n",
      "         [ 0.8781,  0.5724,  1.0708,  ..., -1.2223, -0.9460,  2.1795],\n",
      "         [ 0.8781,  0.5724,  1.0708,  ..., -1.2223, -0.9460,  2.1795]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4622, -0.0321,  0.9785,  ...,  0.6791,  0.6458,  1.1655],\n",
      "         [ 0.0680, -0.2823,  0.5145,  ..., -1.3172,  0.0215,  0.8281],\n",
      "         [-0.5723,  0.5676, -0.4293,  ..., -0.8173,  0.6465,  0.9690],\n",
      "         ...,\n",
      "         [ 0.8833,  0.5762,  1.0722,  ..., -1.2307, -0.9407,  2.1762],\n",
      "         [ 0.8833,  0.5762,  1.0722,  ..., -1.2307, -0.9407,  2.1762],\n",
      "         [ 0.8833,  0.5762,  1.0722,  ..., -1.2307, -0.9407,  2.1762]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4624, -0.0270,  0.9769,  ...,  0.6734,  0.6466,  1.1633],\n",
      "         [ 0.1174,  0.1034, -0.6960,  ..., -1.0440, -0.2650,  0.5845],\n",
      "         [-0.0736,  0.5549,  0.0157,  ...,  0.6660,  0.9096,  0.1667],\n",
      "         ...,\n",
      "         [ 0.8887,  0.5777,  1.0742,  ..., -1.2369, -0.9341,  2.1710],\n",
      "         [ 0.8887,  0.5777,  1.0742,  ..., -1.2369, -0.9341,  2.1710],\n",
      "         [ 0.8887,  0.5777,  1.0742,  ..., -1.2369, -0.9341,  2.1710]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4629, -0.0188,  0.9774,  ...,  0.6622,  0.6470,  1.1597],\n",
      "         [-0.0336,  0.9146,  0.0074,  ..., -1.3865,  0.1996,  0.5335],\n",
      "         [-0.1626,  0.6971,  0.3566,  ..., -1.0969,  0.1116,  0.2838],\n",
      "         ...,\n",
      "         [ 0.8930,  0.5805,  1.0765,  ..., -1.2393, -0.9266,  2.1640],\n",
      "         [ 0.8930,  0.5805,  1.0765,  ..., -1.2393, -0.9266,  2.1640],\n",
      "         [ 0.8930,  0.5805,  1.0765,  ..., -1.2393, -0.9266,  2.1640]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4633, -0.0100,  0.9771,  ...,  0.6542,  0.6460,  1.1572],\n",
      "         [ 0.0258,  0.2843, -0.1808,  ..., -0.0176,  0.4307,  0.0407],\n",
      "         [ 0.3058, -0.4911, -0.2094,  ...,  0.4703,  0.3560,  1.2483],\n",
      "         ...,\n",
      "         [ 0.8919,  0.5855,  1.0770,  ..., -1.2364, -0.9192,  2.1577],\n",
      "         [ 0.8919,  0.5855,  1.0770,  ..., -1.2364, -0.9192,  2.1577],\n",
      "         [ 0.8919,  0.5855,  1.0770,  ..., -1.2364, -0.9192,  2.1577]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4650, -0.0027,  0.9802,  ...,  0.6495,  0.6452,  1.1549],\n",
      "         [ 0.0308,  0.2922, -0.1764,  ..., -0.0155,  0.4315,  0.0399],\n",
      "         [ 0.3138, -0.4651, -0.1945,  ...,  0.4754,  0.3517,  1.2308],\n",
      "         ...,\n",
      "         [ 0.8895,  0.5908,  1.0780,  ..., -1.2337, -0.9118,  2.1507],\n",
      "         [ 0.8895,  0.5908,  1.0780,  ..., -1.2337, -0.9118,  2.1507],\n",
      "         [ 0.8895,  0.5908,  1.0780,  ..., -1.2337, -0.9118,  2.1507]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4682,  0.0026,  0.9872,  ...,  0.6484,  0.6444,  1.1533],\n",
      "         [-0.6268,  1.0020, -0.5123,  ..., -0.0845, -0.0482,  0.5975],\n",
      "         [ 0.2439, -0.2584, -0.0745,  ...,  0.7287,  0.4071,  1.4131],\n",
      "         ...,\n",
      "         [ 0.8866,  0.5974,  1.0807,  ..., -1.2286, -0.9069,  2.1443],\n",
      "         [ 0.8866,  0.5974,  1.0807,  ..., -1.2286, -0.9069,  2.1443],\n",
      "         [ 0.8866,  0.5974,  1.0807,  ..., -1.2286, -0.9069,  2.1443]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4691,  0.0052,  0.9935,  ...,  0.6479,  0.6452,  1.1523],\n",
      "         [-0.0146,  0.9331,  0.0366,  ..., -1.3747,  0.2015,  0.5231],\n",
      "         [-0.4172,  0.1595,  0.3407,  ..., -0.5190,  0.4664,  0.2271],\n",
      "         ...,\n",
      "         [ 0.8832,  0.6033,  1.0852,  ..., -1.2283, -0.9017,  2.1392],\n",
      "         [ 0.8832,  0.6033,  1.0852,  ..., -1.2283, -0.9017,  2.1392],\n",
      "         [ 0.8832,  0.6033,  1.0852,  ..., -1.2283, -0.9017,  2.1392]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4701,  0.0067,  0.9986,  ...,  0.6448,  0.6461,  1.1525],\n",
      "         [ 0.3632,  0.1230,  0.1255,  ..., -0.7484, -0.3180,  0.3764],\n",
      "         [ 0.2650, -0.2651, -0.0502,  ...,  0.3776,  0.4672,  1.2760],\n",
      "         ...,\n",
      "         [ 0.8784,  0.6061,  1.0905,  ..., -1.2220, -0.8971,  2.1350],\n",
      "         [ 0.8784,  0.6061,  1.0905,  ..., -1.2220, -0.8971,  2.1350],\n",
      "         [ 0.8784,  0.6061,  1.0905,  ..., -1.2220, -0.8971,  2.1350]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4690,  0.0044,  1.0042,  ...,  0.6455,  0.6467,  1.1542],\n",
      "         [ 0.5863, -0.1661, -0.1901,  ..., -1.0763,  0.2541,  0.3755],\n",
      "         [-0.3322,  0.0130,  0.4274,  ..., -0.3894,  0.4570,  0.4469],\n",
      "         ...,\n",
      "         [ 0.8738,  0.6070,  1.0957,  ..., -1.2222, -0.8941,  2.1333],\n",
      "         [ 0.8738,  0.6070,  1.0957,  ..., -1.2222, -0.8941,  2.1333],\n",
      "         [ 0.8738,  0.6070,  1.0957,  ..., -1.2222, -0.8941,  2.1333]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 4.6642e-01, -4.0221e-04,  1.0066e+00,  ...,  6.4360e-01,\n",
      "           6.4671e-01,  1.1568e+00],\n",
      "         [ 4.5122e-01,  2.8940e-01,  1.2207e-01,  ..., -1.0828e+00,\n",
      "          -5.5252e-01,  8.9293e-01],\n",
      "         [ 5.3038e-01, -3.6772e-01, -6.7501e-02,  ..., -1.1190e+00,\n",
      "           5.1354e-01,  4.5956e-01],\n",
      "         ...,\n",
      "         [ 8.6899e-01,  6.0549e-01,  1.1021e+00,  ..., -1.2211e+00,\n",
      "          -8.9112e-01,  2.1312e+00],\n",
      "         [ 8.6899e-01,  6.0549e-01,  1.1021e+00,  ..., -1.2211e+00,\n",
      "          -8.9112e-01,  2.1312e+00],\n",
      "         [ 8.6899e-01,  6.0549e-01,  1.1021e+00,  ..., -1.2211e+00,\n",
      "          -8.9112e-01,  2.1312e+00]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4639, -0.0044,  1.0065,  ...,  0.6409,  0.6471,  1.1595],\n",
      "         [ 0.4915, -0.0812,  0.7580,  ..., -1.4153, -0.1254,  0.9918],\n",
      "         [-0.5610,  0.4611, -0.0203,  ..., -0.7115,  0.4709,  0.7586],\n",
      "         ...,\n",
      "         [ 0.8678,  0.5992,  1.1134,  ..., -1.2169, -0.8885,  2.1301],\n",
      "         [ 0.8678,  0.5992,  1.1134,  ..., -1.2169, -0.8885,  2.1301],\n",
      "         [ 0.8678,  0.5992,  1.1134,  ..., -1.2169, -0.8885,  2.1301]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4614, -0.0080,  1.0066,  ...,  0.6403,  0.6474,  1.1640],\n",
      "         [ 0.0502,  0.2631, -0.0760,  ..., -0.0524,  0.4374,  0.0276],\n",
      "         [ 0.3208, -0.4992, -0.0052,  ...,  0.4229,  0.3391,  1.1461],\n",
      "         ...,\n",
      "         [ 0.8665,  0.5950,  1.1235,  ..., -1.2128, -0.8894,  2.1323],\n",
      "         [ 0.8665,  0.5950,  1.1235,  ..., -1.2128, -0.8894,  2.1323],\n",
      "         [ 0.8665,  0.5950,  1.1235,  ..., -1.2128, -0.8894,  2.1323]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4602, -0.0116,  1.0085,  ...,  0.6420,  0.6477,  1.1676],\n",
      "         [ 0.0540,  0.2456, -0.0587,  ..., -0.0617,  0.4380,  0.0281],\n",
      "         [ 0.3206, -0.5319,  0.0268,  ...,  0.4236,  0.3313,  1.1359],\n",
      "         ...,\n",
      "         [ 0.8653,  0.5902,  1.1327,  ..., -1.2119, -0.8892,  2.1330],\n",
      "         [ 0.8653,  0.5902,  1.1327,  ..., -1.2119, -0.8892,  2.1330],\n",
      "         [ 0.8653,  0.5902,  1.1327,  ..., -1.2119, -0.8892,  2.1330]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4606, -0.0159,  1.0119,  ...,  0.6466,  0.6488,  1.1714],\n",
      "         [ 0.0572,  0.2305, -0.0482,  ..., -0.0670,  0.4382,  0.0275],\n",
      "         [ 0.3194, -0.5640,  0.0525,  ...,  0.4304,  0.3303,  1.1271],\n",
      "         ...,\n",
      "         [ 0.8630,  0.5867,  1.1388,  ..., -1.2040, -0.8881,  2.1328],\n",
      "         [ 0.8630,  0.5867,  1.1388,  ..., -1.2040, -0.8881,  2.1328],\n",
      "         [ 0.8630,  0.5867,  1.1388,  ..., -1.2040, -0.8881,  2.1328]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4638, -0.0211,  1.0180,  ...,  0.6559,  0.6498,  1.1756],\n",
      "         [-0.1201,  0.7765,  0.4245,  ..., -1.0887, -0.2171,  0.3810],\n",
      "         [ 0.2066, -0.3370,  0.1884,  ...,  0.7660,  0.5031,  1.4467],\n",
      "         ...,\n",
      "         [ 0.8631,  0.5857,  1.1462,  ..., -1.1995, -0.8887,  2.1357],\n",
      "         [ 0.8631,  0.5857,  1.1462,  ..., -1.1995, -0.8887,  2.1357],\n",
      "         [ 0.8631,  0.5857,  1.1462,  ..., -1.1995, -0.8887,  2.1357]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4646, -0.0243,  1.0253,  ...,  0.6668,  0.6516,  1.1800],\n",
      "         [ 0.0636,  0.2074, -0.0266,  ..., -0.0851,  0.4410,  0.0219],\n",
      "         [ 0.3176, -0.6143,  0.0993,  ...,  0.4686,  0.3480,  1.1246],\n",
      "         ...,\n",
      "         [ 0.8632,  0.5865,  1.1541,  ..., -1.1947, -0.8898,  2.1392],\n",
      "         [ 0.8632,  0.5865,  1.1541,  ..., -1.1947, -0.8898,  2.1392],\n",
      "         [ 0.8632,  0.5865,  1.1541,  ..., -1.1947, -0.8898,  2.1392]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4683, -0.0273,  1.0328,  ...,  0.6788,  0.6531,  1.1833],\n",
      "         [-0.1316,  0.7897,  0.4054,  ..., -1.0797, -0.2266,  0.3710],\n",
      "         [ 0.5434,  0.5284,  0.3830,  ..., -0.2604,  0.3858,  0.5564],\n",
      "         ...,\n",
      "         [ 0.8637,  0.5853,  1.1585,  ..., -1.1819, -0.8899,  2.1386],\n",
      "         [ 0.8637,  0.5853,  1.1585,  ..., -1.1819, -0.8899,  2.1386],\n",
      "         [ 0.8637,  0.5853,  1.1585,  ..., -1.1819, -0.8899,  2.1386]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4701, -0.0297,  1.0410,  ...,  0.6884,  0.6550,  1.1867],\n",
      "         [ 0.0206, -0.3623,  0.5713,  ..., -1.1542,  0.0244,  0.7376],\n",
      "         [ 0.2717, -0.0699,  0.2580,  ..., -0.2430,  0.8956,  0.6343],\n",
      "         ...,\n",
      "         [ 0.8641,  0.5843,  1.1606,  ..., -1.1672, -0.8917,  2.1395],\n",
      "         [ 0.8641,  0.5843,  1.1606,  ..., -1.1672, -0.8917,  2.1395],\n",
      "         [ 0.8641,  0.5843,  1.1606,  ..., -1.1672, -0.8917,  2.1395]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4720, -0.0302,  1.0451,  ...,  0.6977,  0.6576,  1.1880],\n",
      "         [-0.6738,  0.8467, -0.3174,  ..., -0.8029,  0.2246,  0.6751],\n",
      "         [-0.3191,  0.4957, -0.3526,  ...,  1.4820,  0.8281,  0.6180],\n",
      "         ...,\n",
      "         [ 0.8609,  0.5828,  1.1599,  ..., -1.1511, -0.8921,  2.1382],\n",
      "         [ 0.8609,  0.5828,  1.1599,  ..., -1.1511, -0.8921,  2.1382],\n",
      "         [ 0.8609,  0.5828,  1.1599,  ..., -1.1511, -0.8921,  2.1382]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4783, -0.0363,  1.0480,  ...,  0.7013,  0.6594,  1.1891],\n",
      "         [ 0.4747,  0.1959,  0.1482,  ..., -1.1030, -0.6219,  0.8461],\n",
      "         [ 0.5461, -0.4074,  0.0621,  ..., -1.1521,  0.4815,  0.4710],\n",
      "         ...,\n",
      "         [ 0.8598,  0.5786,  1.1586,  ..., -1.1391, -0.8963,  2.1390],\n",
      "         [ 0.8598,  0.5786,  1.1586,  ..., -1.1391, -0.8963,  2.1390],\n",
      "         [ 0.8598,  0.5786,  1.1586,  ..., -1.1391, -0.8963,  2.1390]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 4.8247e-01, -3.9083e-02,  1.0487e+00,  ...,  7.0509e-01,\n",
      "           6.6153e-01,  1.1911e+00],\n",
      "         [-1.1867e-03,  8.7972e-01,  1.4215e-01,  ..., -1.3005e+00,\n",
      "           1.6284e-01,  4.7225e-01],\n",
      "         [-2.4347e-01,  7.2198e-01,  4.5027e-01,  ..., -1.2704e+00,\n",
      "           1.1485e-01,  2.5536e-01],\n",
      "         ...,\n",
      "         [ 8.5869e-01,  5.7616e-01,  1.1553e+00,  ..., -1.1236e+00,\n",
      "          -9.0007e-01,  2.1381e+00],\n",
      "         [ 8.5869e-01,  5.7616e-01,  1.1553e+00,  ..., -1.1236e+00,\n",
      "          -9.0007e-01,  2.1381e+00],\n",
      "         [ 8.5869e-01,  5.7616e-01,  1.1553e+00,  ..., -1.1236e+00,\n",
      "          -9.0007e-01,  2.1381e+00]]], grad_fn=<TransposeBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 3.8306 :   0%|          | 100/124155 [00:19<05:46, 358.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4867, -0.0409,  1.0473,  ...,  0.7068,  0.6633,  1.1935],\n",
      "         [ 0.1721,  0.0874,  0.2235,  ..., -0.0309,  0.6002,  0.8409],\n",
      "         [-0.0501,  0.0276, -0.0099,  ...,  0.8349,  0.4696,  0.8383],\n",
      "         ...,\n",
      "         [ 0.8590,  0.5733,  1.1541,  ..., -1.1137, -0.9038,  2.1382],\n",
      "         [ 0.8590,  0.5733,  1.1541,  ..., -1.1137, -0.9038,  2.1382],\n",
      "         [ 0.8590,  0.5733,  1.1541,  ..., -1.1137, -0.9038,  2.1382]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4896, -0.0409,  1.0440,  ...,  0.7026,  0.6663,  1.1948],\n",
      "         [ 0.3528,  0.0372,  0.0490,  ..., -0.5859, -0.3831,  0.3085],\n",
      "         [ 0.3318, -0.7399,  0.1565,  ...,  0.6267,  0.4600,  1.1818],\n",
      "         ...,\n",
      "         [ 0.8568,  0.5717,  1.1533,  ..., -1.1029, -0.9047,  2.1365],\n",
      "         [ 0.8568,  0.5717,  1.1533,  ..., -1.1029, -0.9047,  2.1365],\n",
      "         [ 0.8568,  0.5717,  1.1533,  ..., -1.1029, -0.9047,  2.1365]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4906, -0.0408,  1.0397,  ...,  0.6991,  0.6694,  1.1960],\n",
      "         [ 0.0493,  0.1827, -0.0917,  ...,  0.0791,  0.4172, -0.0288],\n",
      "         [ 0.3480, -0.8219, -0.0045,  ...,  0.8741,  0.3763,  1.0578],\n",
      "         ...,\n",
      "         [ 0.8547,  0.5703,  1.1494,  ..., -1.0969, -0.9053,  2.1322],\n",
      "         [ 0.8547,  0.5703,  1.1494,  ..., -1.0969, -0.9053,  2.1322],\n",
      "         [ 0.8547,  0.5703,  1.1494,  ..., -1.0969, -0.9053,  2.1322]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4927, -0.0410,  1.0367,  ...,  0.7001,  0.6726,  1.1976],\n",
      "         [-0.0414, -0.3684,  0.3769,  ..., -0.8457, -0.0045,  0.6913],\n",
      "         [ 0.3744, -0.0038,  0.0607,  ..., -0.6827, -0.0576,  0.2549],\n",
      "         ...,\n",
      "         [ 0.8542,  0.5705,  1.1470,  ..., -1.0943, -0.9074,  2.1290],\n",
      "         [ 0.8542,  0.5705,  1.1470,  ..., -1.0943, -0.9074,  2.1290],\n",
      "         [ 0.8542,  0.5705,  1.1470,  ..., -1.0943, -0.9074,  2.1290]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4963, -0.0416,  1.0329,  ...,  0.6975,  0.6768,  1.1981],\n",
      "         [ 0.4663,  0.1831, -0.0108,  ..., -1.0006, -0.6453,  0.7805],\n",
      "         [ 0.5342, -0.4360, -0.0592,  ..., -1.0483,  0.4608,  0.4195],\n",
      "         ...,\n",
      "         [ 0.8564,  0.5691,  1.1477,  ..., -1.0984, -0.9078,  2.1247],\n",
      "         [ 0.8564,  0.5691,  1.1477,  ..., -1.0984, -0.9078,  2.1247],\n",
      "         [ 0.8564,  0.5691,  1.1477,  ..., -1.0984, -0.9078,  2.1247]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4980, -0.0405,  1.0276,  ...,  0.6942,  0.6812,  1.1998],\n",
      "         [ 0.2143, -0.1296, -0.2373,  ..., -0.6042, -0.1877,  0.7845],\n",
      "         [-0.3222,  0.6231,  0.2572,  ..., -1.0180, -0.0662,  0.2330],\n",
      "         ...,\n",
      "         [ 0.8596,  0.5657,  1.1497,  ..., -1.1082, -0.9082,  2.1224],\n",
      "         [ 0.8596,  0.5657,  1.1497,  ..., -1.1082, -0.9082,  2.1224],\n",
      "         [ 0.8596,  0.5657,  1.1497,  ..., -1.1082, -0.9082,  2.1224]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.4988, -0.0392,  1.0210,  ...,  0.6912,  0.6848,  1.2014],\n",
      "         [ 0.0290,  0.1947, -0.1346,  ...,  0.1219,  0.4143, -0.0471],\n",
      "         [ 0.4057, -0.8333, -0.0749,  ...,  0.8932,  0.3975,  1.0082],\n",
      "         ...,\n",
      "         [ 0.8627,  0.5618,  1.1532,  ..., -1.1175, -0.9099,  2.1213],\n",
      "         [ 0.8627,  0.5618,  1.1532,  ..., -1.1175, -0.9099,  2.1213],\n",
      "         [ 0.8627,  0.5618,  1.1532,  ..., -1.1175, -0.9099,  2.1213]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5028, -0.0397,  1.0164,  ...,  0.6901,  0.6886,  1.2026],\n",
      "         [-0.0444, -0.3685,  0.3316,  ..., -0.7903, -0.0217,  0.6645],\n",
      "         [-0.4236,  0.1188,  0.3881,  ..., -0.4747,  0.3880,  0.2050],\n",
      "         ...,\n",
      "         [ 0.8701,  0.5572,  1.1545,  ..., -1.1364, -0.9129,  2.1211],\n",
      "         [ 0.8701,  0.5572,  1.1545,  ..., -1.1364, -0.9129,  2.1211],\n",
      "         [ 0.8701,  0.5572,  1.1545,  ..., -1.1364, -0.9129,  2.1211]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5077, -0.0400,  1.0112,  ...,  0.6873,  0.6913,  1.2020],\n",
      "         [-0.4083,  0.2120, -0.6143,  ...,  0.0815,  0.4101,  0.6250],\n",
      "         [ 0.2500, -0.0621,  0.4818,  ..., -0.9219,  0.1073,  0.7918],\n",
      "         ...,\n",
      "         [ 0.8739,  0.5560,  1.1537,  ..., -1.1491, -0.9150,  2.1183],\n",
      "         [ 0.8739,  0.5560,  1.1537,  ..., -1.1491, -0.9150,  2.1183],\n",
      "         [ 0.8739,  0.5560,  1.1537,  ..., -1.1491, -0.9150,  2.1183]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5135, -0.0400,  1.0067,  ...,  0.6813,  0.6931,  1.2006],\n",
      "         [-0.2489,  0.7083,  0.1830,  ..., -1.1291, -0.2506,  0.3123],\n",
      "         [-0.2070,  0.9453,  0.0578,  ..., -0.7977,  0.5532,  0.4821],\n",
      "         ...,\n",
      "         [ 0.8768,  0.5542,  1.1546,  ..., -1.1640, -0.9174,  2.1168],\n",
      "         [ 0.8768,  0.5542,  1.1546,  ..., -1.1640, -0.9174,  2.1168],\n",
      "         [ 0.8768,  0.5542,  1.1546,  ..., -1.1640, -0.9174,  2.1168]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5178, -0.0384,  1.0043,  ...,  0.6721,  0.6951,  1.1987],\n",
      "         [ 0.0852,  0.0107,  0.0122,  ...,  0.3855,  0.4863,  0.5839],\n",
      "         [-0.1673,  0.3190, -0.6735,  ...,  1.3966,  0.6080,  0.5164],\n",
      "         ...,\n",
      "         [ 0.8787,  0.5536,  1.1556,  ..., -1.1807, -0.9197,  2.1152],\n",
      "         [ 0.8787,  0.5536,  1.1556,  ..., -1.1807, -0.9197,  2.1152],\n",
      "         [ 0.8787,  0.5536,  1.1556,  ..., -1.1807, -0.9197,  2.1152]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5208, -0.0371,  1.0000,  ...,  0.6612,  0.6973,  1.1970],\n",
      "         [ 0.2867,  0.0577, -0.1337,  ..., -0.6490, -0.4328,  0.2403],\n",
      "         [ 0.5250, -0.7568,  0.0031,  ...,  0.4997,  0.4412,  1.0426],\n",
      "         ...,\n",
      "         [ 0.8780,  0.5559,  1.1554,  ..., -1.1907, -0.9193,  2.1128],\n",
      "         [ 0.8780,  0.5559,  1.1554,  ..., -1.1907, -0.9193,  2.1128],\n",
      "         [ 0.8780,  0.5559,  1.1554,  ..., -1.1907, -0.9193,  2.1128]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5211, -0.0384,  0.9981,  ...,  0.6542,  0.6994,  1.1972],\n",
      "         [ 0.3597,  0.7448, -0.2243,  ..., -0.2558,  0.5376,  0.0102],\n",
      "         [ 0.4736, -0.5484, -0.0500,  ...,  0.9904,  0.4072,  1.1058],\n",
      "         ...,\n",
      "         [ 0.8762,  0.5616,  1.1567,  ..., -1.1942, -0.9215,  2.1133],\n",
      "         [ 0.8762,  0.5616,  1.1567,  ..., -1.1942, -0.9215,  2.1133],\n",
      "         [ 0.8762,  0.5616,  1.1567,  ..., -1.1942, -0.9215,  2.1133]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5198, -0.0422,  0.9998,  ...,  0.6507,  0.6996,  1.1989],\n",
      "         [ 0.4374, -0.5281,  0.0155,  ...,  0.0114, -0.3310,  0.3874],\n",
      "         [-0.6149,  0.1689, -0.6043,  ...,  0.0632,  0.6071,  0.4664],\n",
      "         ...,\n",
      "         [ 0.8735,  0.5678,  1.1612,  ..., -1.1978, -0.9295,  2.1176],\n",
      "         [ 0.8735,  0.5678,  1.1612,  ..., -1.1978, -0.9295,  2.1176],\n",
      "         [ 0.8735,  0.5678,  1.1612,  ..., -1.1978, -0.9295,  2.1176]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5166, -0.0465,  1.0032,  ...,  0.6420,  0.7004,  1.1989],\n",
      "         [-0.0947, -0.3625,  0.3550,  ..., -0.7839, -0.0318,  0.6468],\n",
      "         [ 0.3083,  0.0364, -0.0368,  ..., -0.8236, -0.1331,  0.1955],\n",
      "         ...,\n",
      "         [ 0.8695,  0.5703,  1.1653,  ..., -1.2010, -0.9362,  2.1220],\n",
      "         [ 0.8695,  0.5703,  1.1653,  ..., -1.2010, -0.9362,  2.1220],\n",
      "         [ 0.8695,  0.5703,  1.1653,  ..., -1.2010, -0.9362,  2.1220]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5156, -0.0521,  1.0052,  ...,  0.6341,  0.7017,  1.1992],\n",
      "         [ 0.1699, -0.1977, -0.2832,  ..., -0.6586, -0.1725,  0.7586],\n",
      "         [-0.0325, -0.0208,  0.1279,  ...,  0.3684,  0.6363,  0.4837],\n",
      "         ...,\n",
      "         [ 0.8659,  0.5744,  1.1698,  ..., -1.1981, -0.9426,  2.1278],\n",
      "         [ 0.8659,  0.5744,  1.1698,  ..., -1.1981, -0.9426,  2.1278],\n",
      "         [ 0.8659,  0.5744,  1.1698,  ..., -1.1981, -0.9426,  2.1278]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5131, -0.0554,  1.0074,  ...,  0.6298,  0.7030,  1.1985],\n",
      "         [-0.5461,  0.2005,  0.2521,  ..., -0.2752,  0.0635,  0.1960],\n",
      "         [ 0.2901, -0.2542, -0.4302,  ..., -0.2384,  0.5413,  0.1575],\n",
      "         ...,\n",
      "         [ 0.8615,  0.5779,  1.1736,  ..., -1.1879, -0.9473,  2.1312],\n",
      "         [ 0.8615,  0.5779,  1.1736,  ..., -1.1879, -0.9473,  2.1312],\n",
      "         [ 0.8615,  0.5779,  1.1736,  ..., -1.1879, -0.9473,  2.1312]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5098, -0.0607,  1.0062,  ...,  0.6213,  0.7024,  1.1973],\n",
      "         [-0.0331,  0.1778, -0.1498,  ...,  0.0690,  0.4002, -0.0868],\n",
      "         [ 0.4857, -0.7718, -0.1170,  ...,  0.7615,  0.2606,  0.8331],\n",
      "         ...,\n",
      "         [ 0.8555,  0.5787,  1.1764,  ..., -1.1796, -0.9513,  2.1352],\n",
      "         [ 0.8555,  0.5787,  1.1764,  ..., -1.1796, -0.9513,  2.1352],\n",
      "         [ 0.8555,  0.5787,  1.1764,  ..., -1.1796, -0.9513,  2.1352]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5090, -0.0649,  1.0065,  ...,  0.6157,  0.7017,  1.1956],\n",
      "         [-0.1563, -0.3845,  0.3752,  ..., -0.7386, -0.0392,  0.6582],\n",
      "         [ 0.2834,  0.0293, -0.0102,  ..., -0.7559, -0.1292,  0.2163],\n",
      "         ...,\n",
      "         [ 0.8510,  0.5781,  1.1789,  ..., -1.1737, -0.9541,  2.1373],\n",
      "         [ 0.8510,  0.5781,  1.1789,  ..., -1.1737, -0.9541,  2.1373],\n",
      "         [ 0.8510,  0.5781,  1.1789,  ..., -1.1737, -0.9541,  2.1373]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5093, -0.0691,  1.0073,  ...,  0.6113,  0.7012,  1.1939],\n",
      "         [ 0.2067,  0.0675, -0.1273,  ..., -0.5841, -0.4499,  0.2501],\n",
      "         [ 0.1224, -0.3921, -0.2164,  ..., -0.7887,  0.1634,  0.6430],\n",
      "         ...,\n",
      "         [ 0.8464,  0.5751,  1.1811,  ..., -1.1672, -0.9566,  2.1384],\n",
      "         [ 0.8464,  0.5751,  1.1811,  ..., -1.1672, -0.9566,  2.1384],\n",
      "         [ 0.8464,  0.5751,  1.1811,  ..., -1.1672, -0.9566,  2.1384]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4437 :   0%|          | 200/124155 [00:25<5:04:48,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5076, -0.0755,  1.0069,  ...,  0.6096,  0.7006,  1.1944],\n",
      "         [-0.0660,  0.1749, -0.1350,  ...,  0.0540,  0.3854, -0.0854],\n",
      "         [ 0.4724, -0.7882, -0.0581,  ...,  0.7668,  0.1992,  0.8195],\n",
      "         ...,\n",
      "         [ 0.8430,  0.5687,  1.1846,  ..., -1.1665, -0.9594,  2.1383],\n",
      "         [ 0.8430,  0.5687,  1.1846,  ..., -1.1665, -0.9594,  2.1383],\n",
      "         [ 0.8430,  0.5687,  1.1846,  ..., -1.1665, -0.9594,  2.1383]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5085, -0.0821,  1.0106,  ...,  0.6099,  0.7009,  1.1954],\n",
      "         [-0.5984,  0.1540,  0.2919,  ..., -0.2477,  0.0600,  0.1949],\n",
      "         [ 0.2491, -0.5484, -0.1154,  ...,  1.3758,  0.2701,  0.9305],\n",
      "         ...,\n",
      "         [ 0.8379,  0.5654,  1.1862,  ..., -1.1611, -0.9623,  2.1367],\n",
      "         [ 0.8379,  0.5654,  1.1862,  ..., -1.1611, -0.9623,  2.1367],\n",
      "         [ 0.8379,  0.5654,  1.1862,  ..., -1.1611, -0.9623,  2.1367]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5080, -0.0867,  1.0136,  ...,  0.6064,  0.7016,  1.1954],\n",
      "         [-0.1333,  0.4061, -0.3657,  ...,  1.1516,  0.3296,  0.6465],\n",
      "         [ 0.0100, -0.2200,  0.2153,  ...,  0.2570,  0.7379,  0.4710],\n",
      "         ...,\n",
      "         [-0.7363,  0.8524, -0.4541,  ..., -0.0349,  0.0818,  0.3928],\n",
      "         [ 0.4010, -0.3965,  0.6278,  ...,  0.8580,  0.1421,  0.5743],\n",
      "         [-0.1807,  0.2423,  0.1243,  ...,  0.2795,  0.4742, -0.0836]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5061, -0.0902,  1.0147,  ...,  0.6063,  0.7003,  1.1968],\n",
      "         [ 0.2015,  0.0276, -0.0839,  ..., -0.5077, -0.4715,  0.2713],\n",
      "         [-0.1194,  0.2067, -0.3107,  ...,  1.0225,  0.6387,  0.5166],\n",
      "         ...,\n",
      "         [ 0.8289,  0.5508,  1.1777,  ..., -1.1374, -0.9612,  2.1216],\n",
      "         [ 0.8289,  0.5508,  1.1777,  ..., -1.1374, -0.9612,  2.1216],\n",
      "         [ 0.8289,  0.5508,  1.1777,  ..., -1.1374, -0.9612,  2.1216]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5045, -0.0948,  1.0150,  ...,  0.6069,  0.6995,  1.1990],\n",
      "         [ 0.4083, -0.4022, -0.2848,  ..., -0.9589,  0.2022,  0.3122],\n",
      "         [-0.5501, -0.0811,  0.5377,  ..., -0.2525,  0.4434,  0.3346],\n",
      "         ...,\n",
      "         [ 0.8260,  0.5432,  1.1705,  ..., -1.1243, -0.9613,  2.1147],\n",
      "         [ 0.8260,  0.5432,  1.1705,  ..., -1.1243, -0.9613,  2.1147],\n",
      "         [ 0.8260,  0.5432,  1.1705,  ..., -1.1243, -0.9613,  2.1147]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5039, -0.1042,  1.0152,  ...,  0.6044,  0.6987,  1.2038],\n",
      "         [-0.0981,  0.1476, -0.1315,  ...,  0.1002,  0.3628, -0.0774],\n",
      "         [ 0.4337, -0.8296,  0.0067,  ...,  0.9125,  0.1724,  0.8558],\n",
      "         ...,\n",
      "         [ 0.8262,  0.5328,  1.1647,  ..., -1.1187, -0.9648,  2.1127],\n",
      "         [ 0.8262,  0.5328,  1.1647,  ..., -1.1187, -0.9648,  2.1127],\n",
      "         [ 0.8262,  0.5328,  1.1647,  ..., -1.1187, -0.9648,  2.1127]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5064, -0.1153,  1.0190,  ...,  0.6058,  0.6974,  1.2085],\n",
      "         [ 0.3941,  0.0390, -0.0958,  ..., -1.0114, -0.6646,  0.7404],\n",
      "         [-0.5683,  0.1568, -0.4147,  ...,  0.0821,  0.5716,  0.7843],\n",
      "         ...,\n",
      "         [ 0.8285,  0.5223,  1.1620,  ..., -1.1132, -0.9707,  2.1133],\n",
      "         [ 0.8285,  0.5223,  1.1620,  ..., -1.1132, -0.9707,  2.1133],\n",
      "         [ 0.8285,  0.5223,  1.1620,  ..., -1.1132, -0.9707,  2.1133]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5080, -0.1240,  1.0209,  ...,  0.6107,  0.6968,  1.2148],\n",
      "         [-0.0947,  0.1328, -0.1341,  ...,  0.1062,  0.3506, -0.0778],\n",
      "         [ 0.4601, -0.8760,  0.0189,  ...,  0.9671,  0.1620,  0.8889],\n",
      "         ...,\n",
      "         [ 0.8300,  0.5137,  1.1587,  ..., -1.1050, -0.9769,  2.1147],\n",
      "         [ 0.8300,  0.5137,  1.1587,  ..., -1.1050, -0.9769,  2.1147],\n",
      "         [ 0.8300,  0.5137,  1.1587,  ..., -1.1050, -0.9769,  2.1147]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 5.1278e-01, -1.3253e-01,  1.0242e+00,  ...,  6.1621e-01,\n",
      "           6.9564e-01,  1.2188e+00],\n",
      "         [ 6.7229e-01, -6.4060e-01,  5.7739e-02,  ..., -4.2727e-01,\n",
      "          -2.2931e-01,  1.6194e-01],\n",
      "         [-8.3627e-01,  2.0465e-03, -5.3073e-01,  ...,  1.7626e-01,\n",
      "           5.4075e-01,  7.0463e-01],\n",
      "         ...,\n",
      "         [ 8.3118e-01,  5.0747e-01,  1.1550e+00,  ..., -1.1034e+00,\n",
      "          -9.7934e-01,  2.1142e+00],\n",
      "         [ 8.3118e-01,  5.0747e-01,  1.1550e+00,  ..., -1.1034e+00,\n",
      "          -9.7934e-01,  2.1142e+00],\n",
      "         [ 8.3118e-01,  5.0747e-01,  1.1550e+00,  ..., -1.1034e+00,\n",
      "          -9.7934e-01,  2.1142e+00]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5152, -0.1357,  1.0206,  ...,  0.6198,  0.6949,  1.2197],\n",
      "         [-0.1125, -0.1000, -0.0884,  ...,  0.9293,  0.2421,  0.8327],\n",
      "         [-0.8501, -0.1071,  0.2762,  ..., -0.4063,  0.3851, -0.1195],\n",
      "         ...,\n",
      "         [ 0.8335,  0.4979,  1.1503,  ..., -1.1051, -0.9799,  2.1110],\n",
      "         [ 0.8335,  0.4979,  1.1503,  ..., -1.1051, -0.9799,  2.1110],\n",
      "         [ 0.8335,  0.4979,  1.1503,  ..., -1.1051, -0.9799,  2.1110]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5179, -0.1337,  1.0152,  ...,  0.6227,  0.6932,  1.2191],\n",
      "         [-0.0110,  0.3207, -0.4103,  ...,  1.1774,  0.2613,  0.6596],\n",
      "         [-0.3957, -0.0054, -0.5293,  ..., -0.0956,  0.6545,  0.5654],\n",
      "         ...,\n",
      "         [ 0.8374,  0.4869,  1.1433,  ..., -1.1189, -0.9765,  2.1071],\n",
      "         [ 0.8374,  0.4869,  1.1433,  ..., -1.1189, -0.9765,  2.1071],\n",
      "         [ 0.8374,  0.4869,  1.1433,  ..., -1.1189, -0.9765,  2.1071]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5189, -0.1291,  1.0098,  ...,  0.6260,  0.6917,  1.2184],\n",
      "         [ 0.0557, -0.1173, -0.9080,  ..., -1.2065, -0.3876,  0.3489],\n",
      "         [ 0.0203,  0.4060,  0.2988,  ...,  0.8689,  0.9018,  0.0946],\n",
      "         ...,\n",
      "         [ 0.8378,  0.4798,  1.1380,  ..., -1.1272, -0.9688,  2.0998],\n",
      "         [ 0.8378,  0.4798,  1.1380,  ..., -1.1272, -0.9688,  2.0998],\n",
      "         [ 0.8378,  0.4798,  1.1380,  ..., -1.1272, -0.9688,  2.0998]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5191, -0.1253,  1.0065,  ...,  0.6276,  0.6899,  1.2186],\n",
      "         [-0.0266,  0.1071, -0.1688,  ...,  0.0584,  0.3248, -0.0736],\n",
      "         [ 0.6214, -0.9781,  0.0115,  ...,  0.7552,  0.1788,  0.9031],\n",
      "         ...,\n",
      "         [ 0.8394,  0.4755,  1.1348,  ..., -1.1411, -0.9643,  2.0966],\n",
      "         [ 0.8394,  0.4755,  1.1348,  ..., -1.1411, -0.9643,  2.0966],\n",
      "         [ 0.8394,  0.4755,  1.1348,  ..., -1.1411, -0.9643,  2.0966]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5217, -0.1233,  1.0073,  ...,  0.6353,  0.6882,  1.2193],\n",
      "         [ 0.0836, -0.1382, -0.9231,  ..., -1.2375, -0.3914,  0.3344],\n",
      "         [-0.2517,  0.4159,  0.5317,  ..., -1.1767,  0.2747,  0.3118],\n",
      "         ...,\n",
      "         [ 0.8392,  0.4736,  1.1355,  ..., -1.1553, -0.9617,  2.0957],\n",
      "         [ 0.8392,  0.4736,  1.1355,  ..., -1.1553, -0.9617,  2.0957],\n",
      "         [ 0.8392,  0.4736,  1.1355,  ..., -1.1553, -0.9617,  2.0957]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5239, -0.1185,  1.0073,  ...,  0.6422,  0.6860,  1.2191],\n",
      "         [-0.0133,  0.1146, -0.1920,  ...,  0.0378,  0.3246, -0.0792],\n",
      "         [ 0.6468, -0.9852,  0.0265,  ...,  0.6949,  0.1966,  0.8980],\n",
      "         ...,\n",
      "         [ 0.8383,  0.4777,  1.1353,  ..., -1.1641, -0.9593,  2.0952],\n",
      "         [ 0.8383,  0.4777,  1.1353,  ..., -1.1641, -0.9593,  2.0952],\n",
      "         [ 0.8383,  0.4777,  1.1353,  ..., -1.1641, -0.9593,  2.0952]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5279, -0.1129,  1.0108,  ...,  0.6503,  0.6841,  1.2192],\n",
      "         [ 0.5306, -0.0630, -0.1685,  ..., -1.1460, -0.6407,  0.6937],\n",
      "         [ 0.6517, -0.6759, -0.1103,  ..., -1.2666,  0.3850,  0.3624],\n",
      "         ...,\n",
      "         [ 0.8343,  0.4869,  1.1382,  ..., -1.1707, -0.9570,  2.0931],\n",
      "         [ 0.8343,  0.4869,  1.1382,  ..., -1.1707, -0.9570,  2.0931],\n",
      "         [ 0.8343,  0.4869,  1.1382,  ..., -1.1707, -0.9570,  2.0931]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5317, -0.1082,  1.0125,  ...,  0.6582,  0.6833,  1.2221],\n",
      "         [ 0.5296, -0.0542, -0.1746,  ..., -1.1570, -0.6358,  0.6874],\n",
      "         [-0.4146,  0.2088, -0.5567,  ..., -0.1672,  0.6240,  0.7013],\n",
      "         ...,\n",
      "         [ 0.8328,  0.4956,  1.1419,  ..., -1.1767, -0.9562,  2.0934],\n",
      "         [ 0.8328,  0.4956,  1.1419,  ..., -1.1767, -0.9562,  2.0934],\n",
      "         [ 0.8328,  0.4956,  1.1419,  ..., -1.1767, -0.9562,  2.0934]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5334, -0.1013,  1.0115,  ...,  0.6680,  0.6832,  1.2252],\n",
      "         [-0.5508,  0.7349, -0.1943,  ..., -0.6948,  0.0986,  0.8027],\n",
      "         [-0.4633, -0.4746,  0.1871,  ..., -0.1904,  0.3663,  0.5296],\n",
      "         ...,\n",
      "         [ 0.8297,  0.5022,  1.1446,  ..., -1.1813, -0.9556,  2.0927],\n",
      "         [ 0.8297,  0.5022,  1.1446,  ..., -1.1813, -0.9556,  2.0927],\n",
      "         [ 0.8297,  0.5022,  1.1446,  ..., -1.1813, -0.9556,  2.0927]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5380, -0.0966,  1.0076,  ...,  0.6769,  0.6822,  1.2269],\n",
      "         [ 0.4533, -0.3573,  0.1184,  ..., -0.0745, -0.2911,  0.2318],\n",
      "         [-0.6342,  0.3957, -0.8135,  ..., -0.0866,  0.6223,  0.4123],\n",
      "         ...,\n",
      "         [ 0.8260,  0.5089,  1.1461,  ..., -1.1777, -0.9575,  2.0925],\n",
      "         [ 0.8260,  0.5089,  1.1461,  ..., -1.1777, -0.9575,  2.0925],\n",
      "         [ 0.8260,  0.5089,  1.1461,  ..., -1.1777, -0.9575,  2.0925]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5417, -0.0921,  1.0040,  ...,  0.6797,  0.6820,  1.2280],\n",
      "         [ 0.2537,  0.8458, -0.2685,  ..., -0.2966,  0.4601,  0.0106],\n",
      "         [ 0.5727, -0.6480,  0.1703,  ...,  1.0704,  0.2741,  1.1947],\n",
      "         ...,\n",
      "         [ 0.8222,  0.5176,  1.1494,  ..., -1.1689, -0.9589,  2.0926],\n",
      "         [ 0.8222,  0.5176,  1.1494,  ..., -1.1689, -0.9589,  2.0926],\n",
      "         [ 0.8222,  0.5176,  1.1494,  ..., -1.1689, -0.9589,  2.0926]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5453, -0.0878,  1.0005,  ...,  0.6803,  0.6812,  1.2289],\n",
      "         [-0.0456,  0.2257, -0.2523,  ...,  0.0995,  0.3097, -0.1017],\n",
      "         [ 0.5649, -0.8701,  0.0462,  ...,  0.9211,  0.2327,  0.9119],\n",
      "         ...,\n",
      "         [ 0.8185,  0.5280,  1.1504,  ..., -1.1568, -0.9581,  2.0935],\n",
      "         [ 0.8185,  0.5280,  1.1504,  ..., -1.1568, -0.9581,  2.0935],\n",
      "         [ 0.8185,  0.5280,  1.1504,  ..., -1.1568, -0.9581,  2.0935]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5497, -0.0842,  0.9989,  ...,  0.6823,  0.6792,  1.2288],\n",
      "         [-0.5979,  0.0357,  0.1008,  ..., -0.2303,  0.1180,  0.1986],\n",
      "         [-0.0109,  0.9590, -0.3519,  ...,  0.7374,  0.9128, -0.0502],\n",
      "         ...,\n",
      "         [ 0.8132,  0.5383,  1.1508,  ..., -1.1487, -0.9547,  2.0916],\n",
      "         [ 0.8132,  0.5383,  1.1508,  ..., -1.1487, -0.9547,  2.0916],\n",
      "         [ 0.8132,  0.5383,  1.1508,  ..., -1.1487, -0.9547,  2.0916]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5530, -0.0809,  0.9944,  ...,  0.6742,  0.6764,  1.2250],\n",
      "         [-0.0641,  0.2540, -0.2566,  ...,  0.1446,  0.2963, -0.0938],\n",
      "         [ 0.5303, -0.8653,  0.0373,  ...,  0.9881,  0.2147,  0.9139],\n",
      "         ...,\n",
      "         [ 0.8044,  0.5452,  1.1474,  ..., -1.1395, -0.9464,  2.0825],\n",
      "         [ 0.8044,  0.5452,  1.1474,  ..., -1.1395, -0.9464,  2.0825],\n",
      "         [ 0.8044,  0.5452,  1.1474,  ..., -1.1395, -0.9464,  2.0825]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5567, -0.0777,  0.9907,  ...,  0.6695,  0.6736,  1.2219],\n",
      "         [ 0.4099,  0.0281, -0.2093,  ..., -1.0526, -0.6178,  0.6936],\n",
      "         [ 0.0447,  0.3280, -0.2694,  ...,  1.2006,  0.4866,  0.7436],\n",
      "         ...,\n",
      "         [ 0.7977,  0.5489,  1.1396,  ..., -1.1251, -0.9375,  2.0729],\n",
      "         [ 0.7977,  0.5489,  1.1396,  ..., -1.1251, -0.9375,  2.0729],\n",
      "         [ 0.7977,  0.5489,  1.1396,  ..., -1.1251, -0.9375,  2.0729]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5557, -0.0720,  0.9848,  ...,  0.6634,  0.6723,  1.2179],\n",
      "         [-0.0845,  0.2686, -0.2588,  ...,  0.1751,  0.2905, -0.0767],\n",
      "         [ 0.4832, -0.8878, -0.0029,  ...,  1.0019,  0.2108,  0.9177],\n",
      "         ...,\n",
      "         [ 0.7901,  0.5434,  1.1367,  ..., -1.0996, -0.9250,  2.0598],\n",
      "         [ 0.7901,  0.5434,  1.1367,  ..., -1.0996, -0.9250,  2.0598],\n",
      "         [ 0.7901,  0.5434,  1.1367,  ..., -1.0996, -0.9250,  2.0598]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5570, -0.0669,  0.9812,  ...,  0.6589,  0.6715,  1.2137],\n",
      "         [ 0.3663,  0.0320, -0.2040,  ..., -1.0165, -0.5980,  0.7147],\n",
      "         [-0.6702,  0.3907, -0.6505,  ...,  0.3437,  0.5541,  0.6819],\n",
      "         ...,\n",
      "         [ 0.7835,  0.5418,  1.1349,  ..., -1.0775, -0.9126,  2.0475],\n",
      "         [ 0.7835,  0.5418,  1.1349,  ..., -1.0775, -0.9126,  2.0475],\n",
      "         [ 0.7835,  0.5418,  1.1349,  ..., -1.0775, -0.9126,  2.0475]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5554, -0.0618,  0.9763,  ...,  0.6552,  0.6723,  1.2110],\n",
      "         [ 0.2534,  0.0384, -0.1814,  ..., -0.4586, -0.4560,  0.2681],\n",
      "         [ 0.4141, -0.4814, -0.3241,  ..., -0.9872,  0.5275,  0.0847],\n",
      "         ...,\n",
      "         [ 0.7780,  0.5381,  1.1389,  ..., -1.0649, -0.9016,  2.0383],\n",
      "         [ 0.7780,  0.5381,  1.1389,  ..., -1.0649, -0.9016,  2.0383],\n",
      "         [ 0.7780,  0.5381,  1.1389,  ..., -1.0649, -0.9016,  2.0383]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5521, -0.0584,  0.9718,  ...,  0.6500,  0.6732,  1.2092],\n",
      "         [ 0.4888,  0.6226, -0.0023,  ..., -0.6195, -0.2161,  0.2537],\n",
      "         [-0.6973,  0.4172, -0.6104,  ...,  0.3455,  0.7176,  0.6071],\n",
      "         ...,\n",
      "         [ 0.7743,  0.5358,  1.1456,  ..., -1.0598, -0.8911,  2.0278],\n",
      "         [ 0.7743,  0.5358,  1.1456,  ..., -1.0598, -0.8911,  2.0278],\n",
      "         [ 0.7743,  0.5358,  1.1456,  ..., -1.0598, -0.8911,  2.0278]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5473, -0.0552,  0.9668,  ...,  0.6432,  0.6745,  1.2081],\n",
      "         [-0.0950,  0.2375, -0.2075,  ...,  0.1261,  0.2990, -0.0464],\n",
      "         [ 0.4128, -0.9668,  0.0275,  ...,  0.8842,  0.2290,  0.9388],\n",
      "         ...,\n",
      "         [ 0.7719,  0.5347,  1.1547,  ..., -1.0623, -0.8820,  2.0192],\n",
      "         [ 0.7719,  0.5347,  1.1547,  ..., -1.0623, -0.8820,  2.0192],\n",
      "         [ 0.7719,  0.5347,  1.1547,  ..., -1.0623, -0.8820,  2.0192]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5440, -0.0525,  0.9640,  ...,  0.6410,  0.6761,  1.2080],\n",
      "         [-0.0951,  0.2279, -0.1952,  ...,  0.1130,  0.3017, -0.0441],\n",
      "         [ 0.3973, -0.9652,  0.0497,  ...,  0.8678,  0.2348,  0.9395],\n",
      "         ...,\n",
      "         [ 0.7694,  0.5375,  1.1656,  ..., -1.0614, -0.8734,  2.0118],\n",
      "         [ 0.7694,  0.5375,  1.1656,  ..., -1.0614, -0.8734,  2.0118],\n",
      "         [ 0.7694,  0.5375,  1.1656,  ..., -1.0614, -0.8734,  2.0118]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5432, -0.0500,  0.9641,  ...,  0.6415,  0.6771,  1.2078],\n",
      "         [-0.1427,  0.6495, -0.1830,  ..., -1.3105,  0.1322,  0.2856],\n",
      "         [-0.7593,  0.4593, -0.4505,  ...,  0.0043,  0.6909,  0.5179],\n",
      "         ...,\n",
      "         [ 0.7644,  0.5448,  1.1778,  ..., -1.0648, -0.8664,  2.0054],\n",
      "         [ 0.7644,  0.5448,  1.1778,  ..., -1.0648, -0.8664,  2.0054],\n",
      "         [ 0.7644,  0.5448,  1.1778,  ..., -1.0648, -0.8664,  2.0054]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5433, -0.0472,  0.9639,  ...,  0.6416,  0.6781,  1.2089],\n",
      "         [ 0.2448,  0.0111, -0.1640,  ..., -0.5556, -0.4294,  0.2698],\n",
      "         [ 0.3891, -0.8724,  0.1558,  ...,  0.3420,  0.2980,  1.0367],\n",
      "         ...,\n",
      "         [ 0.7609,  0.5516,  1.1894,  ..., -1.0714, -0.8602,  2.0001],\n",
      "         [ 0.7609,  0.5516,  1.1894,  ..., -1.0714, -0.8602,  2.0001],\n",
      "         [ 0.7609,  0.5516,  1.1894,  ..., -1.0714, -0.8602,  2.0001]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5409, -0.0473,  0.9644,  ...,  0.6419,  0.6789,  1.2110],\n",
      "         [ 0.3541, -0.8686, -0.4621,  ..., -0.7901, -0.2391,  0.1751],\n",
      "         [-0.6579,  0.0411,  0.2714,  ..., -0.3613,  0.4881,  0.2471],\n",
      "         ...,\n",
      "         [ 0.7575,  0.5560,  1.2020,  ..., -1.0818, -0.8548,  1.9963],\n",
      "         [ 0.7575,  0.5560,  1.2020,  ..., -1.0818, -0.8548,  1.9963],\n",
      "         [ 0.7575,  0.5560,  1.2020,  ..., -1.0818, -0.8548,  1.9963]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5374, -0.0479,  0.9654,  ...,  0.6427,  0.6803,  1.2128],\n",
      "         [-0.6787,  0.5756, -0.7182,  ...,  0.2896,  0.3058,  0.5646],\n",
      "         [-0.0815,  0.0278, -0.1586,  ..., -0.1652,  0.1513,  0.5366],\n",
      "         ...,\n",
      "         [ 0.7568,  0.5567,  1.2160,  ..., -1.0952, -0.8505,  1.9943],\n",
      "         [ 0.7568,  0.5567,  1.2160,  ..., -1.0952, -0.8505,  1.9943],\n",
      "         [ 0.7568,  0.5567,  1.2160,  ..., -1.0952, -0.8505,  1.9943]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5346, -0.0480,  0.9644,  ...,  0.6407,  0.6795,  1.2133],\n",
      "         [-0.6816,  0.5886, -0.7085,  ...,  0.2638,  0.3062,  0.5560],\n",
      "         [-0.4845, -0.3709,  0.1854,  ..., -0.7413,  0.3207,  0.5160],\n",
      "         ...,\n",
      "         [ 0.7513,  0.5611,  1.2226,  ..., -1.1109, -0.8440,  1.9898],\n",
      "         [ 0.7513,  0.5611,  1.2226,  ..., -1.1109, -0.8440,  1.9898],\n",
      "         [ 0.7513,  0.5611,  1.2226,  ..., -1.1109, -0.8440,  1.9898]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5343, -0.0503,  0.9627,  ...,  0.6346,  0.6772,  1.2146],\n",
      "         [-0.2481, -0.4650,  0.1978,  ..., -0.9688, -0.0168,  0.6599],\n",
      "         [-0.5419,  0.8522, -0.0643,  ..., -0.8053,  0.4499,  0.7145],\n",
      "         ...,\n",
      "         [ 0.7527,  0.5617,  1.2233,  ..., -1.1328, -0.8392,  1.9887],\n",
      "         [ 0.7527,  0.5617,  1.2233,  ..., -1.1328, -0.8392,  1.9887],\n",
      "         [ 0.7527,  0.5617,  1.2233,  ..., -1.1328, -0.8392,  1.9887]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5360, -0.0540,  0.9587,  ...,  0.6285,  0.6757,  1.2158],\n",
      "         [-0.5433,  0.9447, -0.2913,  ..., -0.6744,  0.0592,  0.6612],\n",
      "         [ 0.3869, -0.5387, -0.0678,  ..., -0.2601,  0.1705,  0.0582],\n",
      "         ...,\n",
      "         [ 0.7564,  0.5613,  1.2222,  ..., -1.1492, -0.8353,  1.9894],\n",
      "         [ 0.7564,  0.5613,  1.2222,  ..., -1.1492, -0.8353,  1.9894],\n",
      "         [ 0.7564,  0.5613,  1.2222,  ..., -1.1492, -0.8353,  1.9894]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5390, -0.0565,  0.9525,  ...,  0.6200,  0.6727,  1.2151],\n",
      "         [ 0.1867,  0.9843, -0.2548,  ..., -0.3092,  0.3997,  0.0156],\n",
      "         [ 0.3560, -0.5852,  0.2064,  ...,  0.7883,  0.2600,  1.1478],\n",
      "         ...,\n",
      "         [ 0.7583,  0.5589,  1.2213,  ..., -1.1679, -0.8327,  1.9892],\n",
      "         [ 0.7583,  0.5589,  1.2213,  ..., -1.1679, -0.8327,  1.9892],\n",
      "         [ 0.7583,  0.5589,  1.2213,  ..., -1.1679, -0.8327,  1.9892]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5413, -0.0592,  0.9485,  ...,  0.6120,  0.6692,  1.2146],\n",
      "         [-0.0838,  0.6787, -0.2046,  ..., -1.3572,  0.0915,  0.2388],\n",
      "         [-0.4086,  0.5788,  0.3810,  ..., -1.4054,  0.0568,  0.2167],\n",
      "         ...,\n",
      "         [ 0.7599,  0.5571,  1.2224,  ..., -1.1884, -0.8302,  1.9900],\n",
      "         [ 0.7599,  0.5571,  1.2224,  ..., -1.1884, -0.8302,  1.9900],\n",
      "         [ 0.7599,  0.5571,  1.2224,  ..., -1.1884, -0.8302,  1.9900]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5435, -0.0620,  0.9426,  ...,  0.6044,  0.6658,  1.2151],\n",
      "         [ 0.2998,  0.0349, -0.1731,  ..., -0.6371, -0.4304,  0.2380],\n",
      "         [-0.7233,  0.3566, -0.6933,  ..., -0.0849,  0.6692,  0.3763],\n",
      "         ...,\n",
      "         [ 0.7604,  0.5556,  1.2242,  ..., -1.2121, -0.8288,  1.9907],\n",
      "         [ 0.7604,  0.5556,  1.2242,  ..., -1.2121, -0.8288,  1.9907],\n",
      "         [ 0.7604,  0.5556,  1.2242,  ..., -1.2121, -0.8288,  1.9907]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5426, -0.0647,  0.9358,  ...,  0.5989,  0.6616,  1.2149],\n",
      "         [-0.0758,  0.1902, -0.1901,  ..., -0.0596,  0.3082, -0.0674],\n",
      "         [ 0.2789, -0.8300,  0.0619,  ...,  0.5860,  0.2357,  0.8650],\n",
      "         ...,\n",
      "         [ 0.7599,  0.5536,  1.2258,  ..., -1.2293, -0.8275,  1.9895],\n",
      "         [ 0.7599,  0.5536,  1.2258,  ..., -1.2293, -0.8275,  1.9895],\n",
      "         [ 0.7599,  0.5536,  1.2258,  ..., -1.2293, -0.8275,  1.9895]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5430, -0.0680,  0.9306,  ...,  0.5981,  0.6588,  1.2151],\n",
      "         [ 0.4607,  0.0474, -0.2296,  ..., -1.1205, -0.6765,  0.6518],\n",
      "         [-0.7094,  0.7750, -0.3143,  ...,  0.0261,  0.0398,  0.5994],\n",
      "         ...,\n",
      "         [ 0.7579,  0.5530,  1.2273,  ..., -1.2460, -0.8263,  1.9877],\n",
      "         [ 0.7579,  0.5531,  1.2273,  ..., -1.2460, -0.8263,  1.9877],\n",
      "         [ 0.7579,  0.5531,  1.2273,  ..., -1.2460, -0.8263,  1.9877]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5397, -0.0664,  0.9270,  ...,  0.5933,  0.6578,  1.2140],\n",
      "         [ 0.3084,  0.0798, -0.1718,  ..., -0.5908, -0.4325,  0.2272],\n",
      "         [ 0.3027, -0.7977,  0.1328,  ...,  0.0100,  0.2590,  0.9450],\n",
      "         ...,\n",
      "         [ 0.7466,  0.5572,  1.2294,  ..., -1.2542, -0.8177,  1.9781],\n",
      "         [ 0.7466,  0.5572,  1.2294,  ..., -1.2542, -0.8177,  1.9781],\n",
      "         [ 0.7466,  0.5572,  1.2294,  ..., -1.2542, -0.8177,  1.9781]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5339, -0.0662,  0.9246,  ...,  0.5884,  0.6574,  1.2125],\n",
      "         [-0.6842,  0.6712, -0.6924,  ...,  0.1392,  0.2947,  0.4888],\n",
      "         [-0.4870, -0.3463,  0.0512,  ..., -0.7909,  0.3378,  0.5020],\n",
      "         ...,\n",
      "         [ 0.7355,  0.5617,  1.2309,  ..., -1.2614, -0.8091,  1.9666],\n",
      "         [ 0.7355,  0.5617,  1.2309,  ..., -1.2614, -0.8091,  1.9666],\n",
      "         [ 0.7355,  0.5617,  1.2309,  ..., -1.2614, -0.8091,  1.9666]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5325, -0.0684,  0.9235,  ...,  0.5793,  0.6554,  1.2112],\n",
      "         [ 0.3919, -0.8475, -0.4998,  ..., -0.7845, -0.2602,  0.1257],\n",
      "         [-0.5665,  0.0864,  0.1728,  ..., -0.6459,  0.4957,  0.1525],\n",
      "         ...,\n",
      "         [ 0.7301,  0.5605,  1.2325,  ..., -1.2792, -0.8016,  1.9572],\n",
      "         [ 0.7301,  0.5605,  1.2325,  ..., -1.2792, -0.8016,  1.9572],\n",
      "         [ 0.7301,  0.5605,  1.2325,  ..., -1.2792, -0.8016,  1.9572]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5308, -0.0697,  0.9229,  ...,  0.5726,  0.6529,  1.2111],\n",
      "         [ 0.3048,  0.1126, -0.1945,  ..., -0.5620, -0.4166,  0.2142],\n",
      "         [ 0.2467, -0.7606,  0.1562,  ..., -0.0969,  0.2908,  0.9066],\n",
      "         ...,\n",
      "         [ 0.7396,  0.5504,  1.2327,  ..., -1.3021, -0.7966,  1.9546],\n",
      "         [ 0.7396,  0.5504,  1.2327,  ..., -1.3021, -0.7966,  1.9546],\n",
      "         [ 0.7396,  0.5504,  1.2327,  ..., -1.3021, -0.7966,  1.9546]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5276, -0.0738,  0.9242,  ...,  0.5684,  0.6509,  1.2115],\n",
      "         [-0.5126,  0.9223, -0.2542,  ..., -0.7765,  0.0977,  0.6152],\n",
      "         [-0.5461, -0.1538, -0.3042,  ...,  0.3259,  0.4129,  1.0751],\n",
      "         ...,\n",
      "         [ 0.7479,  0.5405,  1.2349,  ..., -1.3216, -0.7923,  1.9527],\n",
      "         [ 0.7479,  0.5405,  1.2349,  ..., -1.3216, -0.7923,  1.9527],\n",
      "         [ 0.7479,  0.5405,  1.2349,  ..., -1.3216, -0.7923,  1.9527]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5263, -0.0776,  0.9226,  ...,  0.5619,  0.6479,  1.2120],\n",
      "         [-0.0828,  0.1739, -0.1622,  ..., -0.1126,  0.3566, -0.0698],\n",
      "         [ 0.1747, -0.7851,  0.0908,  ...,  0.3651,  0.2949,  0.8059],\n",
      "         ...,\n",
      "         [ 0.7611,  0.5298,  1.2369,  ..., -1.3436, -0.7900,  1.9557],\n",
      "         [ 0.7611,  0.5298,  1.2369,  ..., -1.3436, -0.7900,  1.9557],\n",
      "         [ 0.7611,  0.5298,  1.2369,  ..., -1.3436, -0.7900,  1.9557]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5264, -0.0834,  0.9229,  ...,  0.5585,  0.6451,  1.2120],\n",
      "         [ 0.0245,  0.6195, -0.5300,  ...,  0.9917,  0.2889,  0.5128],\n",
      "         [ 0.4231, -0.9801,  0.2873,  ...,  0.0103,  0.2474,  0.9329],\n",
      "         ...,\n",
      "         [ 0.7771,  0.5197,  1.2394,  ..., -1.3673, -0.7884,  1.9611],\n",
      "         [ 0.7771,  0.5197,  1.2394,  ..., -1.3673, -0.7884,  1.9611],\n",
      "         [ 0.7771,  0.5197,  1.2394,  ..., -1.3673, -0.7884,  1.9611]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5259, -0.0901,  0.9263,  ...,  0.5593,  0.6437,  1.2134],\n",
      "         [-0.0710,  0.1471, -0.1558,  ..., -0.1551,  0.3682, -0.0663],\n",
      "         [ 0.2226, -0.8344,  0.1125,  ...,  0.2951,  0.3101,  0.8262],\n",
      "         ...,\n",
      "         [ 0.7938,  0.5096,  1.2431,  ..., -1.3945, -0.7873,  1.9699],\n",
      "         [ 0.7938,  0.5096,  1.2431,  ..., -1.3945, -0.7873,  1.9699],\n",
      "         [ 0.7938,  0.5096,  1.2431,  ..., -1.3945, -0.7873,  1.9699]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5272, -0.0965,  0.9291,  ...,  0.5646,  0.6421,  1.2140],\n",
      "         [-0.3980, -0.1756,  0.4244,  ..., -0.3434,  0.6267,  0.6206],\n",
      "         [-1.1329,  1.0004,  0.0891,  ...,  0.1985,  0.1640,  0.9231],\n",
      "         ...,\n",
      "         [ 0.8065,  0.5022,  1.2470,  ..., -1.4171, -0.7868,  1.9750],\n",
      "         [ 0.8065,  0.5022,  1.2470,  ..., -1.4171, -0.7868,  1.9750],\n",
      "         [ 0.8065,  0.5022,  1.2470,  ..., -1.4171, -0.7868,  1.9750]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5288, -0.1031,  0.9283,  ...,  0.5711,  0.6389,  1.2141],\n",
      "         [ 0.3205, -0.3355, -0.5744,  ..., -1.0269,  0.1163,  0.1941],\n",
      "         [-0.3029,  0.5657,  0.0938,  ..., -1.0409,  0.1249,  0.3472],\n",
      "         ...,\n",
      "         [ 0.8170,  0.4961,  1.2495,  ..., -1.4379, -0.7874,  1.9807],\n",
      "         [ 0.8170,  0.4961,  1.2495,  ..., -1.4379, -0.7874,  1.9807],\n",
      "         [ 0.8170,  0.4961,  1.2495,  ..., -1.4379, -0.7874,  1.9807]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.5306, -0.1118,  0.9279,  ...,  0.5773,  0.6347,  1.2159],\n",
      "         [-0.0598,  0.1320, -0.1594,  ..., -0.1910,  0.3667, -0.0710],\n",
      "         [ 0.2808, -0.8824,  0.1097,  ...,  0.2980,  0.2971,  0.8428],\n",
      "         ...,\n",
      "         [ 0.8293,  0.4922,  1.2508,  ..., -1.4530, -0.7910,  1.9891],\n",
      "         [ 0.8293,  0.4922,  1.2508,  ..., -1.4530, -0.7910,  1.9891],\n",
      "         [ 0.8293,  0.4922,  1.2508,  ..., -1.4530, -0.7910,  1.9891]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    with tqdm.tqdm(total=len(dataloader)) as prbar:\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            loss = training_step(model, batch, tokenizer.vocab_size, criterion, optimizer, device)\n",
    "            epoch_loss += loss\n",
    "        \n",
    "            if i % 100 == 0:\n",
    "                #print(f'Done {i/len(dataloader) * 100:.2f}%, Loss: {loss:.4f}')\n",
    "                metrics_str = f\"Loss: {round(loss, 4)} \"\n",
    "                #for k, v in metrics_dict.items():\n",
    "                #    metrics_str += f\"{k}: {round(float(v), 4)} \"\n",
    "                prbar.set_description(metrics_str)\n",
    "                prbar.update(100)\n",
    "    \n",
    "    epoch_loss /= len(dataloader)\n",
    "    losses.append(epoch_loss)\n",
    "    \n",
    "    plot_losses(losses)\n",
    "    #torch.save(model.state_dict(), \"rnn.pt\")\n",
    "    torch.save(model, \"rnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(\"rnn.pt\", weights_only=True))\n",
    "model = torch.load(\"rnn.pt\", weights_only=False)\n",
    "\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>пилите, шура, пилите. они теждий алерса!<eos>',\n",
       " '<bos>пилите, шура, пилите. они дотибь, не при нелоповидиет!<eos>',\n",
       " '<bos>пилите, шура, пилите. они \"умолонысо крмем дреб.?<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<bos>пилите, шура, пилите. они вочанмькие.<eos>',\n",
       " '<bos>пилите, шура, пилите. они вессвкацься. естенинто вснагак.ой распулитлаю доколоне не медизар.<eos>',\n",
       " '<bos>пилите, шура, пилите. они к, козьк,ся кролю из когай и не ужы.<eos>',\n",
       " '<bos>пилите, шура, пилите. они хорит, в сивемока! это бым упесостесям...<eos>',\n",
       " '<bos>пилите, шура, пилите. они телодочо в илентравиць обяденон:<eos>',\n",
       " '<bos>пилите, шура, пилите. они зной изчелька вснь кутога.<eos>',\n",
       " '<bos>пилите, шура, пилите. они  пруметы, набы, навечал, мнсяы куболицая в стенугноцяциль.<eos>']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.inference(\"Пилите, Шура, пилите. Они \", device=device) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3. 1/2/3/4 балла\n",
    "**TBD**: \n",
    "Попробуйте обучить рекуррентную сеть задаче классификации. Вы можете воспользоваться сторонними библиотеками для вашей работы, \n",
    "но модель и основной код должны быть написаны на pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  {*} Задача 4. 5/6/7/8 баллов\n",
    "[ссылка](https://www.kaggle.com/t/b2ef08dc3ddf44f981e2ad186c6c508d)\n",
    "\n",
    "Попробуйте обучить сверточную нейронную сеть задаче детекции людей на изображениях разного стиля. Вы можете воспользоваться сторонними библиотеками для вашей работы. Однако, за неисопользование полностью готовых скриптов обучения (как в классной работе) вы получите дополнительные2 балла"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
