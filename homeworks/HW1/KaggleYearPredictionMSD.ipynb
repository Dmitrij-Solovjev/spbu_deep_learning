{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Задание 4.\n","Рассмотрим датасет по предсказанию года создания песни по числовым признакам.\n","Информацию о датасете можно найти здесь: \n","- https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD#\n","- http://labrosa.ee.columbia.edu/millionsong\n","- https://en.wikipedia.org/wiki/Timbre\n","\n","**Ссылка**: https://www.kaggle.com/t/c55b0b2354bd4ca5ac83fe5ed8b3eb92\n","\n","Мы используем поднабор этого датасета. Пожалуйста, не используйте исходный датасет для читинга, за это получите 0 за ВООБЩЕ всю домашку. Это задание организовано с помощью соревнования на kaggle.\n","Попробуйте обучить нейронную сеть (используя линейные и другие слои, возможную нормализацию и активации). Можете использовать любые методы предобработки данных и фокусы, \n","кроме ансамблирования и использования сторонних источников ДАННЫХ.\n","- Задание обязательно, базовое максимальное число баллов - 6. \n","- Топ 25% получат +3 балла, топ 50 +2 балла, топ 75 +1 балл.\n","- Решение должно быть уникальным, необходимо предоставить код и описание решения. Если использованы внешние источники (туториалы, статьи и т.п.), необходимо предоставить ссылки.\n","- Обучите модель, используя ваш кастомный оптимизатор. Это даст еще 1 балл. Покажите, изменилось ли что-то.\n","- При решении задачи можно использовать любые встренные в torch модули (nn, optim, transforms, etc)\n","- Можно использовать numpy, sklearn, pandas ТОЛЬКО для предобработки и постобработки решения (сборки сабмишена). Для самой модели можно использовать только torch.\n","- При переобучении можно добавить dropout, batchnorm итд. "]},{"cell_type":"markdown","metadata":{},"source":["# Предобработка\n","[Источник вдохновления](https://www.kaggle.com/code/raghav1810/release-year-prediction-on-msd-using-neural-nets)"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical \n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","\n","\n","df_x = pd.read_csv(\"../../datasets/YearPredictionMSD/train_x.csv\", index_col=[0]) #, sep=\",\"\n","df_y = pd.read_csv(\"../../datasets/YearPredictionMSD/train_y.csv\", index_col=[0])\n","df = pd.merge(df_x, df_y, left_index=True, right_index=True)\n","\n","#df.info()"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>81</th>\n","      <th>82</th>\n","      <th>83</th>\n","      <th>84</th>\n","      <th>85</th>\n","      <th>86</th>\n","      <th>87</th>\n","      <th>88</th>\n","      <th>89</th>\n","      <th>year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>...</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","      <td>14000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>43.394558</td>\n","      <td>1.540279</td>\n","      <td>8.378243</td>\n","      <td>1.315349</td>\n","      <td>-6.476035</td>\n","      <td>-9.503415</td>\n","      <td>-2.243164</td>\n","      <td>-1.660698</td>\n","      <td>3.543946</td>\n","      <td>1.892996</td>\n","      <td>...</td>\n","      <td>-72.008182</td>\n","      <td>41.154440</td>\n","      <td>37.892338</td>\n","      <td>0.145765</td>\n","      <td>17.576243</td>\n","      <td>-28.502296</td>\n","      <td>4.474666</td>\n","      <td>17.717701</td>\n","      <td>1.227647</td>\n","      <td>1998.366714</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>6.074562</td>\n","      <td>51.578894</td>\n","      <td>35.742553</td>\n","      <td>16.622971</td>\n","      <td>22.823521</td>\n","      <td>12.926176</td>\n","      <td>14.700348</td>\n","      <td>8.035388</td>\n","      <td>10.629817</td>\n","      <td>6.602191</td>\n","      <td>...</td>\n","      <td>171.932584</td>\n","      <td>120.075095</td>\n","      <td>96.748418</td>\n","      <td>16.162963</td>\n","      <td>115.706029</td>\n","      <td>180.463987</td>\n","      <td>13.592096</td>\n","      <td>185.335542</td>\n","      <td>22.018997</td>\n","      <td>11.048088</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>7.199890</td>\n","      <td>-302.031900</td>\n","      <td>-257.525600</td>\n","      <td>-120.723150</td>\n","      <td>-142.160680</td>\n","      <td>-60.198620</td>\n","      <td>-100.602550</td>\n","      <td>-51.443820</td>\n","      <td>-75.539550</td>\n","      <td>-31.344160</td>\n","      <td>...</td>\n","      <td>-1976.846950</td>\n","      <td>-791.832320</td>\n","      <td>-1237.931680</td>\n","      <td>-227.608010</td>\n","      <td>-2678.193680</td>\n","      <td>-3059.906060</td>\n","      <td>-100.618700</td>\n","      <td>-5000.654060</td>\n","      <td>-286.031200</td>\n","      <td>1922.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>39.970260</td>\n","      <td>-25.603507</td>\n","      <td>-11.773080</td>\n","      <td>-8.490435</td>\n","      <td>-20.716735</td>\n","      <td>-18.524397</td>\n","      <td>-10.651808</td>\n","      <td>-6.402985</td>\n","      <td>-2.573275</td>\n","      <td>-2.446435</td>\n","      <td>...</td>\n","      <td>-138.560657</td>\n","      <td>-21.424297</td>\n","      <td>-4.443660</td>\n","      <td>-7.027105</td>\n","      <td>-32.236598</td>\n","      <td>-101.305695</td>\n","      <td>-2.563620</td>\n","      <td>-60.364940</td>\n","      <td>-8.873683</td>\n","      <td>1994.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>44.282770</td>\n","      <td>8.800720</td>\n","      <td>10.226865</td>\n","      <td>-0.582025</td>\n","      <td>-5.808040</td>\n","      <td>-11.254920</td>\n","      <td>-2.007255</td>\n","      <td>-1.516640</td>\n","      <td>3.658655</td>\n","      <td>1.763500</td>\n","      <td>...</td>\n","      <td>-52.984525</td>\n","      <td>29.218730</td>\n","      <td>33.576620</td>\n","      <td>0.770135</td>\n","      <td>15.522650</td>\n","      <td>-22.050410</td>\n","      <td>3.021435</td>\n","      <td>6.982460</td>\n","      <td>-0.050725</td>\n","      <td>2002.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>47.843418</td>\n","      <td>36.610743</td>\n","      <td>29.596557</td>\n","      <td>9.035892</td>\n","      <td>7.858092</td>\n","      <td>-2.198952</td>\n","      <td>6.725500</td>\n","      <td>3.111740</td>\n","      <td>9.935210</td>\n","      <td>6.245860</td>\n","      <td>...</td>\n","      <td>14.405743</td>\n","      <td>89.374030</td>\n","      <td>78.710667</td>\n","      <td>8.380725</td>\n","      <td>66.429958</td>\n","      <td>50.378898</td>\n","      <td>9.912000</td>\n","      <td>86.542642</td>\n","      <td>9.664982</td>\n","      <td>2006.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>57.408630</td>\n","      <td>240.617010</td>\n","      <td>318.868960</td>\n","      <td>143.841600</td>\n","      <td>142.305480</td>\n","      <td>68.300090</td>\n","      <td>147.965260</td>\n","      <td>52.331120</td>\n","      <td>78.149440</td>\n","      <td>36.596180</td>\n","      <td>...</td>\n","      <td>1081.951340</td>\n","      <td>1473.745210</td>\n","      <td>1458.580210</td>\n","      <td>199.121500</td>\n","      <td>1620.749740</td>\n","      <td>1879.332480</td>\n","      <td>352.359540</td>\n","      <td>3165.372860</td>\n","      <td>245.209770</td>\n","      <td>2011.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 91 columns</p>\n","</div>"],"text/plain":["                  0             1             2             3             4  \\\n","count  14000.000000  14000.000000  14000.000000  14000.000000  14000.000000   \n","mean      43.394558      1.540279      8.378243      1.315349     -6.476035   \n","std        6.074562     51.578894     35.742553     16.622971     22.823521   \n","min        7.199890   -302.031900   -257.525600   -120.723150   -142.160680   \n","25%       39.970260    -25.603507    -11.773080     -8.490435    -20.716735   \n","50%       44.282770      8.800720     10.226865     -0.582025     -5.808040   \n","75%       47.843418     36.610743     29.596557      9.035892      7.858092   \n","max       57.408630    240.617010    318.868960    143.841600    142.305480   \n","\n","                  5             6             7             8             9  \\\n","count  14000.000000  14000.000000  14000.000000  14000.000000  14000.000000   \n","mean      -9.503415     -2.243164     -1.660698      3.543946      1.892996   \n","std       12.926176     14.700348      8.035388     10.629817      6.602191   \n","min      -60.198620   -100.602550    -51.443820    -75.539550    -31.344160   \n","25%      -18.524397    -10.651808     -6.402985     -2.573275     -2.446435   \n","50%      -11.254920     -2.007255     -1.516640      3.658655      1.763500   \n","75%       -2.198952      6.725500      3.111740      9.935210      6.245860   \n","max       68.300090    147.965260     52.331120     78.149440     36.596180   \n","\n","       ...            81            82            83            84  \\\n","count  ...  14000.000000  14000.000000  14000.000000  14000.000000   \n","mean   ...    -72.008182     41.154440     37.892338      0.145765   \n","std    ...    171.932584    120.075095     96.748418     16.162963   \n","min    ...  -1976.846950   -791.832320  -1237.931680   -227.608010   \n","25%    ...   -138.560657    -21.424297     -4.443660     -7.027105   \n","50%    ...    -52.984525     29.218730     33.576620      0.770135   \n","75%    ...     14.405743     89.374030     78.710667      8.380725   \n","max    ...   1081.951340   1473.745210   1458.580210    199.121500   \n","\n","                 85            86            87            88            89  \\\n","count  14000.000000  14000.000000  14000.000000  14000.000000  14000.000000   \n","mean      17.576243    -28.502296      4.474666     17.717701      1.227647   \n","std      115.706029    180.463987     13.592096    185.335542     22.018997   \n","min    -2678.193680  -3059.906060   -100.618700  -5000.654060   -286.031200   \n","25%      -32.236598   -101.305695     -2.563620    -60.364940     -8.873683   \n","50%       15.522650    -22.050410      3.021435      6.982460     -0.050725   \n","75%       66.429958     50.378898      9.912000     86.542642      9.664982   \n","max     1620.749740   1879.332480    352.359540   3165.372860    245.209770   \n","\n","               year  \n","count  14000.000000  \n","mean    1998.366714  \n","std       11.048088  \n","min     1922.000000  \n","25%     1994.000000  \n","50%     2002.000000  \n","75%     2006.000000  \n","max     2011.000000  \n","\n","[8 rows x 91 columns]"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["df.describe()\n","#df.to_csv(\"df_describe()\", sep='\\t', index = False)\n"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>81</th>\n","      <th>82</th>\n","      <th>83</th>\n","      <th>84</th>\n","      <th>85</th>\n","      <th>86</th>\n","      <th>87</th>\n","      <th>88</th>\n","      <th>89</th>\n","      <th>year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.000000</td>\n","      <td>0.566384</td>\n","      <td>0.238219</td>\n","      <td>0.015581</td>\n","      <td>-0.290998</td>\n","      <td>-0.255993</td>\n","      <td>0.150465</td>\n","      <td>-0.056922</td>\n","      <td>0.218639</td>\n","      <td>0.100482</td>\n","      <td>...</td>\n","      <td>0.185610</td>\n","      <td>-0.141162</td>\n","      <td>0.043386</td>\n","      <td>0.131090</td>\n","      <td>-0.023281</td>\n","      <td>0.060050</td>\n","      <td>-0.151631</td>\n","      <td>-0.090429</td>\n","      <td>-0.181318</td>\n","      <td>0.231402</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.566384</td>\n","      <td>1.000000</td>\n","      <td>0.003449</td>\n","      <td>0.108685</td>\n","      <td>-0.176475</td>\n","      <td>-0.118153</td>\n","      <td>0.093488</td>\n","      <td>0.110959</td>\n","      <td>0.139684</td>\n","      <td>0.381411</td>\n","      <td>...</td>\n","      <td>0.068017</td>\n","      <td>-0.160104</td>\n","      <td>0.025871</td>\n","      <td>0.147906</td>\n","      <td>0.052706</td>\n","      <td>0.001514</td>\n","      <td>-0.020335</td>\n","      <td>-0.117093</td>\n","      <td>-0.143765</td>\n","      <td>0.027011</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.238219</td>\n","      <td>0.003449</td>\n","      <td>1.000000</td>\n","      <td>0.141888</td>\n","      <td>-0.120211</td>\n","      <td>0.058324</td>\n","      <td>-0.056112</td>\n","      <td>0.084467</td>\n","      <td>0.032342</td>\n","      <td>-0.103261</td>\n","      <td>...</td>\n","      <td>0.176158</td>\n","      <td>0.105282</td>\n","      <td>-0.013705</td>\n","      <td>-0.038581</td>\n","      <td>-0.103733</td>\n","      <td>0.083694</td>\n","      <td>-0.078674</td>\n","      <td>-0.090521</td>\n","      <td>0.096694</td>\n","      <td>-0.142195</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.015581</td>\n","      <td>0.108685</td>\n","      <td>0.141888</td>\n","      <td>1.000000</td>\n","      <td>0.041031</td>\n","      <td>0.316875</td>\n","      <td>0.276893</td>\n","      <td>0.033091</td>\n","      <td>-0.068800</td>\n","      <td>0.158218</td>\n","      <td>...</td>\n","      <td>-0.103787</td>\n","      <td>0.064347</td>\n","      <td>0.081510</td>\n","      <td>-0.082989</td>\n","      <td>0.065558</td>\n","      <td>0.024398</td>\n","      <td>0.263893</td>\n","      <td>0.042521</td>\n","      <td>0.004551</td>\n","      <td>0.015034</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.290998</td>\n","      <td>-0.176475</td>\n","      <td>-0.120211</td>\n","      <td>0.041031</td>\n","      <td>1.000000</td>\n","      <td>0.012747</td>\n","      <td>-0.099421</td>\n","      <td>-0.004039</td>\n","      <td>-0.218758</td>\n","      <td>-0.090853</td>\n","      <td>...</td>\n","      <td>-0.094841</td>\n","      <td>0.025572</td>\n","      <td>-0.023188</td>\n","      <td>0.013525</td>\n","      <td>0.001245</td>\n","      <td>-0.029810</td>\n","      <td>-0.015504</td>\n","      <td>-0.009246</td>\n","      <td>0.031752</td>\n","      <td>0.005840</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>0.060050</td>\n","      <td>0.001514</td>\n","      <td>0.083694</td>\n","      <td>0.024398</td>\n","      <td>-0.029810</td>\n","      <td>-0.030335</td>\n","      <td>0.024270</td>\n","      <td>0.020748</td>\n","      <td>0.057749</td>\n","      <td>0.021375</td>\n","      <td>...</td>\n","      <td>-0.015066</td>\n","      <td>0.160687</td>\n","      <td>0.360869</td>\n","      <td>0.020517</td>\n","      <td>0.015611</td>\n","      <td>1.000000</td>\n","      <td>-0.016337</td>\n","      <td>0.182361</td>\n","      <td>0.216426</td>\n","      <td>0.021897</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>-0.151631</td>\n","      <td>-0.020335</td>\n","      <td>-0.078674</td>\n","      <td>0.263893</td>\n","      <td>-0.015504</td>\n","      <td>0.137150</td>\n","      <td>0.087998</td>\n","      <td>0.047344</td>\n","      <td>0.003349</td>\n","      <td>0.068824</td>\n","      <td>...</td>\n","      <td>0.002216</td>\n","      <td>0.267372</td>\n","      <td>0.008950</td>\n","      <td>-0.233718</td>\n","      <td>0.091228</td>\n","      <td>-0.016337</td>\n","      <td>1.000000</td>\n","      <td>0.058742</td>\n","      <td>0.228683</td>\n","      <td>-0.017512</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>-0.090429</td>\n","      <td>-0.117093</td>\n","      <td>-0.090521</td>\n","      <td>0.042521</td>\n","      <td>-0.009246</td>\n","      <td>-0.003068</td>\n","      <td>0.091808</td>\n","      <td>-0.010945</td>\n","      <td>0.024786</td>\n","      <td>-0.021552</td>\n","      <td>...</td>\n","      <td>-0.064811</td>\n","      <td>0.077995</td>\n","      <td>0.127760</td>\n","      <td>-0.017652</td>\n","      <td>0.180202</td>\n","      <td>0.182361</td>\n","      <td>0.058742</td>\n","      <td>1.000000</td>\n","      <td>0.168630</td>\n","      <td>0.005741</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>-0.181318</td>\n","      <td>-0.143765</td>\n","      <td>0.096694</td>\n","      <td>0.004551</td>\n","      <td>0.031752</td>\n","      <td>0.019502</td>\n","      <td>-0.067506</td>\n","      <td>0.059553</td>\n","      <td>0.048917</td>\n","      <td>0.016578</td>\n","      <td>...</td>\n","      <td>-0.019252</td>\n","      <td>0.090612</td>\n","      <td>-0.029815</td>\n","      <td>-0.155303</td>\n","      <td>-0.025547</td>\n","      <td>0.216426</td>\n","      <td>0.228683</td>\n","      <td>0.168630</td>\n","      <td>1.000000</td>\n","      <td>-0.050458</td>\n","    </tr>\n","    <tr>\n","      <th>year</th>\n","      <td>0.231402</td>\n","      <td>0.027011</td>\n","      <td>-0.142195</td>\n","      <td>0.015034</td>\n","      <td>0.005840</td>\n","      <td>-0.180360</td>\n","      <td>0.116159</td>\n","      <td>-0.031998</td>\n","      <td>-0.028390</td>\n","      <td>0.039055</td>\n","      <td>...</td>\n","      <td>0.001326</td>\n","      <td>0.021529</td>\n","      <td>0.026158</td>\n","      <td>0.050180</td>\n","      <td>-0.047564</td>\n","      <td>0.021897</td>\n","      <td>-0.017512</td>\n","      <td>0.005741</td>\n","      <td>-0.050458</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>91 rows × 91 columns</p>\n","</div>"],"text/plain":["             0         1         2         3         4         5         6  \\\n","0     1.000000  0.566384  0.238219  0.015581 -0.290998 -0.255993  0.150465   \n","1     0.566384  1.000000  0.003449  0.108685 -0.176475 -0.118153  0.093488   \n","2     0.238219  0.003449  1.000000  0.141888 -0.120211  0.058324 -0.056112   \n","3     0.015581  0.108685  0.141888  1.000000  0.041031  0.316875  0.276893   \n","4    -0.290998 -0.176475 -0.120211  0.041031  1.000000  0.012747 -0.099421   \n","...        ...       ...       ...       ...       ...       ...       ...   \n","86    0.060050  0.001514  0.083694  0.024398 -0.029810 -0.030335  0.024270   \n","87   -0.151631 -0.020335 -0.078674  0.263893 -0.015504  0.137150  0.087998   \n","88   -0.090429 -0.117093 -0.090521  0.042521 -0.009246 -0.003068  0.091808   \n","89   -0.181318 -0.143765  0.096694  0.004551  0.031752  0.019502 -0.067506   \n","year  0.231402  0.027011 -0.142195  0.015034  0.005840 -0.180360  0.116159   \n","\n","             7         8         9  ...        81        82        83  \\\n","0    -0.056922  0.218639  0.100482  ...  0.185610 -0.141162  0.043386   \n","1     0.110959  0.139684  0.381411  ...  0.068017 -0.160104  0.025871   \n","2     0.084467  0.032342 -0.103261  ...  0.176158  0.105282 -0.013705   \n","3     0.033091 -0.068800  0.158218  ... -0.103787  0.064347  0.081510   \n","4    -0.004039 -0.218758 -0.090853  ... -0.094841  0.025572 -0.023188   \n","...        ...       ...       ...  ...       ...       ...       ...   \n","86    0.020748  0.057749  0.021375  ... -0.015066  0.160687  0.360869   \n","87    0.047344  0.003349  0.068824  ...  0.002216  0.267372  0.008950   \n","88   -0.010945  0.024786 -0.021552  ... -0.064811  0.077995  0.127760   \n","89    0.059553  0.048917  0.016578  ... -0.019252  0.090612 -0.029815   \n","year -0.031998 -0.028390  0.039055  ...  0.001326  0.021529  0.026158   \n","\n","            84        85        86        87        88        89      year  \n","0     0.131090 -0.023281  0.060050 -0.151631 -0.090429 -0.181318  0.231402  \n","1     0.147906  0.052706  0.001514 -0.020335 -0.117093 -0.143765  0.027011  \n","2    -0.038581 -0.103733  0.083694 -0.078674 -0.090521  0.096694 -0.142195  \n","3    -0.082989  0.065558  0.024398  0.263893  0.042521  0.004551  0.015034  \n","4     0.013525  0.001245 -0.029810 -0.015504 -0.009246  0.031752  0.005840  \n","...        ...       ...       ...       ...       ...       ...       ...  \n","86    0.020517  0.015611  1.000000 -0.016337  0.182361  0.216426  0.021897  \n","87   -0.233718  0.091228 -0.016337  1.000000  0.058742  0.228683 -0.017512  \n","88   -0.017652  0.180202  0.182361  0.058742  1.000000  0.168630  0.005741  \n","89   -0.155303 -0.025547  0.216426  0.228683  0.168630  1.000000 -0.050458  \n","year  0.050180 -0.047564  0.021897 -0.017512  0.005741 -0.050458  1.000000  \n","\n","[91 rows x 91 columns]"]},"execution_count":97,"metadata":{},"output_type":"execute_result"}],"source":["corr_matrix = df.corr()\n","corr_matrix"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"data":{"text/plain":["Text(0, 0.5, 'Number of songs')"]},"execution_count":98,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["nsongs = {}\n","for y in range(1922,2012):\n","    nsongs[y] = len(df[df.year==y])\n","yrs = range(1922,2011)\n","values = [nsongs[y] for y in yrs]\n","plt.bar(yrs, values, align='center')\n","plt.xlabel(\"Year\")\n","plt.ylabel(\"Number of songs\")"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>80</th>\n","      <th>81</th>\n","      <th>82</th>\n","      <th>83</th>\n","      <th>84</th>\n","      <th>85</th>\n","      <th>86</th>\n","      <th>87</th>\n","      <th>88</th>\n","      <th>89</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>91760</th>\n","      <td>45.46530</td>\n","      <td>75.45026</td>\n","      <td>35.47050</td>\n","      <td>2.95624</td>\n","      <td>-19.71282</td>\n","      <td>2.89321</td>\n","      <td>7.77444</td>\n","      <td>3.78676</td>\n","      <td>-5.32777</td>\n","      <td>-0.01938</td>\n","      <td>...</td>\n","      <td>17.23378</td>\n","      <td>27.19400</td>\n","      <td>25.61453</td>\n","      <td>36.30716</td>\n","      <td>10.83426</td>\n","      <td>-0.17645</td>\n","      <td>-75.96021</td>\n","      <td>7.17215</td>\n","      <td>27.33528</td>\n","      <td>5.15809</td>\n","    </tr>\n","    <tr>\n","      <th>91369</th>\n","      <td>46.62819</td>\n","      <td>9.90625</td>\n","      <td>16.37036</td>\n","      <td>-5.59028</td>\n","      <td>-31.03397</td>\n","      <td>-21.84424</td>\n","      <td>14.85164</td>\n","      <td>5.76408</td>\n","      <td>21.08988</td>\n","      <td>10.97875</td>\n","      <td>...</td>\n","      <td>-46.51487</td>\n","      <td>42.38361</td>\n","      <td>52.68072</td>\n","      <td>-12.32147</td>\n","      <td>5.62891</td>\n","      <td>-6.79621</td>\n","      <td>-12.19250</td>\n","      <td>3.80050</td>\n","      <td>324.37311</td>\n","      <td>30.46507</td>\n","    </tr>\n","    <tr>\n","      <th>252079</th>\n","      <td>40.18896</td>\n","      <td>-34.45273</td>\n","      <td>14.01492</td>\n","      <td>2.41669</td>\n","      <td>-24.71461</td>\n","      <td>0.99973</td>\n","      <td>-8.10141</td>\n","      <td>-10.29385</td>\n","      <td>5.54575</td>\n","      <td>-4.24138</td>\n","      <td>...</td>\n","      <td>14.63288</td>\n","      <td>-116.97684</td>\n","      <td>-13.67563</td>\n","      <td>-22.74521</td>\n","      <td>11.06194</td>\n","      <td>6.17129</td>\n","      <td>7.35682</td>\n","      <td>-11.32322</td>\n","      <td>-54.77686</td>\n","      <td>-11.11203</td>\n","    </tr>\n","    <tr>\n","      <th>444856</th>\n","      <td>38.54147</td>\n","      <td>47.70578</td>\n","      <td>28.53514</td>\n","      <td>19.99441</td>\n","      <td>-7.08553</td>\n","      <td>-6.66930</td>\n","      <td>-0.38035</td>\n","      <td>1.43341</td>\n","      <td>-11.50862</td>\n","      <td>4.06733</td>\n","      <td>...</td>\n","      <td>7.98866</td>\n","      <td>-215.72206</td>\n","      <td>-107.01376</td>\n","      <td>103.22619</td>\n","      <td>-2.79405</td>\n","      <td>-31.75290</td>\n","      <td>-80.37151</td>\n","      <td>8.28595</td>\n","      <td>103.31381</td>\n","      <td>1.93217</td>\n","    </tr>\n","    <tr>\n","      <th>324497</th>\n","      <td>53.60781</td>\n","      <td>37.13907</td>\n","      <td>-1.11425</td>\n","      <td>16.71224</td>\n","      <td>21.01561</td>\n","      <td>-21.00132</td>\n","      <td>7.63646</td>\n","      <td>2.46501</td>\n","      <td>1.59013</td>\n","      <td>9.28488</td>\n","      <td>...</td>\n","      <td>-7.19041</td>\n","      <td>-132.61324</td>\n","      <td>-52.45465</td>\n","      <td>-3.50508</td>\n","      <td>9.49213</td>\n","      <td>-29.86827</td>\n","      <td>-146.99808</td>\n","      <td>-17.49415</td>\n","      <td>-29.14021</td>\n","      <td>-28.58531</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>505513</th>\n","      <td>36.30192</td>\n","      <td>16.14399</td>\n","      <td>63.81001</td>\n","      <td>11.62573</td>\n","      <td>7.08731</td>\n","      <td>32.35446</td>\n","      <td>-44.79767</td>\n","      <td>-0.76175</td>\n","      <td>1.83869</td>\n","      <td>9.03123</td>\n","      <td>...</td>\n","      <td>20.91729</td>\n","      <td>-113.00219</td>\n","      <td>256.89098</td>\n","      <td>64.26000</td>\n","      <td>29.16705</td>\n","      <td>68.41382</td>\n","      <td>23.01293</td>\n","      <td>-3.80363</td>\n","      <td>40.25667</td>\n","      <td>-15.91831</td>\n","    </tr>\n","    <tr>\n","      <th>215475</th>\n","      <td>49.66914</td>\n","      <td>44.91246</td>\n","      <td>-22.12116</td>\n","      <td>-18.58574</td>\n","      <td>-2.69059</td>\n","      <td>-29.05889</td>\n","      <td>-4.67774</td>\n","      <td>-1.94542</td>\n","      <td>4.26079</td>\n","      <td>1.01704</td>\n","      <td>...</td>\n","      <td>4.79795</td>\n","      <td>-70.57352</td>\n","      <td>-43.46799</td>\n","      <td>-9.73019</td>\n","      <td>-1.47315</td>\n","      <td>29.21690</td>\n","      <td>-72.31892</td>\n","      <td>8.90277</td>\n","      <td>194.21148</td>\n","      <td>2.42360</td>\n","    </tr>\n","    <tr>\n","      <th>219954</th>\n","      <td>37.28237</td>\n","      <td>-79.66959</td>\n","      <td>91.42166</td>\n","      <td>2.39973</td>\n","      <td>15.16975</td>\n","      <td>-1.40565</td>\n","      <td>-38.82533</td>\n","      <td>-7.95218</td>\n","      <td>8.85991</td>\n","      <td>-8.50413</td>\n","      <td>...</td>\n","      <td>94.91744</td>\n","      <td>-334.86204</td>\n","      <td>207.11738</td>\n","      <td>-56.65323</td>\n","      <td>-9.09471</td>\n","      <td>-37.80197</td>\n","      <td>-470.48789</td>\n","      <td>13.57016</td>\n","      <td>18.28176</td>\n","      <td>7.66985</td>\n","    </tr>\n","    <tr>\n","      <th>337570</th>\n","      <td>43.86913</td>\n","      <td>-0.20153</td>\n","      <td>36.46604</td>\n","      <td>-2.86395</td>\n","      <td>21.35272</td>\n","      <td>-17.25184</td>\n","      <td>-13.24762</td>\n","      <td>-2.94265</td>\n","      <td>4.54526</td>\n","      <td>2.25322</td>\n","      <td>...</td>\n","      <td>20.19795</td>\n","      <td>-128.57375</td>\n","      <td>-29.20243</td>\n","      <td>96.05717</td>\n","      <td>2.34277</td>\n","      <td>-17.52861</td>\n","      <td>155.24947</td>\n","      <td>6.18787</td>\n","      <td>-70.94871</td>\n","      <td>-0.95426</td>\n","    </tr>\n","    <tr>\n","      <th>312186</th>\n","      <td>44.32148</td>\n","      <td>3.51929</td>\n","      <td>-36.57464</td>\n","      <td>-10.06966</td>\n","      <td>-1.38942</td>\n","      <td>-6.54856</td>\n","      <td>2.11339</td>\n","      <td>4.99018</td>\n","      <td>1.82090</td>\n","      <td>1.75405</td>\n","      <td>...</td>\n","      <td>0.37628</td>\n","      <td>-498.42270</td>\n","      <td>-7.88062</td>\n","      <td>106.92642</td>\n","      <td>-8.61648</td>\n","      <td>57.40160</td>\n","      <td>17.61438</td>\n","      <td>10.98254</td>\n","      <td>113.25500</td>\n","      <td>11.08690</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9800 rows × 90 columns</p>\n","</div>"],"text/plain":["               0         1         2         3         4         5         6  \\\n","91760   45.46530  75.45026  35.47050   2.95624 -19.71282   2.89321   7.77444   \n","91369   46.62819   9.90625  16.37036  -5.59028 -31.03397 -21.84424  14.85164   \n","252079  40.18896 -34.45273  14.01492   2.41669 -24.71461   0.99973  -8.10141   \n","444856  38.54147  47.70578  28.53514  19.99441  -7.08553  -6.66930  -0.38035   \n","324497  53.60781  37.13907  -1.11425  16.71224  21.01561 -21.00132   7.63646   \n","...          ...       ...       ...       ...       ...       ...       ...   \n","505513  36.30192  16.14399  63.81001  11.62573   7.08731  32.35446 -44.79767   \n","215475  49.66914  44.91246 -22.12116 -18.58574  -2.69059 -29.05889  -4.67774   \n","219954  37.28237 -79.66959  91.42166   2.39973  15.16975  -1.40565 -38.82533   \n","337570  43.86913  -0.20153  36.46604  -2.86395  21.35272 -17.25184 -13.24762   \n","312186  44.32148   3.51929 -36.57464 -10.06966  -1.38942  -6.54856   2.11339   \n","\n","               7         8         9  ...        80         81         82  \\\n","91760    3.78676  -5.32777  -0.01938  ...  17.23378   27.19400   25.61453   \n","91369    5.76408  21.08988  10.97875  ... -46.51487   42.38361   52.68072   \n","252079 -10.29385   5.54575  -4.24138  ...  14.63288 -116.97684  -13.67563   \n","444856   1.43341 -11.50862   4.06733  ...   7.98866 -215.72206 -107.01376   \n","324497   2.46501   1.59013   9.28488  ...  -7.19041 -132.61324  -52.45465   \n","...          ...       ...       ...  ...       ...        ...        ...   \n","505513  -0.76175   1.83869   9.03123  ...  20.91729 -113.00219  256.89098   \n","215475  -1.94542   4.26079   1.01704  ...   4.79795  -70.57352  -43.46799   \n","219954  -7.95218   8.85991  -8.50413  ...  94.91744 -334.86204  207.11738   \n","337570  -2.94265   4.54526   2.25322  ...  20.19795 -128.57375  -29.20243   \n","312186   4.99018   1.82090   1.75405  ...   0.37628 -498.42270   -7.88062   \n","\n","               83        84        85         86        87         88  \\\n","91760    36.30716  10.83426  -0.17645  -75.96021   7.17215   27.33528   \n","91369   -12.32147   5.62891  -6.79621  -12.19250   3.80050  324.37311   \n","252079  -22.74521  11.06194   6.17129    7.35682 -11.32322  -54.77686   \n","444856  103.22619  -2.79405 -31.75290  -80.37151   8.28595  103.31381   \n","324497   -3.50508   9.49213 -29.86827 -146.99808 -17.49415  -29.14021   \n","...           ...       ...       ...        ...       ...        ...   \n","505513   64.26000  29.16705  68.41382   23.01293  -3.80363   40.25667   \n","215475   -9.73019  -1.47315  29.21690  -72.31892   8.90277  194.21148   \n","219954  -56.65323  -9.09471 -37.80197 -470.48789  13.57016   18.28176   \n","337570   96.05717   2.34277 -17.52861  155.24947   6.18787  -70.94871   \n","312186  106.92642  -8.61648  57.40160   17.61438  10.98254  113.25500   \n","\n","              89  \n","91760    5.15809  \n","91369   30.46507  \n","252079 -11.11203  \n","444856   1.93217  \n","324497 -28.58531  \n","...          ...  \n","505513 -15.91831  \n","215475   2.42360  \n","219954   7.66985  \n","337570  -0.95426  \n","312186  11.08690  \n","\n","[9800 rows x 90 columns]"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["X_train, X_test, Y_train, Y_test = train_test_split(df.iloc[:, 0:90], df_y[\"year\"], test_size=0.3)\n","X_train"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["scaler = StandardScaler()\n","# Fit on training set only.\n","scaler.fit(X_train)\n","# Apply transform to both the train set and the test set.\n","X_train_std = scaler.transform(X_train)\n","X_test_std = scaler.transform(X_test)\n","X_train_std = pd.DataFrame(X_train_std,columns=X_train.columns)\n"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"data":{"text/plain":["54"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["# Make an instance of the Model\n","pca = PCA(.90)\n","\n","# We fit to only our training set\n","pca.fit(X_train_std)\n","# Print number of components generated\n","pca.n_components_"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/dima/Документы/Першин_Никольская_Нейронные_сети/myvenv/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n","  warnings.warn(\n"]}],"source":["X_train_proc = torch.tensor(pca.transform(X_train_std), dtype=torch.float)\n","X_test_proc = torch.tensor(pca.transform(X_test_std), dtype=torch.float)"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[],"source":["Y_train_proc = Y_train - min(Y_train)\n","Y_test_proc = Y_test - min(Y_test)"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[],"source":["Y_train_hot = torch.tensor(to_categorical(Y_train_proc, 90), dtype=torch.uint8)\n","Y_test_hot = torch.tensor(to_categorical(Y_test_proc, 90), dtype=torch.uint8)"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([9800, 54])\n","torch.Size([4200, 90])\n"]}],"source":["print(X_train_proc.shape)\n","print(Y_test_hot.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# Нейросеть\n","[Источник вдохновления](https://machinelearningmastery.com/building-multilayer-perceptron-models-in-pytorch/)"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","\n","\n","class Multiclass(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.input = nn.Linear(54, 100)\n","        self.act = nn.ReLU()\n","#        self.hidden = nn.Linear(100, 100)\n","#        self.act = nn.ReLU()\n","        self.output = nn.Linear(100, 90)\n","        self.act = nn.Softmax()\n","        \n","    def forward(self, x):\n","        x = self.act(self.hidden(x))\n","        x = self.output(x)\n","        return x\n","\n","model = Multiclass()"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","loss_fn = nn.CrossEntropyLoss()\n"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'Multiclass' object has no attribute 'hidden'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[108], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_proc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, Y_train_hot)\n\u001b[1;32m      4\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m~/Документы/Першин_Никольская_Нейронные_сети/myvenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Документы/Першин_Никольская_Нейронные_сети/myvenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[106], line 15\u001b[0m, in \u001b[0;36mMulticlass.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden\u001b[49m(x))\n\u001b[1;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(x)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m~/Документы/Першин_Никольская_Нейронные_сети/myvenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'Multiclass' object has no attribute 'hidden'"]}],"source":["for n in range(10):\n","    y_pred = model(X_train_proc)\n","    loss = loss_fn(y_pred, Y_train_hot)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss_fn = nn.CrossEntropyLoss()\n","loss = loss_fn(output, label)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":4}
